Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type late
0
starting val epoch 0
val [0000 / 0050] validation loss: 	1.07356
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 14:21:51       lr: 	1.0000E-03 loss: 	1.73301
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:5:52         lr: 	1.0000E-03 loss: 	0.63420
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:29:59        lr: 	1.0000E-03 loss: 	0.53789
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.38570
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:32:4         lr: 	1.0000E-03 loss: 	0.48322
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:20:50        lr: 	1.0000E-03 loss: 	0.41147
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:13:57        lr: 	1.0000E-03 loss: 	0.39579
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.42884
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:15:5         lr: 	1.0000E-03 loss: 	0.38653
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:10:54        lr: 	1.0000E-03 loss: 	0.36827
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:7:30         lr: 	1.0000E-03 loss: 	0.37615
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.41058
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:8:37         lr: 	1.0000E-03 loss: 	0.38104
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:5:57         lr: 	1.0000E-03 loss: 	0.38016
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:3:37         lr: 	1.0000E-03 loss: 	0.38791
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.41813
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:4:35         lr: 	1.0000E-03 loss: 	0.42986
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:2:31         lr: 	1.0000E-03 loss: 	0.37144
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:0:52         lr: 	1.0000E-03 loss: 	0.38051
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.41592
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:1:36         lr: 	1.0000E-03 loss: 	0.51294
 epoch [0005 / 0050] [0109/280] eta: 0 Days 0:59:59        lr: 	1.0000E-03 loss: 	0.38467
 epoch [0005 / 0050] [0209/280] eta: 0 Days 0:58:34        lr: 	1.0000E-03 loss: 	0.37874
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.41177
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 0:59:7         lr: 	1.0000E-03 loss: 	0.41639
 epoch [0006 / 0050] [0109/280] eta: 0 Days 0:57:46        lr: 	1.0000E-03 loss: 	0.38852
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:56:42        lr: 	1.0000E-03 loss: 	0.38481
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.39790
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 0:57:8         lr: 	1.0000E-03 loss: 	0.45293
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:56:0         lr: 	1.0000E-03 loss: 	0.38962
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:54:58        lr: 	1.0000E-03 loss: 	0.38743
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.44154
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:55:26        lr: 	1.0000E-03 loss: 	0.49102
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:54:20        lr: 	1.0000E-03 loss: 	0.38170
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:53:19        lr: 	1.0000E-03 loss: 	0.38377
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.41781
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:53:35        lr: 	1.0000E-03 loss: 	0.50753
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:52:42        lr: 	1.0000E-03 loss: 	0.37838
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:51:48        lr: 	1.0000E-03 loss: 	0.37294
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.43224
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:52:2         lr: 	1.0000E-03 loss: 	0.52856
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:51:7         lr: 	1.0000E-03 loss: 	0.35796
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:50:20        lr: 	1.0000E-03 loss: 	0.37047
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.38924
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:50:29        lr: 	1.0000E-03 loss: 	0.42307
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:49:46        lr: 	1.0000E-03 loss: 	0.37596
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:48:57        lr: 	1.0000E-03 loss: 	0.37092
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.38330
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:49:4         lr: 	1.0000E-03 loss: 	0.34703
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:48:24        lr: 	1.0000E-03 loss: 	0.37528
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:47:39        lr: 	1.0000E-03 loss: 	0.38735
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.41859
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:47:44        lr: 	1.0000E-03 loss: 	0.30732
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:47:2         lr: 	1.0000E-03 loss: 	0.35741
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:46:20        lr: 	1.0000E-03 loss: 	0.37153
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.40501
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:46:22        lr: 	1.0000E-03 loss: 	0.45905
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:45:39        lr: 	1.0000E-03 loss: 	0.35334
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:44:57        lr: 	1.0000E-03 loss: 	0.36931
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.46918
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:45:0         lr: 	1.0000E-03 loss: 	0.45359
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:44:15        lr: 	1.0000E-03 loss: 	0.37062
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:43:37        lr: 	1.0000E-03 loss: 	0.36200
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.45164
starting val epoch 0
val [0000 / 0050] validation loss: 	0.39000
Acute and unspecified renal failure                                                        & 0.717(0.760, 0.673) & 0.321 (0.390, 0.263)
fused_ehr test  0   best mean auc :0.717 mean auprc 0.321
                    CI AUROC (0.673, 0.760) CI AUPRC (0.263, 0.390)
                     AUROC accute 0.717 mixed 0.717 chronic 0.717
                     AUROC accute CI (0.673, 0.760) mixed (0.673 , 0.760) chronic (0.673, 0.760)
                     AUPRC accute  0.321 mixed 0.321 chronic 0.321
                     AUPRC accute CI  (0.263, 0.390) mixed (0.263,  0.390) chronic (0.263, 0.390)