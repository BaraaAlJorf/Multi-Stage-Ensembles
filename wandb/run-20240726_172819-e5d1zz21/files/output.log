Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.78205
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 15:34:35       lr: 	1.0000E-06 loss: 	0.79673 loss align 0.0000
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:14:24        lr: 	1.0000E-06 loss: 	0.54602 loss align 0.0000
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:36:39        lr: 	1.0000E-06 loss: 	0.48000 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.40501
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:37:53        lr: 	1.0000E-06 loss: 	0.44978 loss align 0.0000
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:26:20        lr: 	1.0000E-06 loss: 	0.39608 loss align 0.0000
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:20:5         lr: 	1.0000E-06 loss: 	0.38950 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.39073
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:23:14        lr: 	1.0000E-06 loss: 	0.42126 loss align 0.0000
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:19:15        lr: 	1.0000E-06 loss: 	0.36399 loss align 0.0000
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:15:28        lr: 	1.0000E-06 loss: 	0.37676 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.38537
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:17:25        lr: 	1.0000E-06 loss: 	0.42016 loss align 0.0000
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:14:36        lr: 	1.0000E-06 loss: 	0.37972 loss align 0.0000
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:12:10        lr: 	1.0000E-06 loss: 	0.37664 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.38302
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:13:19        lr: 	1.0000E-06 loss: 	0.44873 loss align 0.0000
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:11:22        lr: 	1.0000E-06 loss: 	0.37187 loss align 0.0000
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:9:35         lr: 	1.0000E-06 loss: 	0.36634 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.38362
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:10:37        lr: 	1.0000E-06 loss: 	0.40633 loss align 0.0000
 epoch [0005 / 0050] [0109/280] eta: 0 Days 1:8:52         lr: 	1.0000E-06 loss: 	0.36780 loss align 0.0000
 epoch [0005 / 0050] [0209/280] eta: 0 Days 1:7:15         lr: 	1.0000E-06 loss: 	0.36035 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.38296
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 1:7:44         lr: 	1.0000E-06 loss: 	0.36125 loss align 0.0000
 epoch [0006 / 0050] [0109/280] eta: 0 Days 1:6:24         lr: 	1.0000E-06 loss: 	0.36755 loss align 0.0000
 epoch [0006 / 0050] [0209/280] eta: 0 Days 1:5:2          lr: 	1.0000E-06 loss: 	0.36468 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.38304
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 1:5:49         lr: 	1.0000E-06 loss: 	0.42237 loss align 0.0000
 epoch [0007 / 0050] [0109/280] eta: 0 Days 1:4:33         lr: 	1.0000E-06 loss: 	0.37348 loss align 0.0000
 epoch [0007 / 0050] [0209/280] eta: 0 Days 1:3:15         lr: 	1.0000E-06 loss: 	0.35580 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.38279
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 1:3:28         lr: 	1.0000E-06 loss: 	0.29639 loss align 0.0000
 epoch [0008 / 0050] [0109/280] eta: 0 Days 1:2:17         lr: 	1.0000E-06 loss: 	0.37658 loss align 0.0000
 epoch [0008 / 0050] [0209/280] eta: 0 Days 1:1:7          lr: 	1.0000E-06 loss: 	0.36319 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.38702
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 1:1:16         lr: 	1.0000E-06 loss: 	0.31055 loss align 0.0000
 epoch [0009 / 0050] [0109/280] eta: 0 Days 1:0:13         lr: 	1.0000E-06 loss: 	0.35282 loss align 0.0000
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:59:12        lr: 	1.0000E-06 loss: 	0.35766 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.38460
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:59:23        lr: 	1.0000E-06 loss: 	0.41946 loss align 0.0000
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:58:22        lr: 	1.0000E-06 loss: 	0.35682 loss align 0.0000
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:57:23        lr: 	1.0000E-06 loss: 	0.35479 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.39740
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:57:32        lr: 	1.0000E-06 loss: 	0.46878 loss align 0.0000
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:56:34        lr: 	1.0000E-06 loss: 	0.36017 loss align 0.0000
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:55:39        lr: 	1.0000E-06 loss: 	0.35220 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.38122
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:55:38        lr: 	1.0000E-06 loss: 	0.32673 loss align 0.0000
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:54:45        lr: 	1.0000E-06 loss: 	0.33355 loss align 0.0000
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:53:53        lr: 	1.0000E-06 loss: 	0.33261 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.38969
checkpoint
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:53:59        lr: 	1.0000E-06 loss: 	0.39963 loss align 0.0000
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:53:8         lr: 	1.0000E-06 loss: 	0.33086 loss align 0.0000
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:52:18        lr: 	1.0000E-06 loss: 	0.33974 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.37577
checkpoint
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:52:25        lr: 	1.0000E-06 loss: 	0.35268 loss align 0.0000
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:51:41        lr: 	1.0000E-06 loss: 	0.32550 loss align 0.0000
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:50:54        lr: 	1.0000E-06 loss: 	0.33013 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.36672
checkpoint
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:50:53        lr: 	1.0000E-06 loss: 	0.26918 loss align 0.0000
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:50:4         lr: 	1.0000E-06 loss: 	0.32340 loss align 0.0000
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:49:16        lr: 	1.0000E-06 loss: 	0.32944 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.36241
checkpoint
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:49:13        lr: 	1.0000E-06 loss: 	0.38344 loss align 0.0000
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:48:29        lr: 	1.0000E-06 loss: 	0.31428 loss align 0.0000
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:47:46        lr: 	1.0000E-06 loss: 	0.32372 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.36605
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:47:37        lr: 	1.0000E-06 loss: 	0.37449 loss align 0.0000
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:46:53        lr: 	1.0000E-06 loss: 	0.31745 loss align 0.0000
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:46:13        lr: 	1.0000E-06 loss: 	0.31553 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.36397
checkpoint
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:46:9         lr: 	1.0000E-06 loss: 	0.35919 loss align 0.0000
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:45:26        lr: 	1.0000E-06 loss: 	0.31341 loss align 0.0000
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:44:45        lr: 	1.0000E-06 loss: 	0.31388 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.36866
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:44:33        lr: 	1.0000E-06 loss: 	0.33763 loss align 0.0000
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:43:51        lr: 	1.0000E-06 loss: 	0.29720 loss align 0.0000
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:43:10        lr: 	1.0000E-06 loss: 	0.29685 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.36811
starting train epoch 20
 epoch [0020 / 0050] [0009/280] eta: 0 Days 0:42:58        lr: 	1.0000E-06 loss: 	0.35180 loss align 0.0000
 epoch [0020 / 0050] [0109/280] eta: 0 Days 0:42:16        lr: 	1.0000E-06 loss: 	0.31152 loss align 0.0000
 epoch [0020 / 0050] [0209/280] eta: 0 Days 0:41:37        lr: 	1.0000E-06 loss: 	0.30397 loss align 0.0000
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.36989
checkpoint
starting train epoch 21
 epoch [0021 / 0050] [0009/280] eta: 0 Days 0:41:28        lr: 	1.0000E-06 loss: 	0.36299 loss align 0.0000
 epoch [0021 / 0050] [0109/280] eta: 0 Days 0:40:49        lr: 	1.0000E-06 loss: 	0.30905 loss align 0.0000
 epoch [0021 / 0050] [0209/280] eta: 0 Days 0:40:12        lr: 	1.0000E-06 loss: 	0.29124 loss align 0.0000
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.36751
checkpoint
starting train epoch 22
 epoch [0022 / 0050] [0009/280] eta: 0 Days 0:40:2         lr: 	1.0000E-06 loss: 	0.35521 loss align 0.0000
 epoch [0022 / 0050] [0109/280] eta: 0 Days 0:39:26        lr: 	1.0000E-06 loss: 	0.29423 loss align 0.0000
 epoch [0022 / 0050] [0209/280] eta: 0 Days 0:38:49        lr: 	1.0000E-06 loss: 	0.29695 loss align 0.0000
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.36707
checkpoint
starting train epoch 23
 epoch [0023 / 0050] [0009/280] eta: 0 Days 0:38:38        lr: 	1.0000E-06 loss: 	0.29369 loss align 0.0000
 epoch [0023 / 0050] [0109/280] eta: 0 Days 0:37:59        lr: 	1.0000E-06 loss: 	0.31464 loss align 0.0000
 epoch [0023 / 0050] [0209/280] eta: 0 Days 0:37:21        lr: 	1.0000E-06 loss: 	0.29380 loss align 0.0000
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.36912
checkpoint
starting train epoch 24
 epoch [0024 / 0050] [0009/280] eta: 0 Days 0:37:11        lr: 	1.0000E-06 loss: 	0.40625 loss align 0.0000
 epoch [0024 / 0050] [0109/280] eta: 0 Days 0:36:34        lr: 	1.0000E-06 loss: 	0.30295 loss align 0.0000
 epoch [0024 / 0050] [0209/280] eta: 0 Days 0:35:57        lr: 	1.0000E-06 loss: 	0.29341 loss align 0.0000
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.36767
checkpoint
starting train epoch 25
 epoch [0025 / 0050] [0009/280] eta: 0 Days 0:35:44        lr: 	1.0000E-06 loss: 	0.29661 loss align 0.0000
 epoch [0025 / 0050] [0109/280] eta: 0 Days 0:35:7         lr: 	1.0000E-06 loss: 	0.28202 loss align 0.0000
 epoch [0025 / 0050] [0209/280] eta: 0 Days 0:34:31        lr: 	1.0000E-06 loss: 	0.28866 loss align 0.0000
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.37372
starting train epoch 26
 epoch [0026 / 0050] [0009/280] eta: 0 Days 0:34:14        lr: 	1.0000E-06 loss: 	0.24119 loss align 0.0000
 epoch [0026 / 0050] [0109/280] eta: 0 Days 0:33:38        lr: 	1.0000E-06 loss: 	0.27192 loss align 0.0000
 epoch [0026 / 0050] [0209/280] eta: 0 Days 0:33:1         lr: 	1.0000E-06 loss: 	0.28486 loss align 0.0000
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.37230
starting train epoch 27
 epoch [0027 / 0050] [0009/280] eta: 0 Days 0:32:43        lr: 	1.0000E-06 loss: 	0.32471 loss align 0.0000
 epoch [0027 / 0050] [0109/280] eta: 0 Days 0:32:7         lr: 	1.0000E-06 loss: 	0.26936 loss align 0.0000
 epoch [0027 / 0050] [0209/280] eta: 0 Days 0:31:32        lr: 	1.0000E-06 loss: 	0.28638 loss align 0.0000
28
starting val epoch 28
val [0028 / 0050] validation loss: 	0.38503
starting train epoch 28
 epoch [0028 / 0050] [0009/280] eta: 0 Days 0:31:15        lr: 	1.0000E-06 loss: 	0.30747 loss align 0.0000
 epoch [0028 / 0050] [0109/280] eta: 0 Days 0:30:39        lr: 	1.0000E-06 loss: 	0.28611 loss align 0.0000
 epoch [0028 / 0050] [0209/280] eta: 0 Days 0:30:4         lr: 	1.0000E-06 loss: 	0.27713 loss align 0.0000
29
starting val epoch 29
val [0029 / 0050] validation loss: 	0.37596
starting train epoch 29
 epoch [0029 / 0050] [0009/280] eta: 0 Days 0:29:45        lr: 	1.0000E-06 loss: 	0.45308 loss align 0.0000
 epoch [0029 / 0050] [0109/280] eta: 0 Days 0:29:10        lr: 	1.0000E-06 loss: 	0.30966 loss align 0.0000
 epoch [0029 / 0050] [0209/280] eta: 0 Days 0:28:36        lr: 	1.0000E-06 loss: 	0.28586 loss align 0.0000
30
starting val epoch 30
val [0030 / 0050] validation loss: 	0.38694
starting train epoch 30
 epoch [0030 / 0050] [0009/280] eta: 0 Days 0:28:16        lr: 	1.0000E-06 loss: 	0.33813 loss align 0.0000
 epoch [0030 / 0050] [0109/280] eta: 0 Days 0:27:43        lr: 	1.0000E-06 loss: 	0.28276 loss align 0.0000
 epoch [0030 / 0050] [0209/280] eta: 0 Days 0:27:8         lr: 	1.0000E-06 loss: 	0.27642 loss align 0.0000
31
starting val epoch 31
val [0031 / 0050] validation loss: 	0.39850
checkpoint
starting train epoch 31
 epoch [0031 / 0050] [0009/280] eta: 0 Days 0:26:51        lr: 	1.0000E-06 loss: 	0.39631 loss align 0.0000
 epoch [0031 / 0050] [0109/280] eta: 0 Days 0:26:16        lr: 	1.0000E-06 loss: 	0.26311 loss align 0.0000
 epoch [0031 / 0050] [0209/280] eta: 0 Days 0:25:42        lr: 	1.0000E-06 loss: 	0.26687 loss align 0.0000
32
starting val epoch 32
val [0032 / 0050] validation loss: 	0.38681
starting train epoch 32
 epoch [0032 / 0050] [0009/280] eta: 0 Days 0:25:22        lr: 	1.0000E-06 loss: 	0.36563 loss align 0.0000
 epoch [0032 / 0050] [0109/280] eta: 0 Days 0:24:48        lr: 	1.0000E-06 loss: 	0.26147 loss align 0.0000
 epoch [0032 / 0050] [0209/280] eta: 0 Days 0:24:15        lr: 	1.0000E-06 loss: 	0.27129 loss align 0.0000
33
starting val epoch 33
val [0033 / 0050] validation loss: 	0.38810
starting train epoch 33
 epoch [0033 / 0050] [0009/280] eta: 0 Days 0:23:56        lr: 	1.0000E-06 loss: 	0.27472 loss align 0.0000
 epoch [0033 / 0050] [0109/280] eta: 0 Days 0:23:23        lr: 	1.0000E-06 loss: 	0.25365 loss align 0.0000
 epoch [0033 / 0050] [0209/280] eta: 0 Days 0:22:50        lr: 	1.0000E-06 loss: 	0.27264 loss align 0.0000
34
starting val epoch 34
val [0034 / 0050] validation loss: 	0.38118
starting train epoch 34
 epoch [0034 / 0050] [0009/280] eta: 0 Days 0:22:30        lr: 	1.0000E-06 loss: 	0.34991 loss align 0.0000
 epoch [0034 / 0050] [0109/280] eta: 0 Days 0:21:56        lr: 	1.0000E-06 loss: 	0.27901 loss align 0.0000
 epoch [0034 / 0050] [0209/280] eta: 0 Days 0:21:24        lr: 	1.0000E-06 loss: 	0.26552 loss align 0.0000
35
starting val epoch 35
val [0035 / 0050] validation loss: 	0.40786
starting train epoch 35
 epoch [0035 / 0050] [0009/280] eta: 0 Days 0:21:3         lr: 	1.0000E-06 loss: 	0.25031 loss align 0.0000
 epoch [0035 / 0050] [0109/280] eta: 0 Days 0:20:31        lr: 	1.0000E-06 loss: 	0.25458 loss align 0.0000
 epoch [0035 / 0050] [0209/280] eta: 0 Days 0:19:59        lr: 	1.0000E-06 loss: 	0.27156 loss align 0.0000
36
starting val epoch 36
val [0036 / 0050] validation loss: 	0.38929
starting train epoch 36
 epoch [0036 / 0050] [0009/280] eta: 0 Days 0:19:39        lr: 	1.0000E-06 loss: 	0.34909 loss align 0.0000
 epoch [0036 / 0050] [0109/280] eta: 0 Days 0:19:7         lr: 	1.0000E-06 loss: 	0.27879 loss align 0.0000
 epoch [0036 / 0050] [0209/280] eta: 0 Days 0:18:35        lr: 	1.0000E-06 loss: 	0.26498 loss align 0.0000
37
starting val epoch 37
val [0037 / 0050] validation loss: 	0.39140
starting train epoch 37
 epoch [0037 / 0050] [0009/280] eta: 0 Days 0:18:14        lr: 	1.0000E-06 loss: 	0.27464 loss align 0.0000
 epoch [0037 / 0050] [0109/280] eta: 0 Days 0:17:42        lr: 	1.0000E-06 loss: 	0.26073 loss align 0.0000
 epoch [0037 / 0050] [0209/280] eta: 0 Days 0:17:10        lr: 	1.0000E-06 loss: 	0.25543 loss align 0.0000
38
starting val epoch 38
val [0038 / 0050] validation loss: 	0.39124
starting train epoch 38
 epoch [0038 / 0050] [0009/280] eta: 0 Days 0:16:49        lr: 	1.0000E-06 loss: 	0.28684 loss align 0.0000
 epoch [0038 / 0050] [0109/280] eta: 0 Days 0:16:17        lr: 	1.0000E-06 loss: 	0.27169 loss align 0.0000
 epoch [0038 / 0050] [0209/280] eta: 0 Days 0:15:46        lr: 	1.0000E-06 loss: 	0.26412 loss align 0.0000
39
starting val epoch 39
val [0039 / 0050] validation loss: 	0.39735
starting train epoch 39
 epoch [0039 / 0050] [0009/280] eta: 0 Days 0:15:25        lr: 	1.0000E-06 loss: 	0.24626 loss align 0.0000
 epoch [0039 / 0050] [0109/280] eta: 0 Days 0:14:53        lr: 	1.0000E-06 loss: 	0.25533 loss align 0.0000
 epoch [0039 / 0050] [0209/280] eta: 0 Days 0:14:21        lr: 	1.0000E-06 loss: 	0.24365 loss align 0.0000
40
starting val epoch 40
val [0040 / 0050] validation loss: 	0.39622
starting train epoch 40
 epoch [0040 / 0050] [0009/280] eta: 0 Days 0:13:59        lr: 	1.0000E-06 loss: 	0.23301 loss align 0.0000
 epoch [0040 / 0050] [0109/280] eta: 0 Days 0:13:28        lr: 	1.0000E-06 loss: 	0.24668 loss align 0.0000
 epoch [0040 / 0050] [0209/280] eta: 0 Days 0:12:57        lr: 	1.0000E-06 loss: 	0.24751 loss align 0.0000
41
starting val epoch 41
val [0041 / 0050] validation loss: 	0.42616
starting train epoch 41
 epoch [0041 / 0050] [0009/280] eta: 0 Days 0:12:35        lr: 	1.0000E-06 loss: 	0.25278 loss align 0.0000
 epoch [0041 / 0050] [0109/280] eta: 0 Days 0:12:3         lr: 	1.0000E-06 loss: 	0.24121 loss align 0.0000
 epoch [0041 / 0050] [0209/280] eta: 0 Days 0:11:32        lr: 	1.0000E-06 loss: 	0.23921 loss align 0.0000
42
starting val epoch 42
val [0042 / 0050] validation loss: 	0.40210
starting train epoch 42
 epoch [0042 / 0050] [0009/280] eta: 0 Days 0:11:10        lr: 	1.0000E-06 loss: 	0.21469 loss align 0.0000
 epoch [0042 / 0050] [0109/280] eta: 0 Days 0:10:38        lr: 	1.0000E-06 loss: 	0.23834 loss align 0.0000
 epoch [0042 / 0050] [0209/280] eta: 0 Days 0:10:8         lr: 	1.0000E-06 loss: 	0.24286 loss align 0.0000
43
starting val epoch 43
val [0043 / 0050] validation loss: 	0.40596
starting train epoch 43
 epoch [0043 / 0050] [0009/280] eta: 0 Days 0:9:45         lr: 	1.0000E-06 loss: 	0.25557 loss align 0.0000
 epoch [0043 / 0050] [0109/280] eta: 0 Days 0:9:14         lr: 	1.0000E-06 loss: 	0.20888 loss align 0.0000
 epoch [0043 / 0050] [0209/280] eta: 0 Days 0:8:43         lr: 	1.0000E-06 loss: 	0.23405 loss align 0.0000
44
starting val epoch 44
val [0044 / 0050] validation loss: 	0.41320
starting train epoch 44
 epoch [0044 / 0050] [0009/280] eta: 0 Days 0:8:20         lr: 	1.0000E-06 loss: 	0.25503 loss align 0.0000
 epoch [0044 / 0050] [0109/280] eta: 0 Days 0:7:50         lr: 	1.0000E-06 loss: 	0.22598 loss align 0.0000
 epoch [0044 / 0050] [0209/280] eta: 0 Days 0:7:19         lr: 	1.0000E-06 loss: 	0.23956 loss align 0.0000
45
starting val epoch 45
val [0045 / 0050] validation loss: 	0.41828
starting train epoch 45
 epoch [0045 / 0050] [0009/280] eta: 0 Days 0:6:56         lr: 	1.0000E-06 loss: 	0.33652 loss align 0.0000
 epoch [0045 / 0050] [0109/280] eta: 0 Days 0:6:26         lr: 	1.0000E-06 loss: 	0.24083 loss align 0.0000
 epoch [0045 / 0050] [0209/280] eta: 0 Days 0:5:55         lr: 	1.0000E-06 loss: 	0.23049 loss align 0.0000
46
starting val epoch 46
val [0046 / 0050] validation loss: 	0.41481
starting val epoch 0
val [0000 / 0050] validation loss: 	0.41939
Acute and unspecified renal failure                                                        & 0.762(0.802, 0.723) & 0.424 (0.489, 0.356)
fused_ehr test  0   best mean auc :0.762 mean auprc 0.424
                    CI AUROC (0.723, 0.802) CI AUPRC (0.356, 0.489)
                     AUROC accute 0.762 mixed 0.762 chronic 0.762
                     AUROC accute CI (0.723, 0.802) mixed (0.723 , 0.802) chronic (0.723, 0.802)
                     AUPRC accute  0.424 mixed 0.424 chronic 0.424
                     AUPRC accute CI  (0.356, 0.489) mixed (0.356,  0.489) chronic (0.356, 0.489)