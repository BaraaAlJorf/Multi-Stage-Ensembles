Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
==> training
Running unimodal pretraining for modality RR
0
Starting val epoch 0
val [0000 / 0050] validation loss: 	0.66053
checkpoint
Starting train epoch 0
 epoch [0000 / 0050] [0099/1017] eta: 0 Days 9:48:20        lr: 	1.0000E-06 loss: 	0.51083
 epoch [0000 / 0050] [0199/1017] eta: 0 Days 6:55:33        lr: 	1.0000E-06 loss: 	0.45424
 epoch [0000 / 0050] [0299/1017] eta: 0 Days 5:59:21        lr: 	1.0000E-06 loss: 	0.43625
 epoch [0000 / 0050] [0399/1017] eta: 0 Days 5:30:7         lr: 	1.0000E-06 loss: 	0.42301
 epoch [0000 / 0050] [0499/1017] eta: 0 Days 5:12:56        lr: 	1.0000E-06 loss: 	0.41562
 epoch [0000 / 0050] [0599/1017] eta: 0 Days 5:0:33         lr: 	1.0000E-06 loss: 	0.41046
 epoch [0000 / 0050] [0699/1017] eta: 0 Days 4:52:0         lr: 	1.0000E-06 loss: 	0.40540
 epoch [0000 / 0050] [0799/1017] eta: 0 Days 4:45:12        lr: 	1.0000E-06 loss: 	0.40542
 epoch [0000 / 0050] [0899/1017] eta: 0 Days 4:40:31        lr: 	1.0000E-06 loss: 	0.40250
 epoch [0000 / 0050] [0999/1017] eta: 0 Days 4:36:10        lr: 	1.0000E-06 loss: 	0.39990
1
Starting val epoch 1
val [0001 / 0050] validation loss: 	0.37859
checkpoint
Starting train epoch 1
 epoch [0001 / 0050] [0099/1017] eta: 0 Days 5:0:57         lr: 	1.0000E-06 loss: 	0.38058
 epoch [0001 / 0050] [0199/1017] eta: 0 Days 4:55:7         lr: 	1.0000E-06 loss: 	0.38271
 epoch [0001 / 0050] [0299/1017] eta: 0 Days 4:50:17        lr: 	1.0000E-06 loss: 	0.38348
 epoch [0001 / 0050] [0399/1017] eta: 0 Days 4:46:14        lr: 	1.0000E-06 loss: 	0.37917
 epoch [0001 / 0050] [0499/1017] eta: 0 Days 4:42:40        lr: 	1.0000E-06 loss: 	0.37450
 epoch [0001 / 0050] [0599/1017] eta: 0 Days 4:39:30        lr: 	1.0000E-06 loss: 	0.37808
 epoch [0001 / 0050] [0699/1017] eta: 0 Days 4:36:44        lr: 	1.0000E-06 loss: 	0.37930
 epoch [0001 / 0050] [0799/1017] eta: 0 Days 4:33:58        lr: 	1.0000E-06 loss: 	0.37722
 epoch [0001 / 0050] [0899/1017] eta: 0 Days 4:31:27        lr: 	1.0000E-06 loss: 	0.37821
 epoch [0001 / 0050] [0999/1017] eta: 0 Days 4:29:1         lr: 	1.0000E-06 loss: 	0.37956
2
Starting val epoch 2
val [0002 / 0050] validation loss: 	0.36373
checkpoint
Starting train epoch 2
 epoch [0002 / 0050] [0099/1017] eta: 0 Days 4:41:42        lr: 	1.0000E-06 loss: 	0.36577
 epoch [0002 / 0050] [0199/1017] eta: 0 Days 4:39:13        lr: 	1.0000E-06 loss: 	0.35637
 epoch [0002 / 0050] [0299/1017] eta: 0 Days 4:36:50        lr: 	1.0000E-06 loss: 	0.36851
 epoch [0002 / 0050] [0399/1017] eta: 0 Days 4:34:53        lr: 	1.0000E-06 loss: 	0.36576
 epoch [0002 / 0050] [0499/1017] eta: 0 Days 4:32:50        lr: 	1.0000E-06 loss: 	0.36344
 epoch [0002 / 0050] [0599/1017] eta: 0 Days 4:30:33        lr: 	1.0000E-06 loss: 	0.36406
 epoch [0002 / 0050] [0699/1017] eta: 0 Days 4:28:37        lr: 	1.0000E-06 loss: 	0.36548
 epoch [0002 / 0050] [0799/1017] eta: 0 Days 4:26:56        lr: 	1.0000E-06 loss: 	0.36269
 epoch [0002 / 0050] [0899/1017] eta: 0 Days 4:25:4         lr: 	1.0000E-06 loss: 	0.36625
 epoch [0002 / 0050] [0999/1017] eta: 0 Days 4:23:26        lr: 	1.0000E-06 loss: 	0.36528
3
Starting val epoch 3
val [0003 / 0050] validation loss: 	0.35327
checkpoint
Starting train epoch 3
 epoch [0003 / 0050] [0099/1017] eta: 0 Days 4:31:46        lr: 	1.0000E-06 loss: 	0.37282
 epoch [0003 / 0050] [0199/1017] eta: 0 Days 4:29:48        lr: 	1.0000E-06 loss: 	0.37154
 epoch [0003 / 0050] [0299/1017] eta: 0 Days 4:28:6         lr: 	1.0000E-06 loss: 	0.36240
 epoch [0003 / 0050] [0399/1017] eta: 0 Days 4:26:22        lr: 	1.0000E-06 loss: 	0.36624
 epoch [0003 / 0050] [0499/1017] eta: 0 Days 4:24:47        lr: 	1.0000E-06 loss: 	0.36339
 epoch [0003 / 0050] [0599/1017] eta: 0 Days 4:23:17        lr: 	1.0000E-06 loss: 	0.36337
 epoch [0003 / 0050] [0699/1017] eta: 0 Days 4:21:51        lr: 	1.0000E-06 loss: 	0.36204
 epoch [0003 / 0050] [0799/1017] eta: 0 Days 4:20:31        lr: 	1.0000E-06 loss: 	0.36119
 epoch [0003 / 0050] [0899/1017] eta: 0 Days 4:19:9         lr: 	1.0000E-06 loss: 	0.35711
 epoch [0003 / 0050] [0999/1017] eta: 0 Days 4:17:47        lr: 	1.0000E-06 loss: 	0.35532
4
Starting val epoch 4
val [0004 / 0050] validation loss: 	0.35214
checkpoint
Starting train epoch 4
 epoch [0004 / 0050] [0099/1017] eta: 0 Days 4:23:37        lr: 	1.0000E-06 loss: 	0.34407
 epoch [0004 / 0050] [0199/1017] eta: 0 Days 4:22:6         lr: 	1.0000E-06 loss: 	0.35751
 epoch [0004 / 0050] [0299/1017] eta: 0 Days 4:20:42        lr: 	1.0000E-06 loss: 	0.35709
 epoch [0004 / 0050] [0399/1017] eta: 0 Days 4:19:18        lr: 	1.0000E-06 loss: 	0.35290
 epoch [0004 / 0050] [0499/1017] eta: 0 Days 4:17:59        lr: 	1.0000E-06 loss: 	0.35028
 epoch [0004 / 0050] [0599/1017] eta: 0 Days 4:16:50        lr: 	1.0000E-06 loss: 	0.34798
 epoch [0004 / 0050] [0699/1017] eta: 0 Days 4:15:35        lr: 	1.0000E-06 loss: 	0.34501
 epoch [0004 / 0050] [0799/1017] eta: 0 Days 4:14:29        lr: 	1.0000E-06 loss: 	0.34822
 epoch [0004 / 0050] [0899/1017] eta: 0 Days 4:13:23        lr: 	1.0000E-06 loss: 	0.34740
 epoch [0004 / 0050] [0999/1017] eta: 0 Days 4:12:24        lr: 	1.0000E-06 loss: 	0.34705
5
Starting val epoch 5
val [0005 / 0050] validation loss: 	0.34752
checkpoint
Starting train epoch 5
 epoch [0005 / 0050] [0099/1017] eta: 0 Days 4:16:55        lr: 	1.0000E-06 loss: 	0.35315
 epoch [0005 / 0050] [0199/1017] eta: 0 Days 4:15:48        lr: 	1.0000E-06 loss: 	0.34993
 epoch [0005 / 0050] [0299/1017] eta: 0 Days 4:14:42        lr: 	1.0000E-06 loss: 	0.34322
 epoch [0005 / 0050] [0399/1017] eta: 0 Days 4:13:30        lr: 	1.0000E-06 loss: 	0.34368
 epoch [0005 / 0050] [0499/1017] eta: 0 Days 4:12:23        lr: 	1.0000E-06 loss: 	0.34447
 epoch [0005 / 0050] [0599/1017] eta: 0 Days 4:11:14        lr: 	1.0000E-06 loss: 	0.34423
 epoch [0005 / 0050] [0699/1017] eta: 0 Days 4:10:3         lr: 	1.0000E-06 loss: 	0.34246
 epoch [0005 / 0050] [0799/1017] eta: 0 Days 4:8:55         lr: 	1.0000E-06 loss: 	0.33977
 epoch [0005 / 0050] [0899/1017] eta: 0 Days 4:7:51         lr: 	1.0000E-06 loss: 	0.34174
 epoch [0005 / 0050] [0999/1017] eta: 0 Days 4:6:51         lr: 	1.0000E-06 loss: 	0.33931
6
Starting val epoch 6
val [0006 / 0050] validation loss: 	0.34497
checkpoint
Starting train epoch 6
 epoch [0006 / 0050] [0099/1017] eta: 0 Days 4:10:26        lr: 	1.0000E-06 loss: 	0.33707
 epoch [0006 / 0050] [0199/1017] eta: 0 Days 4:9:17         lr: 	1.0000E-06 loss: 	0.33470
 epoch [0006 / 0050] [0299/1017] eta: 0 Days 4:8:13         lr: 	1.0000E-06 loss: 	0.33558
 epoch [0006 / 0050] [0399/1017] eta: 0 Days 4:7:10         lr: 	1.0000E-06 loss: 	0.33591
 epoch [0006 / 0050] [0499/1017] eta: 0 Days 4:6:11         lr: 	1.0000E-06 loss: 	0.33772
 epoch [0006 / 0050] [0599/1017] eta: 0 Days 4:5:13         lr: 	1.0000E-06 loss: 	0.33504
 epoch [0006 / 0050] [0699/1017] eta: 0 Days 4:4:17         lr: 	1.0000E-06 loss: 	0.33478
 epoch [0006 / 0050] [0799/1017] eta: 0 Days 4:3:18         lr: 	1.0000E-06 loss: 	0.33400
 epoch [0006 / 0050] [0899/1017] eta: 0 Days 4:2:20         lr: 	1.0000E-06 loss: 	0.33471
 epoch [0006 / 0050] [0999/1017] eta: 0 Days 4:1:20         lr: 	1.0000E-06 loss: 	0.33268
7
Starting val epoch 7
val [0007 / 0050] validation loss: 	0.35300
checkpoint
Starting train epoch 7
 epoch [0007 / 0050] [0099/1017] eta: 0 Days 4:4:13         lr: 	1.0000E-06 loss: 	0.32998
 epoch [0007 / 0050] [0199/1017] eta: 0 Days 4:3:13         lr: 	1.0000E-06 loss: 	0.32756
 epoch [0007 / 0050] [0299/1017] eta: 0 Days 4:2:16         lr: 	1.0000E-06 loss: 	0.33225
 epoch [0007 / 0050] [0399/1017] eta: 0 Days 4:1:18         lr: 	1.0000E-06 loss: 	0.32732
 epoch [0007 / 0050] [0499/1017] eta: 0 Days 4:0:18         lr: 	1.0000E-06 loss: 	0.32531
 epoch [0007 / 0050] [0599/1017] eta: 0 Days 3:59:23        lr: 	1.0000E-06 loss: 	0.32416
 epoch [0007 / 0050] [0699/1017] eta: 0 Days 3:58:26        lr: 	1.0000E-06 loss: 	0.32463
 epoch [0007 / 0050] [0799/1017] eta: 0 Days 3:57:30        lr: 	1.0000E-06 loss: 	0.32852
 epoch [0007 / 0050] [0899/1017] eta: 0 Days 3:56:33        lr: 	1.0000E-06 loss: 	0.32567
 epoch [0007 / 0050] [0999/1017] eta: 0 Days 3:55:38        lr: 	1.0000E-06 loss: 	0.32665
8
Starting val epoch 8
val [0008 / 0050] validation loss: 	0.34366
checkpoint
Starting train epoch 8
 epoch [0008 / 0050] [0099/1017] eta: 0 Days 3:57:58        lr: 	1.0000E-06 loss: 	0.31411
 epoch [0008 / 0050] [0199/1017] eta: 0 Days 3:57:2         lr: 	1.0000E-06 loss: 	0.31525
 epoch [0008 / 0050] [0299/1017] eta: 0 Days 3:56:10        lr: 	1.0000E-06 loss: 	0.31753
 epoch [0008 / 0050] [0399/1017] eta: 0 Days 3:55:14        lr: 	1.0000E-06 loss: 	0.31805
 epoch [0008 / 0050] [0499/1017] eta: 0 Days 3:54:16        lr: 	1.0000E-06 loss: 	0.31892
 epoch [0008 / 0050] [0599/1017] eta: 0 Days 3:53:22        lr: 	1.0000E-06 loss: 	0.31846
 epoch [0008 / 0050] [0699/1017] eta: 0 Days 3:52:28        lr: 	1.0000E-06 loss: 	0.32124
 epoch [0008 / 0050] [0799/1017] eta: 0 Days 3:51:37        lr: 	1.0000E-06 loss: 	0.32010
 epoch [0008 / 0050] [0899/1017] eta: 0 Days 3:50:42        lr: 	1.0000E-06 loss: 	0.31898
 epoch [0008 / 0050] [0999/1017] eta: 0 Days 3:49:52        lr: 	1.0000E-06 loss: 	0.31976
9
Starting val epoch 9
val [0009 / 0050] validation loss: 	0.36943
Starting train epoch 9
 epoch [0009 / 0050] [0099/1017] eta: 0 Days 3:51:41        lr: 	1.0000E-06 loss: 	0.33106
 epoch [0009 / 0050] [0199/1017] eta: 0 Days 3:50:50        lr: 	1.0000E-06 loss: 	0.32022
 epoch [0009 / 0050] [0299/1017] eta: 0 Days 3:49:58        lr: 	1.0000E-06 loss: 	0.30574
 epoch [0009 / 0050] [0399/1017] eta: 0 Days 3:49:6         lr: 	1.0000E-06 loss: 	0.30903
 epoch [0009 / 0050] [0499/1017] eta: 0 Days 3:48:14        lr: 	1.0000E-06 loss: 	0.30889
 epoch [0009 / 0050] [0599/1017] eta: 0 Days 3:47:23        lr: 	1.0000E-06 loss: 	0.31007
 epoch [0009 / 0050] [0699/1017] eta: 0 Days 3:46:31        lr: 	1.0000E-06 loss: 	0.31281
 epoch [0009 / 0050] [0799/1017] eta: 0 Days 3:45:43        lr: 	1.0000E-06 loss: 	0.31105
 epoch [0009 / 0050] [0899/1017] eta: 0 Days 3:44:55        lr: 	1.0000E-06 loss: 	0.31142
 epoch [0009 / 0050] [0999/1017] eta: 0 Days 3:44:6         lr: 	1.0000E-06 loss: 	0.31290
10
Starting val epoch 10
val [0010 / 0050] validation loss: 	0.34610
checkpoint
Starting train epoch 10
 epoch [0010 / 0050] [0099/1017] eta: 0 Days 3:45:47        lr: 	1.0000E-06 loss: 	0.30874
 epoch [0010 / 0050] [0199/1017] eta: 0 Days 3:45:2         lr: 	1.0000E-06 loss: 	0.31883
 epoch [0010 / 0050] [0299/1017] eta: 0 Days 3:44:16        lr: 	1.0000E-06 loss: 	0.32254
 epoch [0010 / 0050] [0399/1017] eta: 0 Days 3:43:29        lr: 	1.0000E-06 loss: 	0.31892
 epoch [0010 / 0050] [0499/1017] eta: 0 Days 3:42:44        lr: 	1.0000E-06 loss: 	0.31629
 epoch [0010 / 0050] [0599/1017] eta: 0 Days 3:41:56        lr: 	1.0000E-06 loss: 	0.31082
 epoch [0010 / 0050] [0699/1017] eta: 0 Days 3:41:8         lr: 	1.0000E-06 loss: 	0.30949
 epoch [0010 / 0050] [0799/1017] eta: 0 Days 3:40:19        lr: 	1.0000E-06 loss: 	0.31021
 epoch [0010 / 0050] [0899/1017] eta: 0 Days 3:39:31        lr: 	1.0000E-06 loss: 	0.30774
 epoch [0010 / 0050] [0999/1017] eta: 0 Days 3:38:42        lr: 	1.0000E-06 loss: 	0.30694
11
Starting val epoch 11
val [0011 / 0050] validation loss: 	0.35084
Starting train epoch 11
 epoch [0011 / 0050] [0099/1017] eta: 0 Days 3:40:0         lr: 	1.0000E-06 loss: 	0.29295
 epoch [0011 / 0050] [0199/1017] eta: 0 Days 3:39:11        lr: 	1.0000E-06 loss: 	0.29516
 epoch [0011 / 0050] [0299/1017] eta: 0 Days 3:38:26        lr: 	1.0000E-06 loss: 	0.29110
 epoch [0011 / 0050] [0399/1017] eta: 0 Days 3:37:39        lr: 	1.0000E-06 loss: 	0.29754
 epoch [0011 / 0050] [0499/1017] eta: 0 Days 3:36:51        lr: 	1.0000E-06 loss: 	0.29939
 epoch [0011 / 0050] [0599/1017] eta: 0 Days 3:36:5         lr: 	1.0000E-06 loss: 	0.29908
 epoch [0011 / 0050] [0699/1017] eta: 0 Days 3:35:17        lr: 	1.0000E-06 loss: 	0.29962
 epoch [0011 / 0050] [0799/1017] eta: 0 Days 3:34:32        lr: 	1.0000E-06 loss: 	0.29872
 epoch [0011 / 0050] [0899/1017] eta: 0 Days 3:33:48        lr: 	1.0000E-06 loss: 	0.30094
 epoch [0011 / 0050] [0999/1017] eta: 0 Days 3:33:2         lr: 	1.0000E-06 loss: 	0.30115
12
Starting val epoch 12
val [0012 / 0050] validation loss: 	0.36784
Starting train epoch 12
 epoch [0012 / 0050] [0099/1017] eta: 0 Days 3:34:3         lr: 	1.0000E-06 loss: 	0.30182
 epoch [0012 / 0050] [0199/1017] eta: 0 Days 3:33:17        lr: 	1.0000E-06 loss: 	0.29574
 epoch [0012 / 0050] [0299/1017] eta: 0 Days 3:32:29        lr: 	1.0000E-06 loss: 	0.28018
 epoch [0012 / 0050] [0399/1017] eta: 0 Days 3:31:41        lr: 	1.0000E-06 loss: 	0.28998
 epoch [0012 / 0050] [0499/1017] eta: 0 Days 3:30:56        lr: 	1.0000E-06 loss: 	0.29111
 epoch [0012 / 0050] [0599/1017] eta: 0 Days 3:30:12        lr: 	1.0000E-06 loss: 	0.29232
 epoch [0012 / 0050] [0699/1017] eta: 0 Days 3:29:28        lr: 	1.0000E-06 loss: 	0.29117
 epoch [0012 / 0050] [0799/1017] eta: 0 Days 3:28:43        lr: 	1.0000E-06 loss: 	0.29344
 epoch [0012 / 0050] [0899/1017] eta: 0 Days 3:27:59        lr: 	1.0000E-06 loss: 	0.29366
 epoch [0012 / 0050] [0999/1017] eta: 0 Days 3:27:13        lr: 	1.0000E-06 loss: 	0.29127
13
Starting val epoch 13
val [0013 / 0050] validation loss: 	0.36910
Starting train epoch 13
 epoch [0013 / 0050] [0099/1017] eta: 0 Days 3:28:4         lr: 	1.0000E-06 loss: 	0.26176
 epoch [0013 / 0050] [0199/1017] eta: 0 Days 3:27:18        lr: 	1.0000E-06 loss: 	0.27701
 epoch [0013 / 0050] [0299/1017] eta: 0 Days 3:26:32        lr: 	1.0000E-06 loss: 	0.28178
 epoch [0013 / 0050] [0399/1017] eta: 0 Days 3:25:48        lr: 	1.0000E-06 loss: 	0.28331
 epoch [0013 / 0050] [0499/1017] eta: 0 Days 3:25:3         lr: 	1.0000E-06 loss: 	0.27932
 epoch [0013 / 0050] [0599/1017] eta: 0 Days 3:24:19        lr: 	1.0000E-06 loss: 	0.28233
 epoch [0013 / 0050] [0699/1017] eta: 0 Days 3:23:35        lr: 	1.0000E-06 loss: 	0.28070
 epoch [0013 / 0050] [0799/1017] eta: 0 Days 3:22:52        lr: 	1.0000E-06 loss: 	0.28207
 epoch [0013 / 0050] [0899/1017] eta: 0 Days 3:22:7         lr: 	1.0000E-06 loss: 	0.28228
 epoch [0013 / 0050] [0999/1017] eta: 0 Days 3:21:24        lr: 	1.0000E-06 loss: 	0.28367
14
Starting val epoch 14
val [0014 / 0050] validation loss: 	0.38679
Starting train epoch 14
 epoch [0014 / 0050] [0099/1017] eta: 0 Days 3:22:8         lr: 	1.0000E-06 loss: 	0.28421
 epoch [0014 / 0050] [0199/1017] eta: 0 Days 3:21:26        lr: 	1.0000E-06 loss: 	0.29894
 epoch [0014 / 0050] [0299/1017] eta: 0 Days 3:20:43        lr: 	1.0000E-06 loss: 	0.28990
 epoch [0014 / 0050] [0399/1017] eta: 0 Days 3:19:59        lr: 	1.0000E-06 loss: 	0.27997
 epoch [0014 / 0050] [0499/1017] eta: 0 Days 3:19:15        lr: 	1.0000E-06 loss: 	0.27922
 epoch [0014 / 0050] [0599/1017] eta: 0 Days 3:18:32        lr: 	1.0000E-06 loss: 	0.27558
 epoch [0014 / 0050] [0699/1017] eta: 0 Days 3:17:49        lr: 	1.0000E-06 loss: 	0.27941
 epoch [0014 / 0050] [0799/1017] eta: 0 Days 3:17:7         lr: 	1.0000E-06 loss: 	0.27844
 epoch [0014 / 0050] [0899/1017] eta: 0 Days 3:16:24        lr: 	1.0000E-06 loss: 	0.27803
 epoch [0014 / 0050] [0999/1017] eta: 0 Days 3:15:42        lr: 	1.0000E-06 loss: 	0.27596
15
Starting val epoch 15
val [0015 / 0050] validation loss: 	0.39554
Starting train epoch 15
 epoch [0015 / 0050] [0099/1017] eta: 0 Days 3:16:20        lr: 	1.0000E-06 loss: 	0.27999
 epoch [0015 / 0050] [0199/1017] eta: 0 Days 3:15:37        lr: 	1.0000E-06 loss: 	0.27990
 epoch [0015 / 0050] [0299/1017] eta: 0 Days 3:14:56        lr: 	1.0000E-06 loss: 	0.27300
 epoch [0015 / 0050] [0399/1017] eta: 0 Days 3:14:15        lr: 	1.0000E-06 loss: 	0.27137
 epoch [0015 / 0050] [0499/1017] eta: 0 Days 3:13:33        lr: 	1.0000E-06 loss: 	0.27279
 epoch [0015 / 0050] [0599/1017] eta: 0 Days 3:12:53        lr: 	1.0000E-06 loss: 	0.27417
 epoch [0015 / 0050] [0699/1017] eta: 0 Days 3:12:11        lr: 	1.0000E-06 loss: 	0.27060
 epoch [0015 / 0050] [0799/1017] eta: 0 Days 3:11:29        lr: 	1.0000E-06 loss: 	0.27120
 epoch [0015 / 0050] [0899/1017] eta: 0 Days 3:10:47        lr: 	1.0000E-06 loss: 	0.26857
 epoch [0015 / 0050] [0999/1017] eta: 0 Days 3:10:5         lr: 	1.0000E-06 loss: 	0.26951
16
Starting val epoch 16
val [0016 / 0050] validation loss: 	0.38304
Starting train epoch 16
 epoch [0016 / 0050] [0099/1017] eta: 0 Days 3:10:35        lr: 	1.0000E-06 loss: 	0.24932
 epoch [0016 / 0050] [0199/1017] eta: 0 Days 3:9:54         lr: 	1.0000E-06 loss: 	0.24821
 epoch [0016 / 0050] [0299/1017] eta: 0 Days 3:9:12         lr: 	1.0000E-06 loss: 	0.25947
 epoch [0016 / 0050] [0399/1017] eta: 0 Days 3:8:32         lr: 	1.0000E-06 loss: 	0.26359
 epoch [0016 / 0050] [0499/1017] eta: 0 Days 3:7:50         lr: 	1.0000E-06 loss: 	0.25716
 epoch [0016 / 0050] [0599/1017] eta: 0 Days 3:7:9          lr: 	1.0000E-06 loss: 	0.25897
 epoch [0016 / 0050] [0699/1017] eta: 0 Days 3:6:28         lr: 	1.0000E-06 loss: 	0.25705
 epoch [0016 / 0050] [0799/1017] eta: 0 Days 3:5:47         lr: 	1.0000E-06 loss: 	0.25950
 epoch [0016 / 0050] [0899/1017] eta: 0 Days 3:5:7          lr: 	1.0000E-06 loss: 	0.25958
 epoch [0016 / 0050] [0999/1017] eta: 0 Days 3:4:27         lr: 	1.0000E-06 loss: 	0.26007
17
Starting val epoch 17
val [0017 / 0050] validation loss: 	0.40751
Starting train epoch 17
 epoch [0017 / 0050] [0099/1017] eta: 0 Days 3:4:51         lr: 	1.0000E-06 loss: 	0.27141
 epoch [0017 / 0050] [0199/1017] eta: 0 Days 3:4:11         lr: 	1.0000E-06 loss: 	0.25635
 epoch [0017 / 0050] [0299/1017] eta: 0 Days 3:3:30         lr: 	1.0000E-06 loss: 	0.25428
 epoch [0017 / 0050] [0399/1017] eta: 0 Days 3:2:49         lr: 	1.0000E-06 loss: 	0.25657
 epoch [0017 / 0050] [0499/1017] eta: 0 Days 3:2:9          lr: 	1.0000E-06 loss: 	0.25280
 epoch [0017 / 0050] [0599/1017] eta: 0 Days 3:1:27         lr: 	1.0000E-06 loss: 	0.25295
 epoch [0017 / 0050] [0699/1017] eta: 0 Days 3:0:48         lr: 	1.0000E-06 loss: 	0.25389
 epoch [0017 / 0050] [0799/1017] eta: 0 Days 3:0:6          lr: 	1.0000E-06 loss: 	0.25442
 epoch [0017 / 0050] [0899/1017] eta: 0 Days 2:59:26        lr: 	1.0000E-06 loss: 	0.25366
 epoch [0017 / 0050] [0999/1017] eta: 0 Days 2:58:47        lr: 	1.0000E-06 loss: 	0.25433
18
Starting val epoch 18
val [0018 / 0050] validation loss: 	0.41728
Starting train epoch 18
 epoch [0018 / 0050] [0099/1017] eta: 0 Days 2:59:6         lr: 	1.0000E-06 loss: 	0.22674
 epoch [0018 / 0050] [0199/1017] eta: 0 Days 2:58:26        lr: 	1.0000E-06 loss: 	0.23656
 epoch [0018 / 0050] [0299/1017] eta: 0 Days 2:57:47        lr: 	1.0000E-06 loss: 	0.24237
 epoch [0018 / 0050] [0399/1017] eta: 0 Days 2:57:8         lr: 	1.0000E-06 loss: 	0.24473
 epoch [0018 / 0050] [0499/1017] eta: 0 Days 2:56:27        lr: 	1.0000E-06 loss: 	0.23665
 epoch [0018 / 0050] [0599/1017] eta: 0 Days 2:55:48        lr: 	1.0000E-06 loss: 	0.24073
 epoch [0018 / 0050] [0699/1017] eta: 0 Days 2:55:8         lr: 	1.0000E-06 loss: 	0.24149
 epoch [0018 / 0050] [0799/1017] eta: 0 Days 2:54:28        lr: 	1.0000E-06 loss: 	0.24098
 epoch [0018 / 0050] [0899/1017] eta: 0 Days 2:53:48        lr: 	1.0000E-06 loss: 	0.24243
 epoch [0018 / 0050] [0999/1017] eta: 0 Days 2:53:8         lr: 	1.0000E-06 loss: 	0.24358
19
Starting val epoch 19
val [0019 / 0050] validation loss: 	0.42410
Starting train epoch 19
 epoch [0019 / 0050] [0099/1017] eta: 0 Days 2:53:22        lr: 	1.0000E-06 loss: 	0.23628
 epoch [0019 / 0050] [0199/1017] eta: 0 Days 2:52:42        lr: 	1.0000E-06 loss: 	0.23013
 epoch [0019 / 0050] [0299/1017] eta: 0 Days 2:52:3         lr: 	1.0000E-06 loss: 	0.24252
 epoch [0019 / 0050] [0399/1017] eta: 0 Days 2:51:23        lr: 	1.0000E-06 loss: 	0.23766
 epoch [0019 / 0050] [0499/1017] eta: 0 Days 2:50:44        lr: 	1.0000E-06 loss: 	0.23468
 epoch [0019 / 0050] [0599/1017] eta: 0 Days 2:50:4         lr: 	1.0000E-06 loss: 	0.23418
 epoch [0019 / 0050] [0699/1017] eta: 0 Days 2:49:25        lr: 	1.0000E-06 loss: 	0.23615
 epoch [0019 / 0050] [0799/1017] eta: 0 Days 2:48:46        lr: 	1.0000E-06 loss: 	0.23479
 epoch [0019 / 0050] [0899/1017] eta: 0 Days 2:48:6         lr: 	1.0000E-06 loss: 	0.23425
 epoch [0019 / 0050] [0999/1017] eta: 0 Days 2:47:28        lr: 	1.0000E-06 loss: 	0.23498
20
Starting val epoch 20
val [0020 / 0050] validation loss: 	0.46096
Starting train epoch 20
 epoch [0020 / 0050] [0099/1017] eta: 0 Days 2:47:39        lr: 	1.0000E-06 loss: 	0.22415
 epoch [0020 / 0050] [0199/1017] eta: 0 Days 2:47:0         lr: 	1.0000E-06 loss: 	0.22656
 epoch [0020 / 0050] [0299/1017] eta: 0 Days 2:46:22        lr: 	1.0000E-06 loss: 	0.22390
 epoch [0020 / 0050] [0399/1017] eta: 0 Days 2:45:43        lr: 	1.0000E-06 loss: 	0.22282
 epoch [0020 / 0050] [0499/1017] eta: 0 Days 2:45:5         lr: 	1.0000E-06 loss: 	0.22280
 epoch [0020 / 0050] [0599/1017] eta: 0 Days 2:44:28        lr: 	1.0000E-06 loss: 	0.22135
 epoch [0020 / 0050] [0699/1017] eta: 0 Days 2:43:50        lr: 	1.0000E-06 loss: 	0.22544
 epoch [0020 / 0050] [0799/1017] eta: 0 Days 2:43:11        lr: 	1.0000E-06 loss: 	0.22631
 epoch [0020 / 0050] [0899/1017] eta: 0 Days 2:42:33        lr: 	1.0000E-06 loss: 	0.22676
 epoch [0020 / 0050] [0999/1017] eta: 0 Days 2:41:54        lr: 	1.0000E-06 loss: 	0.22737
21
Starting val epoch 21
val [0021 / 0050] validation loss: 	0.49106
Starting train epoch 21
 epoch [0021 / 0050] [0099/1017] eta: 0 Days 2:42:0         lr: 	1.0000E-06 loss: 	0.20635
 epoch [0021 / 0050] [0199/1017] eta: 0 Days 2:41:20        lr: 	1.0000E-06 loss: 	0.21154
 epoch [0021 / 0050] [0299/1017] eta: 0 Days 2:40:42        lr: 	1.0000E-06 loss: 	0.22007
 epoch [0021 / 0050] [0399/1017] eta: 0 Days 2:40:4         lr: 	1.0000E-06 loss: 	0.21841
 epoch [0021 / 0050] [0499/1017] eta: 0 Days 2:39:26        lr: 	1.0000E-06 loss: 	0.22028
 epoch [0021 / 0050] [0599/1017] eta: 0 Days 2:38:49        lr: 	1.0000E-06 loss: 	0.21665
 epoch [0021 / 0050] [0699/1017] eta: 0 Days 2:38:11        lr: 	1.0000E-06 loss: 	0.21766
 epoch [0021 / 0050] [0799/1017] eta: 0 Days 2:37:33        lr: 	1.0000E-06 loss: 	0.21780
 epoch [0021 / 0050] [0899/1017] eta: 0 Days 2:36:55        lr: 	1.0000E-06 loss: 	0.21745
 epoch [0021 / 0050] [0999/1017] eta: 0 Days 2:36:17        lr: 	1.0000E-06 loss: 	0.21731
22
Starting val epoch 22
val [0022 / 0050] validation loss: 	0.49818
Starting train epoch 22
 epoch [0022 / 0050] [0099/1017] eta: 0 Days 2:36:21        lr: 	1.0000E-06 loss: 	0.21563
 epoch [0022 / 0050] [0199/1017] eta: 0 Days 2:35:42        lr: 	1.0000E-06 loss: 	0.22240
 epoch [0022 / 0050] [0299/1017] eta: 0 Days 2:35:5         lr: 	1.0000E-06 loss: 	0.21342
 epoch [0022 / 0050] [0399/1017] eta: 0 Days 2:34:27        lr: 	1.0000E-06 loss: 	0.20471
 epoch [0022 / 0050] [0499/1017] eta: 0 Days 2:33:50        lr: 	1.0000E-06 loss: 	0.20360
 epoch [0022 / 0050] [0599/1017] eta: 0 Days 2:33:12        lr: 	1.0000E-06 loss: 	0.19906
 epoch [0022 / 0050] [0699/1017] eta: 0 Days 2:32:34        lr: 	1.0000E-06 loss: 	0.20083
 epoch [0022 / 0050] [0799/1017] eta: 0 Days 2:31:56        lr: 	1.0000E-06 loss: 	0.20245
 epoch [0022 / 0050] [0899/1017] eta: 0 Days 2:31:18        lr: 	1.0000E-06 loss: 	0.20537
 epoch [0022 / 0050] [0999/1017] eta: 0 Days 2:30:40        lr: 	1.0000E-06 loss: 	0.20542
23
Starting val epoch 23
val [0023 / 0050] validation loss: 	0.48574
Starting train epoch 23
 epoch [0023 / 0050] [0099/1017] eta: 0 Days 2:30:40        lr: 	1.0000E-06 loss: 	0.19107
 epoch [0023 / 0050] [0199/1017] eta: 0 Days 2:30:3         lr: 	1.0000E-06 loss: 	0.19633
 epoch [0023 / 0050] [0299/1017] eta: 0 Days 2:29:26        lr: 	1.0000E-06 loss: 	0.19899
 epoch [0023 / 0050] [0399/1017] eta: 0 Days 2:28:48        lr: 	1.0000E-06 loss: 	0.19657
 epoch [0023 / 0050] [0499/1017] eta: 0 Days 2:28:11        lr: 	1.0000E-06 loss: 	0.19622
 epoch [0023 / 0050] [0599/1017] eta: 0 Days 2:27:33        lr: 	1.0000E-06 loss: 	0.20003
 epoch [0023 / 0050] [0699/1017] eta: 0 Days 2:26:56        lr: 	1.0000E-06 loss: 	0.19897
 epoch [0023 / 0050] [0799/1017] eta: 0 Days 2:26:18        lr: 	1.0000E-06 loss: 	0.20045
 epoch [0023 / 0050] [0899/1017] eta: 0 Days 2:25:41        lr: 	1.0000E-06 loss: 	0.20134
 epoch [0023 / 0050] [0999/1017] eta: 0 Days 2:25:6         lr: 	1.0000E-06 loss: 	0.19899
24
Starting val epoch 24
val [0024 / 0050] validation loss: 	0.51536
Starting train epoch 24
 epoch [0024 / 0050] [0099/1017] eta: 0 Days 2:25:2         lr: 	1.0000E-06 loss: 	0.17870
 epoch [0024 / 0050] [0199/1017] eta: 0 Days 2:24:25        lr: 	1.0000E-06 loss: 	0.18379
 epoch [0024 / 0050] [0299/1017] eta: 0 Days 2:23:48        lr: 	1.0000E-06 loss: 	0.18662
 epoch [0024 / 0050] [0399/1017] eta: 0 Days 2:23:11        lr: 	1.0000E-06 loss: 	0.18725
 epoch [0024 / 0050] [0499/1017] eta: 0 Days 2:22:34        lr: 	1.0000E-06 loss: 	0.18472
 epoch [0024 / 0050] [0599/1017] eta: 0 Days 2:21:57        lr: 	1.0000E-06 loss: 	0.18386
 epoch [0024 / 0050] [0699/1017] eta: 0 Days 2:21:19        lr: 	1.0000E-06 loss: 	0.18605
 epoch [0024 / 0050] [0799/1017] eta: 0 Days 2:20:42        lr: 	1.0000E-06 loss: 	0.18665
 epoch [0024 / 0050] [0899/1017] eta: 0 Days 2:20:5         lr: 	1.0000E-06 loss: 	0.18741
 epoch [0024 / 0050] [0999/1017] eta: 0 Days 2:19:28        lr: 	1.0000E-06 loss: 	0.18926
25
Starting val epoch 25
val [0025 / 0050] validation loss: 	0.50030
Starting val epoch 0
val [0000 / 0050] validation loss: 	0.34288
Acute and unspecified renal failure                                                        & 0.758(0.777, 0.738) & 0.299 (0.335, 0.268)
fused_ehr test  0   best mean auc :0.758 mean auprc 0.299
                    CI AUROC (0.738, 0.777) CI AUPRC (0.268, 0.335)
                     AUROC accute 0.758 mixed 0.758 chronic 0.758
                     AUROC accute CI (0.738, 0.777) mixed (0.738 , 0.777) chronic (0.738, 0.777)
                     AUPRC accute  0.299 mixed 0.299 chronic 0.299
                     AUPRC accute CI  (0.268, 0.335) mixed (0.268,  0.335) chronic (0.268, 0.335)