Running unimodal pretraining for modality CXR
0
Starting val epoch 0
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0000 / 0020] validation loss: 	0.50319
checkpoint
Starting train epoch 0
 epoch [0000 / 0020] [0099/280] eta: 0 Days 0:47:15        lr: 	1.0000E-06 loss: 	0.41079
 epoch [0000 / 0020] [0199/280] eta: 0 Days 0:34:57        lr: 	1.0000E-06 loss: 	0.42090
1
Starting val epoch 1
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0001 / 0020] validation loss: 	0.42472
checkpoint
Starting train epoch 1
 epoch [0001 / 0020] [0099/280] eta: 0 Days 0:32:13        lr: 	1.0000E-06 loss: 	0.41383
 epoch [0001 / 0020] [0199/280] eta: 0 Days 0:29:39        lr: 	1.0000E-06 loss: 	0.42058
2
Starting val epoch 2
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0002 / 0020] validation loss: 	0.41908
checkpoint
Starting train epoch 2
 epoch [0002 / 0020] [0099/280] eta: 0 Days 0:28:41        lr: 	1.0000E-06 loss: 	0.44008
 epoch [0002 / 0020] [0199/280] eta: 0 Days 0:27:11        lr: 	1.0000E-06 loss: 	0.41517
3
Starting val epoch 3
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0003 / 0020] validation loss: 	0.41533
checkpoint
Starting train epoch 3
 epoch [0003 / 0020] [0099/280] eta: 0 Days 0:26:22        lr: 	1.0000E-06 loss: 	0.42412
 epoch [0003 / 0020] [0199/280] eta: 0 Days 0:25:15        lr: 	1.0000E-06 loss: 	0.41553
4
Starting val epoch 4
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0004 / 0020] validation loss: 	0.41647
checkpoint
Starting train epoch 4
 epoch [0004 / 0020] [0099/280] eta: 0 Days 0:24:26        lr: 	1.0000E-06 loss: 	0.42406
 epoch [0004 / 0020] [0199/280] eta: 0 Days 0:23:29        lr: 	1.0000E-06 loss: 	0.41012
5
Starting val epoch 5
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0005 / 0020] validation loss: 	0.40582
checkpoint
Starting train epoch 5
 epoch [0005 / 0020] [0099/280] eta: 0 Days 0:22:41        lr: 	1.0000E-06 loss: 	0.38365
 epoch [0005 / 0020] [0199/280] eta: 0 Days 0:21:50        lr: 	1.0000E-06 loss: 	0.39039
6
Starting val epoch 6
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0006 / 0020] validation loss: 	0.40031
checkpoint
Starting train epoch 6
 epoch [0006 / 0020] [0099/280] eta: 0 Days 0:21:0         lr: 	1.0000E-06 loss: 	0.38349
 epoch [0006 / 0020] [0199/280] eta: 0 Days 0:20:14        lr: 	1.0000E-06 loss: 	0.39366
7
Starting val epoch 7
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0007 / 0020] validation loss: 	0.40026
checkpoint
Starting train epoch 7
 epoch [0007 / 0020] [0099/280] eta: 0 Days 0:19:22        lr: 	1.0000E-06 loss: 	0.41158
 epoch [0007 / 0020] [0199/280] eta: 0 Days 0:18:39        lr: 	1.0000E-06 loss: 	0.39748
8
Starting val epoch 8
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0008 / 0020] validation loss: 	0.39763
checkpoint
Starting train epoch 8
 epoch [0008 / 0020] [0099/280] eta: 0 Days 0:17:47        lr: 	1.0000E-06 loss: 	0.40692
 epoch [0008 / 0020] [0199/280] eta: 0 Days 0:17:6         lr: 	1.0000E-06 loss: 	0.39866
9
Starting val epoch 9
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0009 / 0020] validation loss: 	0.39339
checkpoint
Starting train epoch 9
 epoch [0009 / 0020] [0099/280] eta: 0 Days 0:16:13        lr: 	1.0000E-06 loss: 	0.36368
 epoch [0009 / 0020] [0199/280] eta: 0 Days 0:15:33        lr: 	1.0000E-06 loss: 	0.39030
10
Starting val epoch 10
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0010 / 0020] validation loss: 	0.39262
checkpoint
Starting train epoch 10
 epoch [0010 / 0020] [0099/280] eta: 0 Days 0:14:39        lr: 	1.0000E-06 loss: 	0.39883
 epoch [0010 / 0020] [0199/280] eta: 0 Days 0:14:1         lr: 	1.0000E-06 loss: 	0.39058
11
Starting val epoch 11
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0011 / 0020] validation loss: 	0.39269
checkpoint
Starting train epoch 11
 epoch [0011 / 0020] [0099/280] eta: 0 Days 0:13:7         lr: 	1.0000E-06 loss: 	0.38434
 epoch [0011 / 0020] [0199/280] eta: 0 Days 0:12:30        lr: 	1.0000E-06 loss: 	0.37571
12
Starting val epoch 12
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0012 / 0020] validation loss: 	0.39098
Starting train epoch 12
 epoch [0012 / 0020] [0099/280] eta: 0 Days 0:11:34        lr: 	1.0000E-06 loss: 	0.38221
 epoch [0012 / 0020] [0199/280] eta: 0 Days 0:10:58        lr: 	1.0000E-06 loss: 	0.37031
13
Starting val epoch 13
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0013 / 0020] validation loss: 	0.38991
checkpoint
Starting train epoch 13
 epoch [0013 / 0020] [0099/280] eta: 0 Days 0:10:3         lr: 	1.0000E-06 loss: 	0.35931
 epoch [0013 / 0020] [0199/280] eta: 0 Days 0:9:27         lr: 	1.0000E-06 loss: 	0.37536
14
Starting val epoch 14
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0014 / 0020] validation loss: 	0.38942
checkpoint
Starting train epoch 14
 epoch [0014 / 0020] [0099/280] eta: 0 Days 0:8:31         lr: 	1.0000E-06 loss: 	0.36816
 epoch [0014 / 0020] [0199/280] eta: 0 Days 0:7:57         lr: 	1.0000E-06 loss: 	0.37312
15
Starting val epoch 15
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0015 / 0020] validation loss: 	0.38946
Starting train epoch 15
 epoch [0015 / 0020] [0099/280] eta: 0 Days 0:7:0          lr: 	1.0000E-06 loss: 	0.37721
 epoch [0015 / 0020] [0199/280] eta: 0 Days 0:6:26         lr: 	1.0000E-06 loss: 	0.38315
16
Starting val epoch 16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0016 / 0020] validation loss: 	0.39076
Starting train epoch 16
 epoch [0016 / 0020] [0099/280] eta: 0 Days 0:5:29         lr: 	1.0000E-06 loss: 	0.39117
 epoch [0016 / 0020] [0199/280] eta: 0 Days 0:4:56         lr: 	1.0000E-06 loss: 	0.37384
17
Starting val epoch 17
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0017 / 0020] validation loss: 	0.38873
Starting train epoch 17
 epoch [0017 / 0020] [0099/280] eta: 0 Days 0:3:58         lr: 	1.0000E-06 loss: 	0.38541
 epoch [0017 / 0020] [0199/280] eta: 0 Days 0:3:25         lr: 	1.0000E-06 loss: 	0.37854
18
Starting val epoch 18
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0018 / 0020] validation loss: 	0.38981
checkpoint
Starting train epoch 18
 epoch [0018 / 0020] [0099/280] eta: 0 Days 0:2:28         lr: 	1.0000E-06 loss: 	0.38869
 epoch [0018 / 0020] [0199/280] eta: 0 Days 0:1:55         lr: 	1.0000E-06 loss: 	0.37445
19
Starting val epoch 19
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
8
val [0019 / 0020] validation loss: 	0.38815
Starting train epoch 19
 epoch [0019 / 0020] [0099/280] eta: 0 Days 0:0:58         lr: 	1.0000E-06 loss: 	0.39035
 epoch [0019 / 0020] [0199/280] eta: 0 Days 0:0:25         lr: 	1.0000E-06 loss: 	0.37092
Starting val epoch 0
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
16
10
val [0000 / 0020] validation loss: 	0.39807