Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type late
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.86368
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 12:42:46       lr: 	1.0000E-04 loss: 	0.51230
 epoch [0000 / 0050] [0109/267] eta: 0 Days 2:29:10        lr: 	1.0000E-04 loss: 	0.39742
 epoch [0000 / 0050] [0209/267] eta: 0 Days 1:59:24        lr: 	1.0000E-04 loss: 	0.36279
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.38294
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:4:8          lr: 	1.0000E-04 loss: 	0.44254
 epoch [0001 / 0050] [0109/267] eta: 0 Days 1:53:52        lr: 	1.0000E-04 loss: 	0.33412
 epoch [0001 / 0050] [0209/267] eta: 0 Days 1:47:13        lr: 	1.0000E-04 loss: 	0.34492
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.38342
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 1:50:25        lr: 	1.0000E-04 loss: 	0.35818
 epoch [0002 / 0050] [0109/267] eta: 0 Days 1:45:40        lr: 	1.0000E-04 loss: 	0.31971
 epoch [0002 / 0050] [0209/267] eta: 0 Days 1:42:2         lr: 	1.0000E-04 loss: 	0.32713
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.37662
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 1:43:23        lr: 	1.0000E-04 loss: 	0.29560
 epoch [0003 / 0050] [0109/267] eta: 0 Days 1:40:36        lr: 	1.0000E-04 loss: 	0.30960
 epoch [0003 / 0050] [0209/267] eta: 0 Days 1:38:21        lr: 	1.0000E-04 loss: 	0.31315
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.36385
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 1:39:21        lr: 	1.0000E-04 loss: 	0.24424
 epoch [0004 / 0050] [0109/267] eta: 0 Days 1:37:11        lr: 	1.0000E-04 loss: 	0.30486
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:35:14        lr: 	1.0000E-04 loss: 	0.30725
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.36849
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:35:55        lr: 	1.0000E-04 loss: 	0.29986
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:34:3         lr: 	1.0000E-04 loss: 	0.29913
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:32:21        lr: 	1.0000E-04 loss: 	0.30184
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.35996
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:32:51        lr: 	1.0000E-04 loss: 	0.36256
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:31:16        lr: 	1.0000E-04 loss: 	0.27389
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:29:48        lr: 	1.0000E-04 loss: 	0.28460
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.38525
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:30:9         lr: 	1.0000E-04 loss: 	0.23677
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:28:42        lr: 	1.0000E-04 loss: 	0.26768
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:27:18        lr: 	1.0000E-04 loss: 	0.27559
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.37624
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:27:32        lr: 	1.0000E-04 loss: 	0.27222
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:26:11        lr: 	1.0000E-04 loss: 	0.26650
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:24:52        lr: 	1.0000E-04 loss: 	0.26670
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.37649
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:25:2         lr: 	1.0000E-04 loss: 	0.19351
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:23:47        lr: 	1.0000E-04 loss: 	0.26224
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:22:33        lr: 	1.0000E-04 loss: 	0.26923
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.38513
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:22:50        lr: 	1.0000E-04 loss: 	0.38330
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:21:40        lr: 	1.0000E-04 loss: 	0.23101
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:20:30        lr: 	1.0000E-04 loss: 	0.23822
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.39338
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:20:31        lr: 	1.0000E-04 loss: 	0.28445
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:19:23        lr: 	1.0000E-04 loss: 	0.23447
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:18:19        lr: 	1.0000E-04 loss: 	0.22924
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.40837
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:18:17        lr: 	1.0000E-04 loss: 	0.26626
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:17:12        lr: 	1.0000E-04 loss: 	0.21141
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:16:10        lr: 	1.0000E-04 loss: 	0.21197
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.44208
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:16:7         lr: 	1.0000E-04 loss: 	0.12692
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:15:3         lr: 	1.0000E-04 loss: 	0.20320
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:14:1         lr: 	1.0000E-04 loss: 	0.20901
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.48586
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:13:56        lr: 	1.0000E-04 loss: 	0.23602
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:12:55        lr: 	1.0000E-04 loss: 	0.19881
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:11:54        lr: 	1.0000E-04 loss: 	0.19984
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.45941
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:11:44        lr: 	1.0000E-04 loss: 	0.19895
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:10:45        lr: 	1.0000E-04 loss: 	0.18344
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:9:46         lr: 	1.0000E-04 loss: 	0.18170
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.52473
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:9:36         lr: 	1.0000E-04 loss: 	0.13797
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:8:38         lr: 	1.0000E-04 loss: 	0.15632
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:7:42         lr: 	1.0000E-04 loss: 	0.16741
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.50000
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:7:28         lr: 	1.0000E-04 loss: 	0.16601
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:6:31         lr: 	1.0000E-04 loss: 	0.15227
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:5:35         lr: 	1.0000E-04 loss: 	0.15631
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.57407
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:5:23         lr: 	1.0000E-04 loss: 	0.11111
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:4:28         lr: 	1.0000E-04 loss: 	0.12948
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:3:34         lr: 	1.0000E-04 loss: 	0.13538
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.64221
starting train epoch 19
 epoch [0019 / 0050] [0009/267] eta: 0 Days 1:3:18         lr: 	1.0000E-04 loss: 	0.06557
 epoch [0019 / 0050] [0109/267] eta: 0 Days 1:2:24         lr: 	1.0000E-04 loss: 	0.13120
 epoch [0019 / 0050] [0209/267] eta: 0 Days 1:1:30         lr: 	1.0000E-04 loss: 	0.13216
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.64941
starting train epoch 20
 epoch [0020 / 0050] [0009/267] eta: 0 Days 1:1:14         lr: 	1.0000E-04 loss: 	0.11151
 epoch [0020 / 0050] [0109/267] eta: 0 Days 1:0:19         lr: 	1.0000E-04 loss: 	0.11141
 epoch [0020 / 0050] [0209/267] eta: 0 Days 0:59:25        lr: 	1.0000E-04 loss: 	0.12789
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.67805
starting train epoch 21
 epoch [0021 / 0050] [0009/267] eta: 0 Days 0:59:7         lr: 	1.0000E-04 loss: 	0.10699
 epoch [0021 / 0050] [0109/267] eta: 0 Days 0:58:13        lr: 	1.0000E-04 loss: 	0.10987
 epoch [0021 / 0050] [0209/267] eta: 0 Days 0:57:20        lr: 	1.0000E-04 loss: 	0.11102
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.65075
starting train epoch 22
 epoch [0022 / 0050] [0009/267] eta: 0 Days 0:57:1         lr: 	1.0000E-04 loss: 	0.06603
 epoch [0022 / 0050] [0109/267] eta: 0 Days 0:56:9         lr: 	1.0000E-04 loss: 	0.07504
 epoch [0022 / 0050] [0209/267] eta: 0 Days 0:55:17        lr: 	1.0000E-04 loss: 	0.09485
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.72893
starting train epoch 23
 epoch [0023 / 0050] [0009/267] eta: 0 Days 0:54:58        lr: 	1.0000E-04 loss: 	0.10899
 epoch [0023 / 0050] [0109/267] eta: 0 Days 0:54:6         lr: 	1.0000E-04 loss: 	0.10140
 epoch [0023 / 0050] [0209/267] eta: 0 Days 0:53:15        lr: 	1.0000E-04 loss: 	0.09144
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.83261
starting train epoch 24
 epoch [0024 / 0050] [0009/267] eta: 0 Days 0:52:54        lr: 	1.0000E-04 loss: 	0.11829
 epoch [0024 / 0050] [0109/267] eta: 0 Days 0:52:2         lr: 	1.0000E-04 loss: 	0.09835
 epoch [0024 / 0050] [0209/267] eta: 0 Days 0:51:12        lr: 	1.0000E-04 loss: 	0.09022
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.77329
starting val epoch 0
val [0000 / 0050] validation loss: 	0.43419
Acute and unspecified renal failure                                                        & 0.773(0.808, 0.735) & 0.398 (0.476, 0.333)
fused_ehr test  0   best mean auc :0.773 mean auprc 0.398
                    CI AUROC (0.735, 0.808) CI AUPRC (0.333, 0.476)
                     AUROC accute 0.773 mixed 0.773 chronic 0.773
                     AUROC accute CI (0.735, 0.808) mixed (0.735 , 0.808) chronic (0.735, 0.808)
                     AUPRC accute  0.398 mixed 0.398 chronic 0.398
                     AUPRC accute CI  (0.333, 0.476) mixed (0.333,  0.476) chronic (0.333, 0.476)