Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type late
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.86368
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 12:42:30       lr: 	1.0000E-07 loss: 	0.90495
 epoch [0000 / 0050] [0109/267] eta: 0 Days 2:26:6         lr: 	1.0000E-07 loss: 	0.76432
 epoch [0000 / 0050] [0209/267] eta: 0 Days 1:55:58        lr: 	1.0000E-07 loss: 	0.70938
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.59340
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:0:2          lr: 	1.0000E-07 loss: 	0.62807
 epoch [0001 / 0050] [0109/267] eta: 0 Days 1:49:50        lr: 	1.0000E-07 loss: 	0.53878
 epoch [0001 / 0050] [0209/267] eta: 0 Days 1:44:10        lr: 	1.0000E-07 loss: 	0.51759
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.47864
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 1:47:20        lr: 	1.0000E-07 loss: 	0.49729
 epoch [0002 / 0050] [0109/267] eta: 0 Days 1:42:40        lr: 	1.0000E-07 loss: 	0.44346
 epoch [0002 / 0050] [0209/267] eta: 0 Days 1:39:8         lr: 	1.0000E-07 loss: 	0.44131
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.44180
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 1:41:11        lr: 	1.0000E-07 loss: 	0.41244
 epoch [0003 / 0050] [0109/267] eta: 0 Days 1:38:11        lr: 	1.0000E-07 loss: 	0.43003
 epoch [0003 / 0050] [0209/267] eta: 0 Days 1:35:43        lr: 	1.0000E-07 loss: 	0.42098
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.42997
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 1:37:10        lr: 	1.0000E-07 loss: 	0.38762
 epoch [0004 / 0050] [0109/267] eta: 0 Days 1:34:43        lr: 	1.0000E-07 loss: 	0.41493
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:32:39        lr: 	1.0000E-07 loss: 	0.40978
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.42339
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:33:41        lr: 	1.0000E-07 loss: 	0.39601
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:31:45        lr: 	1.0000E-07 loss: 	0.41093
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:30:0         lr: 	1.0000E-07 loss: 	0.40585
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.41794
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:30:46        lr: 	1.0000E-07 loss: 	0.55608
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:29:7         lr: 	1.0000E-07 loss: 	0.38684
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:27:36        lr: 	1.0000E-07 loss: 	0.39834
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.41308
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:28:14        lr: 	1.0000E-07 loss: 	0.40626
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:26:55        lr: 	1.0000E-07 loss: 	0.39320
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:25:37        lr: 	1.0000E-07 loss: 	0.39284
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.40841
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:26:5         lr: 	1.0000E-07 loss: 	0.44803
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:24:41        lr: 	1.0000E-07 loss: 	0.39570
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:23:21        lr: 	1.0000E-07 loss: 	0.38410
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.40397
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:23:43        lr: 	1.0000E-07 loss: 	0.42714
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:22:26        lr: 	1.0000E-07 loss: 	0.39183
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:21:13        lr: 	1.0000E-07 loss: 	0.38396
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.39945
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:21:24        lr: 	1.0000E-07 loss: 	0.45780
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:20:11        lr: 	1.0000E-07 loss: 	0.37331
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:18:59        lr: 	1.0000E-07 loss: 	0.37134
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.39528
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:19:8         lr: 	1.0000E-07 loss: 	0.44548
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:17:58        lr: 	1.0000E-07 loss: 	0.38480
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:16:50        lr: 	1.0000E-07 loss: 	0.37228
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.39238
checkpoint
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:16:57        lr: 	1.0000E-07 loss: 	0.44261
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:15:49        lr: 	1.0000E-07 loss: 	0.37721
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:14:46        lr: 	1.0000E-07 loss: 	0.36445
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.38853
checkpoint
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:14:49        lr: 	1.0000E-07 loss: 	0.27221
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:13:44        lr: 	1.0000E-07 loss: 	0.35684
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:12:39        lr: 	1.0000E-07 loss: 	0.36096
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.38455
checkpoint
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:12:37        lr: 	1.0000E-07 loss: 	0.45451
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:11:35        lr: 	1.0000E-07 loss: 	0.38588
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:10:35        lr: 	1.0000E-07 loss: 	0.36772
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.38270
checkpoint
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:10:31        lr: 	1.0000E-07 loss: 	0.30928
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:9:30         lr: 	1.0000E-07 loss: 	0.34658
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:8:30         lr: 	1.0000E-07 loss: 	0.34931
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.37852
checkpoint
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:8:26         lr: 	1.0000E-07 loss: 	0.41983
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:7:26         lr: 	1.0000E-07 loss: 	0.33793
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:6:28         lr: 	1.0000E-07 loss: 	0.34982
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.37589
checkpoint
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:6:19         lr: 	1.0000E-07 loss: 	0.39378
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:5:24         lr: 	1.0000E-07 loss: 	0.33728
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:4:29         lr: 	1.0000E-07 loss: 	0.34145
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.37302
checkpoint
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:4:18         lr: 	1.0000E-07 loss: 	0.29459
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:3:21         lr: 	1.0000E-07 loss: 	0.33740
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:2:25         lr: 	1.0000E-07 loss: 	0.34166
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.37006
checkpoint
starting train epoch 19
 epoch [0019 / 0050] [0009/267] eta: 0 Days 1:2:13         lr: 	1.0000E-07 loss: 	0.33916
 epoch [0019 / 0050] [0109/267] eta: 0 Days 1:1:19         lr: 	1.0000E-07 loss: 	0.32411
 epoch [0019 / 0050] [0209/267] eta: 0 Days 1:0:26         lr: 	1.0000E-07 loss: 	0.33140
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.36793
checkpoint
starting train epoch 20
 epoch [0020 / 0050] [0009/267] eta: 0 Days 1:0:13         lr: 	1.0000E-07 loss: 	0.51088
 epoch [0020 / 0050] [0109/267] eta: 0 Days 0:59:18        lr: 	1.0000E-07 loss: 	0.32809
 epoch [0020 / 0050] [0209/267] eta: 0 Days 0:58:23        lr: 	1.0000E-07 loss: 	0.33174
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.36603
checkpoint
starting train epoch 21
 epoch [0021 / 0050] [0009/267] eta: 0 Days 0:58:9         lr: 	1.0000E-07 loss: 	0.35470
 epoch [0021 / 0050] [0109/267] eta: 0 Days 0:57:15        lr: 	1.0000E-07 loss: 	0.34167
 epoch [0021 / 0050] [0209/267] eta: 0 Days 0:56:22        lr: 	1.0000E-07 loss: 	0.33352
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.36576
checkpoint
starting train epoch 22
 epoch [0022 / 0050] [0009/267] eta: 0 Days 0:56:7         lr: 	1.0000E-07 loss: 	0.31043
 epoch [0022 / 0050] [0109/267] eta: 0 Days 0:55:14        lr: 	1.0000E-07 loss: 	0.31763
 epoch [0022 / 0050] [0209/267] eta: 0 Days 0:54:20        lr: 	1.0000E-07 loss: 	0.32537
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.36233
checkpoint
starting train epoch 23
 epoch [0023 / 0050] [0009/267] eta: 0 Days 0:54:3         lr: 	1.0000E-07 loss: 	0.37496
 epoch [0023 / 0050] [0109/267] eta: 0 Days 0:53:11        lr: 	1.0000E-07 loss: 	0.33313
 epoch [0023 / 0050] [0209/267] eta: 0 Days 0:52:19        lr: 	1.0000E-07 loss: 	0.32719
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.36328
checkpoint
starting train epoch 24
 epoch [0024 / 0050] [0009/267] eta: 0 Days 0:52:1         lr: 	1.0000E-07 loss: 	0.34185
 epoch [0024 / 0050] [0109/267] eta: 0 Days 0:51:9         lr: 	1.0000E-07 loss: 	0.32859
 epoch [0024 / 0050] [0209/267] eta: 0 Days 0:50:17        lr: 	1.0000E-07 loss: 	0.31663
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.35940
checkpoint
starting train epoch 25
 epoch [0025 / 0050] [0009/267] eta: 0 Days 0:49:59        lr: 	1.0000E-07 loss: 	0.32898
 epoch [0025 / 0050] [0109/267] eta: 0 Days 0:49:8         lr: 	1.0000E-07 loss: 	0.32142
 epoch [0025 / 0050] [0209/267] eta: 0 Days 0:48:18        lr: 	1.0000E-07 loss: 	0.32227
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.35839
checkpoint
starting train epoch 26
 epoch [0026 / 0050] [0009/267] eta: 0 Days 0:47:58        lr: 	1.0000E-07 loss: 	0.39278
 epoch [0026 / 0050] [0109/267] eta: 0 Days 0:47:8         lr: 	1.0000E-07 loss: 	0.30844
 epoch [0026 / 0050] [0209/267] eta: 0 Days 0:46:18        lr: 	1.0000E-07 loss: 	0.31607
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.35629
checkpoint
starting train epoch 27
 epoch [0027 / 0050] [0009/267] eta: 0 Days 0:46:0         lr: 	1.0000E-07 loss: 	0.25548
 epoch [0027 / 0050] [0109/267] eta: 0 Days 0:45:9         lr: 	1.0000E-07 loss: 	0.30203
 epoch [0027 / 0050] [0209/267] eta: 0 Days 0:44:20        lr: 	1.0000E-07 loss: 	0.30828
28
starting val epoch 28
val [0028 / 0050] validation loss: 	0.35444
checkpoint
starting train epoch 28
 epoch [0028 / 0050] [0009/267] eta: 0 Days 0:44:0         lr: 	1.0000E-07 loss: 	0.37039
 epoch [0028 / 0050] [0109/267] eta: 0 Days 0:43:10        lr: 	1.0000E-07 loss: 	0.31058
 epoch [0028 / 0050] [0209/267] eta: 0 Days 0:42:21        lr: 	1.0000E-07 loss: 	0.31016
29
starting val epoch 29
val [0029 / 0050] validation loss: 	0.35414
checkpoint
starting train epoch 29
 epoch [0029 / 0050] [0009/267] eta: 0 Days 0:42:0         lr: 	1.0000E-07 loss: 	0.42960
 epoch [0029 / 0050] [0109/267] eta: 0 Days 0:41:10        lr: 	1.0000E-07 loss: 	0.31195
 epoch [0029 / 0050] [0209/267] eta: 0 Days 0:40:21        lr: 	1.0000E-07 loss: 	0.30915
30
starting val epoch 30
val [0030 / 0050] validation loss: 	0.35494
checkpoint
starting train epoch 30
 epoch [0030 / 0050] [0009/267] eta: 0 Days 0:39:59        lr: 	1.0000E-07 loss: 	0.29601
 epoch [0030 / 0050] [0109/267] eta: 0 Days 0:39:10        lr: 	1.0000E-07 loss: 	0.30302
 epoch [0030 / 0050] [0209/267] eta: 0 Days 0:38:22        lr: 	1.0000E-07 loss: 	0.30759
31
starting val epoch 31
val [0031 / 0050] validation loss: 	0.35621
checkpoint
starting train epoch 31
 epoch [0031 / 0050] [0009/267] eta: 0 Days 0:37:59        lr: 	1.0000E-07 loss: 	0.42757
 epoch [0031 / 0050] [0109/267] eta: 0 Days 0:37:10        lr: 	1.0000E-07 loss: 	0.30251
 epoch [0031 / 0050] [0209/267] eta: 0 Days 0:36:22        lr: 	1.0000E-07 loss: 	0.30122
32
starting val epoch 32
val [0032 / 0050] validation loss: 	0.35250
checkpoint
starting train epoch 32
 epoch [0032 / 0050] [0009/267] eta: 0 Days 0:35:59        lr: 	1.0000E-07 loss: 	0.30143
 epoch [0032 / 0050] [0109/267] eta: 0 Days 0:35:10        lr: 	1.0000E-07 loss: 	0.31686
 epoch [0032 / 0050] [0209/267] eta: 0 Days 0:34:23        lr: 	1.0000E-07 loss: 	0.30693
33
starting val epoch 33
val [0033 / 0050] validation loss: 	0.35551
checkpoint
starting train epoch 33
 epoch [0033 / 0050] [0009/267] eta: 0 Days 0:33:59        lr: 	1.0000E-07 loss: 	0.43930
 epoch [0033 / 0050] [0109/267] eta: 0 Days 0:33:11        lr: 	1.0000E-07 loss: 	0.30031
 epoch [0033 / 0050] [0209/267] eta: 0 Days 0:32:22        lr: 	1.0000E-07 loss: 	0.29550
34
starting val epoch 34
val [0034 / 0050] validation loss: 	0.35120
checkpoint
starting train epoch 34
 epoch [0034 / 0050] [0009/267] eta: 0 Days 0:31:58        lr: 	1.0000E-07 loss: 	0.32999
 epoch [0034 / 0050] [0109/267] eta: 0 Days 0:31:10        lr: 	1.0000E-07 loss: 	0.28614
 epoch [0034 / 0050] [0209/267] eta: 0 Days 0:30:23        lr: 	1.0000E-07 loss: 	0.29385
35
starting val epoch 35
val [0035 / 0050] validation loss: 	0.35111
checkpoint
starting train epoch 35
 epoch [0035 / 0050] [0009/267] eta: 0 Days 0:29:57        lr: 	1.0000E-07 loss: 	0.34698
 epoch [0035 / 0050] [0109/267] eta: 0 Days 0:29:10        lr: 	1.0000E-07 loss: 	0.31266
 epoch [0035 / 0050] [0209/267] eta: 0 Days 0:28:22        lr: 	1.0000E-07 loss: 	0.30144
36
starting val epoch 36
val [0036 / 0050] validation loss: 	0.35279
checkpoint
starting train epoch 36
 epoch [0036 / 0050] [0009/267] eta: 0 Days 0:27:57        lr: 	1.0000E-07 loss: 	0.43765
 epoch [0036 / 0050] [0109/267] eta: 0 Days 0:27:9         lr: 	1.0000E-07 loss: 	0.29522
 epoch [0036 / 0050] [0209/267] eta: 0 Days 0:26:22        lr: 	1.0000E-07 loss: 	0.29097
37
starting val epoch 37
val [0037 / 0050] validation loss: 	0.35068
checkpoint
starting train epoch 37
 epoch [0037 / 0050] [0009/267] eta: 0 Days 0:25:57        lr: 	1.0000E-07 loss: 	0.35004
 epoch [0037 / 0050] [0109/267] eta: 0 Days 0:25:9         lr: 	1.0000E-07 loss: 	0.32228
 epoch [0037 / 0050] [0209/267] eta: 0 Days 0:24:23        lr: 	1.0000E-07 loss: 	0.29840
38
starting val epoch 38
val [0038 / 0050] validation loss: 	0.35374
checkpoint
starting train epoch 38
 epoch [0038 / 0050] [0009/267] eta: 0 Days 0:23:56        lr: 	1.0000E-07 loss: 	0.30770
 epoch [0038 / 0050] [0109/267] eta: 0 Days 0:23:9         lr: 	1.0000E-07 loss: 	0.30149
 epoch [0038 / 0050] [0209/267] eta: 0 Days 0:22:22        lr: 	1.0000E-07 loss: 	0.29195
39
starting val epoch 39
val [0039 / 0050] validation loss: 	0.35093
checkpoint
starting train epoch 39
 epoch [0039 / 0050] [0009/267] eta: 0 Days 0:21:56        lr: 	1.0000E-07 loss: 	0.25636
 epoch [0039 / 0050] [0109/267] eta: 0 Days 0:21:9         lr: 	1.0000E-07 loss: 	0.30281
 epoch [0039 / 0050] [0209/267] eta: 0 Days 0:20:22        lr: 	1.0000E-07 loss: 	0.28996
40
starting val epoch 40
val [0040 / 0050] validation loss: 	0.35143
checkpoint
starting train epoch 40
 epoch [0040 / 0050] [0009/267] eta: 0 Days 0:19:55        lr: 	1.0000E-07 loss: 	0.27096
 epoch [0040 / 0050] [0109/267] eta: 0 Days 0:19:9         lr: 	1.0000E-07 loss: 	0.28495
 epoch [0040 / 0050] [0209/267] eta: 0 Days 0:18:22        lr: 	1.0000E-07 loss: 	0.28737
41
starting val epoch 41
val [0041 / 0050] validation loss: 	0.35087
checkpoint
starting train epoch 41
 epoch [0041 / 0050] [0009/267] eta: 0 Days 0:17:55        lr: 	1.0000E-07 loss: 	0.29130
 epoch [0041 / 0050] [0109/267] eta: 0 Days 0:17:9         lr: 	1.0000E-07 loss: 	0.29328
 epoch [0041 / 0050] [0209/267] eta: 0 Days 0:16:23        lr: 	1.0000E-07 loss: 	0.28848
42
starting val epoch 42
val [0042 / 0050] validation loss: 	0.34779
checkpoint
starting train epoch 42
 epoch [0042 / 0050] [0009/267] eta: 0 Days 0:15:55        lr: 	1.0000E-07 loss: 	0.28117
 epoch [0042 / 0050] [0109/267] eta: 0 Days 0:15:9         lr: 	1.0000E-07 loss: 	0.27761
 epoch [0042 / 0050] [0209/267] eta: 0 Days 0:14:23        lr: 	1.0000E-07 loss: 	0.27853
43
starting val epoch 43
val [0043 / 0050] validation loss: 	0.34893
checkpoint
starting train epoch 43
 epoch [0043 / 0050] [0009/267] eta: 0 Days 0:13:55        lr: 	1.0000E-07 loss: 	0.34300
 epoch [0043 / 0050] [0109/267] eta: 0 Days 0:13:9         lr: 	1.0000E-07 loss: 	0.28976
 epoch [0043 / 0050] [0209/267] eta: 0 Days 0:12:23        lr: 	1.0000E-07 loss: 	0.28686
44
starting val epoch 44
val [0044 / 0050] validation loss: 	0.35077
checkpoint
starting train epoch 44
 epoch [0044 / 0050] [0009/267] eta: 0 Days 0:11:55        lr: 	1.0000E-07 loss: 	0.31898
 epoch [0044 / 0050] [0109/267] eta: 0 Days 0:11:9         lr: 	1.0000E-07 loss: 	0.29074
 epoch [0044 / 0050] [0209/267] eta: 0 Days 0:10:24        lr: 	1.0000E-07 loss: 	0.28570
45
starting val epoch 45
val [0045 / 0050] validation loss: 	0.34986
checkpoint
starting train epoch 45
 epoch [0045 / 0050] [0009/267] eta: 0 Days 0:9:55         lr: 	1.0000E-07 loss: 	0.32923
 epoch [0045 / 0050] [0109/267] eta: 0 Days 0:9:9          lr: 	1.0000E-07 loss: 	0.29354
 epoch [0045 / 0050] [0209/267] eta: 0 Days 0:8:24         lr: 	1.0000E-07 loss: 	0.28462
46
starting val epoch 46
val [0046 / 0050] validation loss: 	0.34953
checkpoint
starting train epoch 46
 epoch [0046 / 0050] [0009/267] eta: 0 Days 0:7:55         lr: 	1.0000E-07 loss: 	0.41295
 epoch [0046 / 0050] [0109/267] eta: 0 Days 0:7:9          lr: 	1.0000E-07 loss: 	0.29227
 epoch [0046 / 0050] [0209/267] eta: 0 Days 0:6:24         lr: 	1.0000E-07 loss: 	0.28635
47
starting val epoch 47
val [0047 / 0050] validation loss: 	0.35209
checkpoint
starting train epoch 47
 epoch [0047 / 0050] [0009/267] eta: 0 Days 0:5:55         lr: 	1.0000E-07 loss: 	0.25165
 epoch [0047 / 0050] [0109/267] eta: 0 Days 0:5:10         lr: 	1.0000E-07 loss: 	0.27540
 epoch [0047 / 0050] [0209/267] eta: 0 Days 0:4:25         lr: 	1.0000E-07 loss: 	0.28145
48
starting val epoch 48
val [0048 / 0050] validation loss: 	0.35039
checkpoint
starting train epoch 48
 epoch [0048 / 0050] [0009/267] eta: 0 Days 0:3:55         lr: 	1.0000E-07 loss: 	0.25703
 epoch [0048 / 0050] [0109/267] eta: 0 Days 0:3:10         lr: 	1.0000E-07 loss: 	0.27291
 epoch [0048 / 0050] [0209/267] eta: 0 Days 0:2:25         lr: 	1.0000E-07 loss: 	0.28232
49
starting val epoch 49
val [0049 / 0050] validation loss: 	0.35175
checkpoint
starting train epoch 49
 epoch [0049 / 0050] [0009/267] eta: 0 Days 0:1:55         lr: 	1.0000E-07 loss: 	0.23713
 epoch [0049 / 0050] [0109/267] eta: 0 Days 0:1:10         lr: 	1.0000E-07 loss: 	0.29024
 epoch [0049 / 0050] [0209/267] eta: 0 Days 0:0:25         lr: 	1.0000E-07 loss: 	0.27763
starting val epoch 0
val [0000 / 0050] validation loss: 	0.33325
Acute and unspecified renal failure                                                        & 0.839(0.869, 0.807) & 0.497 (0.578, 0.419)
fused_ehr test  0   best mean auc :0.839 mean auprc 0.497
                    CI AUROC (0.807, 0.869) CI AUPRC (0.419, 0.578)
                     AUROC accute 0.839 mixed 0.839 chronic 0.839
                     AUROC accute CI (0.807, 0.869) mixed (0.807 , 0.869) chronic (0.807, 0.869)
                     AUPRC accute  0.497 mixed 0.497 chronic 0.497
                     AUPRC accute CI  (0.419, 0.578) mixed (0.419,  0.578) chronic (0.419, 0.578)