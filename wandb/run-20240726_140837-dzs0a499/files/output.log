Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.92043
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 16:15:38       lr: 	1.0000E-04 loss: 	0.56753 loss align 0.0000
 epoch [0000 / 0050] [0109/267] eta: 0 Days 3:12:41        lr: 	1.0000E-04 loss: 	0.41744 loss align 0.0000
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:34:27        lr: 	1.0000E-04 loss: 	0.39085 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.43022
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:41:8         lr: 	1.0000E-04 loss: 	0.40113 loss align 0.0000
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:27:24        lr: 	1.0000E-04 loss: 	0.36858 loss align 0.0000
 epoch [0001 / 0050] [0209/267] eta: 0 Days 2:19:10        lr: 	1.0000E-04 loss: 	0.35858 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.48690
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:23:46        lr: 	1.0000E-04 loss: 	0.43020 loss align 0.0000
 epoch [0002 / 0050] [0109/267] eta: 0 Days 2:17:37        lr: 	1.0000E-04 loss: 	0.33411 loss align 0.0000
 epoch [0002 / 0050] [0209/267] eta: 0 Days 2:12:55        lr: 	1.0000E-04 loss: 	0.33579 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.36589
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 2:14:37        lr: 	1.0000E-04 loss: 	0.29910 loss align 0.0000
 epoch [0003 / 0050] [0109/267] eta: 0 Days 2:10:42        lr: 	1.0000E-04 loss: 	0.33235 loss align 0.0000
 epoch [0003 / 0050] [0209/267] eta: 0 Days 2:7:22         lr: 	1.0000E-04 loss: 	0.33784 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.35281
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 2:9:43         lr: 	1.0000E-04 loss: 	0.36125 loss align 0.0000
 epoch [0004 / 0050] [0109/267] eta: 0 Days 2:6:46         lr: 	1.0000E-04 loss: 	0.33644 loss align 0.0000
 epoch [0004 / 0050] [0209/267] eta: 0 Days 2:4:8          lr: 	1.0000E-04 loss: 	0.34018 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.38228
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 2:5:3          lr: 	1.0000E-04 loss: 	0.39885 loss align 0.0000
 epoch [0005 / 0050] [0109/267] eta: 0 Days 2:2:38         lr: 	1.0000E-04 loss: 	0.33120 loss align 0.0000
 epoch [0005 / 0050] [0209/267] eta: 0 Days 2:0:24         lr: 	1.0000E-04 loss: 	0.32956 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.37679
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 2:1:7          lr: 	1.0000E-04 loss: 	0.39584 loss align 0.0000
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:58:55        lr: 	1.0000E-04 loss: 	0.33336 loss align 0.0000
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:56:57        lr: 	1.0000E-04 loss: 	0.33372 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.41054
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:57:25        lr: 	1.0000E-04 loss: 	0.34062 loss align 0.0000
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:55:31        lr: 	1.0000E-04 loss: 	0.31254 loss align 0.0000
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:53:39        lr: 	1.0000E-04 loss: 	0.30564 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.37994
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:54:3         lr: 	1.0000E-04 loss: 	0.34134 loss align 0.0000
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:52:20        lr: 	1.0000E-04 loss: 	0.31286 loss align 0.0000
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:50:37        lr: 	1.0000E-04 loss: 	0.30110 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.38829
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:50:51        lr: 	1.0000E-04 loss: 	0.33080 loss align 0.0000
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:49:11        lr: 	1.0000E-04 loss: 	0.29547 loss align 0.0000
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:47:36        lr: 	1.0000E-04 loss: 	0.29045 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.37034
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:48:5         lr: 	1.0000E-04 loss: 	0.30320 loss align 0.0000
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:46:33        lr: 	1.0000E-04 loss: 	0.29458 loss align 0.0000
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:45:1         lr: 	1.0000E-04 loss: 	0.28274 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.35865
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:45:4         lr: 	1.0000E-04 loss: 	0.31264 loss align 0.0000
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:43:32        lr: 	1.0000E-04 loss: 	0.28261 loss align 0.0000
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:42:7         lr: 	1.0000E-04 loss: 	0.27564 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.42015
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:42:5         lr: 	1.0000E-04 loss: 	0.27143 loss align 0.0000
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:40:40        lr: 	1.0000E-04 loss: 	0.24964 loss align 0.0000
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:39:15        lr: 	1.0000E-04 loss: 	0.26663 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.45589
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:39:10        lr: 	1.0000E-04 loss: 	0.22123 loss align 0.0000
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:37:46        lr: 	1.0000E-04 loss: 	0.24354 loss align 0.0000
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:36:24        lr: 	1.0000E-04 loss: 	0.24055 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.44767
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:36:16        lr: 	1.0000E-04 loss: 	0.26598 loss align 0.0000
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:34:57        lr: 	1.0000E-04 loss: 	0.23731 loss align 0.0000
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:33:38        lr: 	1.0000E-04 loss: 	0.24009 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.40892
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:33:28        lr: 	1.0000E-04 loss: 	0.22513 loss align 0.0000
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:32:9         lr: 	1.0000E-04 loss: 	0.24936 loss align 0.0000
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:30:52        lr: 	1.0000E-04 loss: 	0.25424 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.45528
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:30:39        lr: 	1.0000E-04 loss: 	0.16085 loss align 0.0000
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:29:24        lr: 	1.0000E-04 loss: 	0.22099 loss align 0.0000
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:28:8         lr: 	1.0000E-04 loss: 	0.21231 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.51183
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:27:52        lr: 	1.0000E-04 loss: 	0.26670 loss align 0.0000
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:26:38        lr: 	1.0000E-04 loss: 	0.21751 loss align 0.0000
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:25:23        lr: 	1.0000E-04 loss: 	0.21603 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.45155
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:25:7         lr: 	1.0000E-04 loss: 	0.17245 loss align 0.0000
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:23:54        lr: 	1.0000E-04 loss: 	0.18367 loss align 0.0000
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:22:43        lr: 	1.0000E-04 loss: 	0.19513 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.48768
starting train epoch 19
 epoch [0019 / 0050] [0009/267] eta: 0 Days 1:22:23        lr: 	1.0000E-04 loss: 	0.26818 loss align 0.0000
 epoch [0019 / 0050] [0109/267] eta: 0 Days 1:21:11        lr: 	1.0000E-04 loss: 	0.19527 loss align 0.0000
 epoch [0019 / 0050] [0209/267] eta: 0 Days 1:20:0         lr: 	1.0000E-04 loss: 	0.19276 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.48076
starting train epoch 20
 epoch [0020 / 0050] [0009/267] eta: 0 Days 1:19:40        lr: 	1.0000E-04 loss: 	0.11674 loss align 0.0000
 epoch [0020 / 0050] [0109/267] eta: 0 Days 1:18:28        lr: 	1.0000E-04 loss: 	0.17877 loss align 0.0000
 epoch [0020 / 0050] [0209/267] eta: 0 Days 1:17:19        lr: 	1.0000E-04 loss: 	0.18640 loss align 0.0000
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.59996
starting train epoch 21
 epoch [0021 / 0050] [0009/267] eta: 0 Days 1:16:57        lr: 	1.0000E-04 loss: 	0.10339 loss align 0.0000
 epoch [0021 / 0050] [0109/267] eta: 0 Days 1:15:47        lr: 	1.0000E-04 loss: 	0.18094 loss align 0.0000
 epoch [0021 / 0050] [0209/267] eta: 0 Days 1:14:38        lr: 	1.0000E-04 loss: 	0.19488 loss align 0.0000
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.52846
starting train epoch 22
 epoch [0022 / 0050] [0009/267] eta: 0 Days 1:14:15        lr: 	1.0000E-04 loss: 	0.17494 loss align 0.0000
 epoch [0022 / 0050] [0109/267] eta: 0 Days 1:13:6         lr: 	1.0000E-04 loss: 	0.26673 loss align 0.0000
 epoch [0022 / 0050] [0209/267] eta: 0 Days 1:11:57        lr: 	1.0000E-04 loss: 	0.29394 loss align 0.0000
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.48733
starting train epoch 23
 epoch [0023 / 0050] [0009/267] eta: 0 Days 1:11:33        lr: 	1.0000E-04 loss: 	0.15368 loss align 0.0000
 epoch [0023 / 0050] [0109/267] eta: 0 Days 1:10:25        lr: 	1.0000E-04 loss: 	0.19178 loss align 0.0000
 epoch [0023 / 0050] [0209/267] eta: 0 Days 1:9:17         lr: 	1.0000E-04 loss: 	0.18376 loss align 0.0000
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.52002
starting train epoch 24
 epoch [0024 / 0050] [0009/267] eta: 0 Days 1:8:51         lr: 	1.0000E-04 loss: 	0.16374 loss align 0.0000
 epoch [0024 / 0050] [0109/267] eta: 0 Days 1:7:43         lr: 	1.0000E-04 loss: 	0.16679 loss align 0.0000
 epoch [0024 / 0050] [0209/267] eta: 0 Days 1:6:36         lr: 	1.0000E-04 loss: 	0.17924 loss align 0.0000
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.49770
starting val epoch 0
val [0000 / 0050] validation loss: 	0.36788
Acute and unspecified renal failure                                                        & 0.795(0.830, 0.761) & 0.415 (0.496, 0.353)
fused_ehr test  0   best mean auc :0.795 mean auprc 0.415
                    CI AUROC (0.761, 0.830) CI AUPRC (0.353, 0.496)
                     AUROC accute 0.795 mixed 0.795 chronic 0.795
                     AUROC accute CI (0.761, 0.830) mixed (0.761 , 0.830) chronic (0.761, 0.830)
                     AUPRC accute  0.415 mixed 0.415 chronic 0.415
                     AUPRC accute CI  (0.353, 0.496) mixed (0.353,  0.496) chronic (0.353, 0.496)