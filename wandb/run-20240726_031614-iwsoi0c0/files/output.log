Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.84791
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 14:17:6        lr: 	1.0000E-05 loss: 	0.53830 loss align 0.0000
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:7:17         lr: 	1.0000E-05 loss: 	0.43800 loss align 0.0000
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:32:39        lr: 	1.0000E-05 loss: 	0.41388 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.37793
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:34:49        lr: 	1.0000E-05 loss: 	0.39359 loss align 0.0000
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:24:41        lr: 	1.0000E-05 loss: 	0.34392 loss align 0.0000
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:17:49        lr: 	1.0000E-05 loss: 	0.34325 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.39811
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:20:18        lr: 	1.0000E-05 loss: 	0.41017 loss align 0.0000
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:15:47        lr: 	1.0000E-05 loss: 	0.31994 loss align 0.0000
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:12:42        lr: 	1.0000E-05 loss: 	0.32576 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.32365
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:14:53        lr: 	1.0000E-05 loss: 	0.35987 loss align 0.0000
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:12:4         lr: 	1.0000E-05 loss: 	0.31146 loss align 0.0000
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:9:56         lr: 	1.0000E-05 loss: 	0.30400 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.35192
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:10:39        lr: 	1.0000E-05 loss: 	0.32239 loss align 0.0000
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:8:50         lr: 	1.0000E-05 loss: 	0.27762 loss align 0.0000
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:7:0          lr: 	1.0000E-05 loss: 	0.28374 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.33015
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:8:0          lr: 	1.0000E-05 loss: 	0.30884 loss align 0.0000
 epoch [0005 / 0050] [0109/280] eta: 0 Days 1:6:24         lr: 	1.0000E-05 loss: 	0.27986 loss align 0.0000
 epoch [0005 / 0050] [0209/280] eta: 0 Days 1:4:36         lr: 	1.0000E-05 loss: 	0.27304 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.36032
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 1:4:56         lr: 	1.0000E-05 loss: 	0.27023 loss align 0.0000
 epoch [0006 / 0050] [0109/280] eta: 0 Days 1:3:52         lr: 	1.0000E-05 loss: 	0.26152 loss align 0.0000
 epoch [0006 / 0050] [0209/280] eta: 0 Days 1:3:0          lr: 	1.0000E-05 loss: 	0.26244 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.34016
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 1:3:32         lr: 	1.0000E-05 loss: 	0.31770 loss align 0.0000
 epoch [0007 / 0050] [0109/280] eta: 0 Days 1:2:23         lr: 	1.0000E-05 loss: 	0.25312 loss align 0.0000
 epoch [0007 / 0050] [0209/280] eta: 0 Days 1:1:9          lr: 	1.0000E-05 loss: 	0.24257 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.36949
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 1:1:18         lr: 	1.0000E-05 loss: 	0.18156 loss align 0.0000
 epoch [0008 / 0050] [0109/280] eta: 0 Days 1:0:6          lr: 	1.0000E-05 loss: 	0.25609 loss align 0.0000
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:59:9         lr: 	1.0000E-05 loss: 	0.24850 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.40973
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:59:16        lr: 	1.0000E-05 loss: 	0.21881 loss align 0.0000
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:58:12        lr: 	1.0000E-05 loss: 	0.21219 loss align 0.0000
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:57:13        lr: 	1.0000E-05 loss: 	0.22801 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.34914
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:57:17        lr: 	1.0000E-05 loss: 	0.27065 loss align 0.0000
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:56:18        lr: 	1.0000E-05 loss: 	0.21342 loss align 0.0000
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:55:28        lr: 	1.0000E-05 loss: 	0.21585 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.39420
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:55:37        lr: 	1.0000E-05 loss: 	0.27554 loss align 0.0000
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:54:44        lr: 	1.0000E-05 loss: 	0.20548 loss align 0.0000
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:53:59        lr: 	1.0000E-05 loss: 	0.20644 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.38016
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:53:58        lr: 	1.0000E-05 loss: 	0.22799 loss align 0.0000
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:53:11        lr: 	1.0000E-05 loss: 	0.17725 loss align 0.0000
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:52:21        lr: 	1.0000E-05 loss: 	0.18407 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.44820
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:52:16        lr: 	1.0000E-05 loss: 	0.26827 loss align 0.0000
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:51:27        lr: 	1.0000E-05 loss: 	0.19204 loss align 0.0000
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:50:41        lr: 	1.0000E-05 loss: 	0.19404 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.42361
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:50:40        lr: 	1.0000E-05 loss: 	0.16176 loss align 0.0000
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:49:53        lr: 	1.0000E-05 loss: 	0.17478 loss align 0.0000
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:49:14        lr: 	1.0000E-05 loss: 	0.17423 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.46264
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:49:9         lr: 	1.0000E-05 loss: 	0.08255 loss align 0.0000
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:48:26        lr: 	1.0000E-05 loss: 	0.14986 loss align 0.0000
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:47:48        lr: 	1.0000E-05 loss: 	0.16690 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.42494
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:47:43        lr: 	1.0000E-05 loss: 	0.16729 loss align 0.0000
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:47:1         lr: 	1.0000E-05 loss: 	0.15405 loss align 0.0000
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:46:23        lr: 	1.0000E-05 loss: 	0.15900 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.42534
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:46:14        lr: 	1.0000E-05 loss: 	0.14306 loss align 0.0000
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:45:33        lr: 	1.0000E-05 loss: 	0.14203 loss align 0.0000
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:44:50        lr: 	1.0000E-05 loss: 	0.13923 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.49988
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:44:45        lr: 	1.0000E-05 loss: 	0.09028 loss align 0.0000
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:44:6         lr: 	1.0000E-05 loss: 	0.14945 loss align 0.0000
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:43:29        lr: 	1.0000E-05 loss: 	0.14566 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.48989
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:43:22        lr: 	1.0000E-05 loss: 	0.09948 loss align 0.0000
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:42:46        lr: 	1.0000E-05 loss: 	0.10664 loss align 0.0000
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:42:5         lr: 	1.0000E-05 loss: 	0.11616 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.48199
starting val epoch 0
val [0000 / 0050] validation loss: 	0.34269
Acute and unspecified renal failure                                                        & 0.822(0.853, 0.788) & 0.491 (0.566, 0.427)
fused_ehr test  0   best mean auc :0.822 mean auprc 0.491
                    CI AUROC (0.788, 0.853) CI AUPRC (0.427, 0.566)
                     AUROC accute 0.822 mixed 0.822 chronic 0.822
                     AUROC accute CI (0.788, 0.853) mixed (0.788 , 0.853) chronic (0.788, 0.853)
                     AUPRC accute  0.491 mixed 0.491 chronic 0.491
                     AUPRC accute CI  (0.427, 0.566) mixed (0.427,  0.566) chronic (0.427, 0.566)