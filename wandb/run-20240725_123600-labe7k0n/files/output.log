Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type joint
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.77787
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 13:24:55       lr: 	1.0000E-04 loss: 	0.57680
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:2:59         lr: 	1.0000E-04 loss: 	0.40827
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:28:53        lr: 	1.0000E-04 loss: 	0.39781
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.39185
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:31:4         lr: 	1.0000E-04 loss: 	0.39895
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:20:48        lr: 	1.0000E-04 loss: 	0.36300
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:14:21        lr: 	1.0000E-04 loss: 	0.36028
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.35543
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:16:56        lr: 	1.0000E-04 loss: 	0.36669
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:12:36        lr: 	1.0000E-04 loss: 	0.35802
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:9:39         lr: 	1.0000E-04 loss: 	0.33879
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.34720
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:11:32        lr: 	1.0000E-04 loss: 	0.33841
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:9:4          lr: 	1.0000E-04 loss: 	0.33678
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:6:49         lr: 	1.0000E-04 loss: 	0.33331
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.34418
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:7:35         lr: 	1.0000E-04 loss: 	0.38218
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:5:38         lr: 	1.0000E-04 loss: 	0.33916
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:3:58         lr: 	1.0000E-04 loss: 	0.32660
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.34427
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:4:37         lr: 	1.0000E-04 loss: 	0.40215
 epoch [0005 / 0050] [0109/280] eta: 0 Days 1:3:12         lr: 	1.0000E-04 loss: 	0.33927
 epoch [0005 / 0050] [0209/280] eta: 0 Days 1:1:51         lr: 	1.0000E-04 loss: 	0.32255
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.34827
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 1:2:33         lr: 	1.0000E-04 loss: 	0.36319
 epoch [0006 / 0050] [0109/280] eta: 0 Days 1:1:13         lr: 	1.0000E-04 loss: 	0.31715
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:59:57        lr: 	1.0000E-04 loss: 	0.31405
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.35201
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 1:0:17         lr: 	1.0000E-04 loss: 	0.25005
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:59:7         lr: 	1.0000E-04 loss: 	0.30117
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:57:58        lr: 	1.0000E-04 loss: 	0.29062
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.34849
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:58:19        lr: 	1.0000E-04 loss: 	0.28143
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:57:16        lr: 	1.0000E-04 loss: 	0.29732
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:56:18        lr: 	1.0000E-04 loss: 	0.29557
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.34638
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:56:27        lr: 	1.0000E-04 loss: 	0.26480
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:55:32        lr: 	1.0000E-04 loss: 	0.30847
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:54:38        lr: 	1.0000E-04 loss: 	0.29515
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.42528
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:54:48        lr: 	1.0000E-04 loss: 	0.27860
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:53:56        lr: 	1.0000E-04 loss: 	0.27655
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:53:12        lr: 	1.0000E-04 loss: 	0.27953
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.40087
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:53:19        lr: 	1.0000E-04 loss: 	0.28593
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:52:32        lr: 	1.0000E-04 loss: 	0.26295
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:51:43        lr: 	1.0000E-04 loss: 	0.26127
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.43800
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:51:55        lr: 	1.0000E-04 loss: 	0.21771
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:51:13        lr: 	1.0000E-04 loss: 	0.23874
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:50:27        lr: 	1.0000E-04 loss: 	0.25945
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.38370
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:50:32        lr: 	1.0000E-04 loss: 	0.34413
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:49:47        lr: 	1.0000E-04 loss: 	0.27874
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:49:6         lr: 	1.0000E-04 loss: 	0.24677
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.38401
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:49:5         lr: 	1.0000E-04 loss: 	0.32176
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:48:22        lr: 	1.0000E-04 loss: 	0.24637
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:47:40        lr: 	1.0000E-04 loss: 	0.24071
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.46873
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:47:40        lr: 	1.0000E-04 loss: 	0.24418
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:46:57        lr: 	1.0000E-04 loss: 	0.22880
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:46:19        lr: 	1.0000E-04 loss: 	0.23779
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.44028
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:46:12        lr: 	1.0000E-04 loss: 	0.16520
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:45:33        lr: 	1.0000E-04 loss: 	0.20171
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:44:56        lr: 	1.0000E-04 loss: 	0.22724
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.41519
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:44:50        lr: 	1.0000E-04 loss: 	0.18406
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:44:14        lr: 	1.0000E-04 loss: 	0.20588
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:43:39        lr: 	1.0000E-04 loss: 	0.20434
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.46834
starting val epoch 0
val [0000 / 0050] validation loss: 	0.35359
Acute and unspecified renal failure                                                        & 0.800(0.835, 0.766) & 0.439 (0.515, 0.370)
fused_ehr test  0   best mean auc :0.800 mean auprc 0.439
                    CI AUROC (0.766, 0.835) CI AUPRC (0.370, 0.515)
                     AUROC accute 0.800 mixed 0.800 chronic 0.800
                     AUROC accute CI (0.766, 0.835) mixed (0.766 , 0.835) chronic (0.766, 0.835)
                     AUPRC accute  0.439 mixed 0.439 chronic 0.439
                     AUPRC accute CI  (0.370, 0.515) mixed (0.370,  0.515) chronic (0.370, 0.515)