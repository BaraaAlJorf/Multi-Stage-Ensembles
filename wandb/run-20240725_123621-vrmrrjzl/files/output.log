Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type joint
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.77787
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 14:3:9         lr: 	1.0000E-05 loss: 	0.59425
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:4:4          lr: 	1.0000E-05 loss: 	0.41523
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:31:19        lr: 	1.0000E-05 loss: 	0.39887
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.37224
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:32:58        lr: 	1.0000E-05 loss: 	0.38220
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:21:35        lr: 	1.0000E-05 loss: 	0.35152
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:15:8         lr: 	1.0000E-05 loss: 	0.35059
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.37624
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:17:35        lr: 	1.0000E-05 loss: 	0.35800
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:13:4         lr: 	1.0000E-05 loss: 	0.34511
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:9:41         lr: 	1.0000E-05 loss: 	0.32828
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.35513
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:11:19        lr: 	1.0000E-05 loss: 	0.35375
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:8:39         lr: 	1.0000E-05 loss: 	0.32819
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:6:15         lr: 	1.0000E-05 loss: 	0.32906
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.34823
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:7:41         lr: 	1.0000E-05 loss: 	0.37595
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:5:43         lr: 	1.0000E-05 loss: 	0.31526
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:3:45         lr: 	1.0000E-05 loss: 	0.31007
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.35043
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:4:24         lr: 	1.0000E-05 loss: 	0.36120
 epoch [0005 / 0050] [0109/280] eta: 0 Days 1:3:7          lr: 	1.0000E-05 loss: 	0.30837
 epoch [0005 / 0050] [0209/280] eta: 0 Days 1:1:39         lr: 	1.0000E-05 loss: 	0.29241
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.32956
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 1:2:32         lr: 	1.0000E-05 loss: 	0.34914
 epoch [0006 / 0050] [0109/280] eta: 0 Days 1:1:19         lr: 	1.0000E-05 loss: 	0.28945
 epoch [0006 / 0050] [0209/280] eta: 0 Days 1:0:6          lr: 	1.0000E-05 loss: 	0.27631
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.32691
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 1:0:48         lr: 	1.0000E-05 loss: 	0.23409
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:59:38        lr: 	1.0000E-05 loss: 	0.25214
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:58:33        lr: 	1.0000E-05 loss: 	0.25729
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.33858
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:59:1         lr: 	1.0000E-05 loss: 	0.25941
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:57:55        lr: 	1.0000E-05 loss: 	0.25082
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:56:54        lr: 	1.0000E-05 loss: 	0.24293
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.33749
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:57:16        lr: 	1.0000E-05 loss: 	0.17802
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:56:19        lr: 	1.0000E-05 loss: 	0.23875
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:55:23        lr: 	1.0000E-05 loss: 	0.22708
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.35684
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:55:38        lr: 	1.0000E-05 loss: 	0.17232
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:54:44        lr: 	1.0000E-05 loss: 	0.20502
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:53:49        lr: 	1.0000E-05 loss: 	0.21322
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.36881
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:53:53        lr: 	1.0000E-05 loss: 	0.15424
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:52:59        lr: 	1.0000E-05 loss: 	0.19058
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:52:10        lr: 	1.0000E-05 loss: 	0.20036
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.40000
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:52:16        lr: 	1.0000E-05 loss: 	0.16175
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:51:27        lr: 	1.0000E-05 loss: 	0.18105
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:50:41        lr: 	1.0000E-05 loss: 	0.19481
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.38372
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:50:42        lr: 	1.0000E-05 loss: 	0.25914
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:49:56        lr: 	1.0000E-05 loss: 	0.19969
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:49:13        lr: 	1.0000E-05 loss: 	0.18249
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.41538
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:49:10        lr: 	1.0000E-05 loss: 	0.17175
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:48:27        lr: 	1.0000E-05 loss: 	0.17675
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:47:43        lr: 	1.0000E-05 loss: 	0.16598
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.43084
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:47:38        lr: 	1.0000E-05 loss: 	0.11962
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:46:57        lr: 	1.0000E-05 loss: 	0.14592
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:46:17        lr: 	1.0000E-05 loss: 	0.15545
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.45045
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:46:11        lr: 	1.0000E-05 loss: 	0.10727
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:45:29        lr: 	1.0000E-05 loss: 	0.14191
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:44:47        lr: 	1.0000E-05 loss: 	0.15910
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.46297
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:44:40        lr: 	1.0000E-05 loss: 	0.11513
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:43:57        lr: 	1.0000E-05 loss: 	0.13204
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:43:19        lr: 	1.0000E-05 loss: 	0.12709
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.55287
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:43:11        lr: 	1.0000E-05 loss: 	0.09370
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:42:33        lr: 	1.0000E-05 loss: 	0.12260
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:41:55        lr: 	1.0000E-05 loss: 	0.11918
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.53906
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:41:46        lr: 	1.0000E-05 loss: 	0.12793
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:41:9         lr: 	1.0000E-05 loss: 	0.11480
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:40:31        lr: 	1.0000E-05 loss: 	0.11813
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.54859
starting train epoch 20
 epoch [0020 / 0050] [0009/280] eta: 0 Days 0:40:21        lr: 	1.0000E-05 loss: 	0.14623
 epoch [0020 / 0050] [0109/280] eta: 0 Days 0:39:43        lr: 	1.0000E-05 loss: 	0.11837
 epoch [0020 / 0050] [0209/280] eta: 0 Days 0:39:8         lr: 	1.0000E-05 loss: 	0.10778
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.54944
starting train epoch 21
 epoch [0021 / 0050] [0009/280] eta: 0 Days 0:38:56        lr: 	1.0000E-05 loss: 	0.11967
 epoch [0021 / 0050] [0109/280] eta: 0 Days 0:38:22        lr: 	1.0000E-05 loss: 	0.10673
 epoch [0021 / 0050] [0209/280] eta: 0 Days 0:37:44        lr: 	1.0000E-05 loss: 	0.10557
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.51029
starting train epoch 22
 epoch [0022 / 0050] [0009/280] eta: 0 Days 0:37:32        lr: 	1.0000E-05 loss: 	0.12315
 epoch [0022 / 0050] [0109/280] eta: 0 Days 0:36:56        lr: 	1.0000E-05 loss: 	0.11362
 epoch [0022 / 0050] [0209/280] eta: 0 Days 0:36:20        lr: 	1.0000E-05 loss: 	0.11315
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.63339
starting train epoch 23
 epoch [0023 / 0050] [0009/280] eta: 0 Days 0:36:9         lr: 	1.0000E-05 loss: 	0.08655
 epoch [0023 / 0050] [0109/280] eta: 0 Days 0:35:34        lr: 	1.0000E-05 loss: 	0.07576
 epoch [0023 / 0050] [0209/280] eta: 0 Days 0:35:0         lr: 	1.0000E-05 loss: 	0.08750
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.61956
starting val epoch 0
val [0000 / 0050] validation loss: 	0.34970
Acute and unspecified renal failure                                                        & 0.835(0.864, 0.806) & 0.531 (0.603, 0.470)
fused_ehr test  0   best mean auc :0.835 mean auprc 0.531
                    CI AUROC (0.806, 0.864) CI AUPRC (0.470, 0.603)
                     AUROC accute 0.835 mixed 0.835 chronic 0.835
                     AUROC accute CI (0.806, 0.864) mixed (0.806 , 0.864) chronic (0.806, 0.864)
                     AUPRC accute  0.531 mixed 0.531 chronic 0.531
                     AUPRC accute CI  (0.470, 0.603) mixed (0.470,  0.603) chronic (0.470, 0.603)