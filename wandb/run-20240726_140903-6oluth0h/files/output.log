Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.92043
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 14:25:21       lr: 	1.0000E-05 loss: 	0.64198 loss align 0.0000
 epoch [0000 / 0050] [0109/267] eta: 0 Days 2:46:56        lr: 	1.0000E-05 loss: 	0.40722 loss align 0.0000
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:13:7         lr: 	1.0000E-05 loss: 	0.40638 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.40868
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:18:22        lr: 	1.0000E-05 loss: 	0.43598 loss align 0.0000
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:6:26         lr: 	1.0000E-05 loss: 	0.39053 loss align 0.0000
 epoch [0001 / 0050] [0209/267] eta: 0 Days 1:59:8         lr: 	1.0000E-05 loss: 	0.37477 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.35302
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:2:34         lr: 	1.0000E-05 loss: 	0.34596 loss align 0.0000
 epoch [0002 / 0050] [0109/267] eta: 0 Days 1:57:20        lr: 	1.0000E-05 loss: 	0.29883 loss align 0.0000
 epoch [0002 / 0050] [0209/267] eta: 0 Days 1:52:54        lr: 	1.0000E-05 loss: 	0.29523 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.33670
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 1:55:10        lr: 	1.0000E-05 loss: 	0.28095 loss align 0.0000
 epoch [0003 / 0050] [0109/267] eta: 0 Days 1:51:47        lr: 	1.0000E-05 loss: 	0.26856 loss align 0.0000
 epoch [0003 / 0050] [0209/267] eta: 0 Days 1:48:52        lr: 	1.0000E-05 loss: 	0.27566 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.36953
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 1:50:37        lr: 	1.0000E-05 loss: 	0.26282 loss align 0.0000
 epoch [0004 / 0050] [0109/267] eta: 0 Days 1:47:57        lr: 	1.0000E-05 loss: 	0.23531 loss align 0.0000
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:45:27        lr: 	1.0000E-05 loss: 	0.24417 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.49708
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:46:10        lr: 	1.0000E-05 loss: 	0.19271 loss align 0.0000
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:43:58        lr: 	1.0000E-05 loss: 	0.20218 loss align 0.0000
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:41:56        lr: 	1.0000E-05 loss: 	0.19789 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.43551
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:42:28        lr: 	1.0000E-05 loss: 	0.19682 loss align 0.0000
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:40:36        lr: 	1.0000E-05 loss: 	0.13286 loss align 0.0000
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:38:52        lr: 	1.0000E-05 loss: 	0.14731 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.55941
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:39:16        lr: 	1.0000E-05 loss: 	0.05231 loss align 0.0000
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:37:36        lr: 	1.0000E-05 loss: 	0.10726 loss align 0.0000
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:35:58        lr: 	1.0000E-05 loss: 	0.10879 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.70053
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:36:17        lr: 	1.0000E-05 loss: 	0.05724 loss align 0.0000
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:34:44        lr: 	1.0000E-05 loss: 	0.06853 loss align 0.0000
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:33:10        lr: 	1.0000E-05 loss: 	0.07957 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.71504
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:33:21        lr: 	1.0000E-05 loss: 	0.03621 loss align 0.0000
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:31:55        lr: 	1.0000E-05 loss: 	0.06813 loss align 0.0000
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:30:35        lr: 	1.0000E-05 loss: 	0.05885 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.69557
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:30:44        lr: 	1.0000E-05 loss: 	0.02416 loss align 0.0000
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:29:26        lr: 	1.0000E-05 loss: 	0.05006 loss align 0.0000
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:28:10        lr: 	1.0000E-05 loss: 	0.04960 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.82448
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:28:11        lr: 	1.0000E-05 loss: 	0.09845 loss align 0.0000
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:26:57        lr: 	1.0000E-05 loss: 	0.04282 loss align 0.0000
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:25:45        lr: 	1.0000E-05 loss: 	0.04525 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.73753
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:25:47        lr: 	1.0000E-05 loss: 	0.05886 loss align 0.0000
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:24:40        lr: 	1.0000E-05 loss: 	0.02725 loss align 0.0000
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:23:30        lr: 	1.0000E-05 loss: 	0.03127 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.81012
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:23:32        lr: 	1.0000E-05 loss: 	0.03052 loss align 0.0000
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:22:21        lr: 	1.0000E-05 loss: 	0.02841 loss align 0.0000
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:21:12        lr: 	1.0000E-05 loss: 	0.02977 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.92081
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:21:5         lr: 	1.0000E-05 loss: 	0.00506 loss align 0.0000
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:19:57        lr: 	1.0000E-05 loss: 	0.01738 loss align 0.0000
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:18:48        lr: 	1.0000E-05 loss: 	0.02533 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.95316
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:18:41        lr: 	1.0000E-05 loss: 	0.08658 loss align 0.0000
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:17:35        lr: 	1.0000E-05 loss: 	0.02195 loss align 0.0000
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:16:28        lr: 	1.0000E-05 loss: 	0.02201 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	1.06254
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:16:16        lr: 	1.0000E-05 loss: 	0.01393 loss align 0.0000
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:15:15        lr: 	1.0000E-05 loss: 	0.02010 loss align 0.0000
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:14:12        lr: 	1.0000E-05 loss: 	0.01951 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.84184
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:13:58        lr: 	1.0000E-05 loss: 	0.00231 loss align 0.0000
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:12:56        lr: 	1.0000E-05 loss: 	0.01990 loss align 0.0000
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:11:53        lr: 	1.0000E-05 loss: 	0.02352 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	1.06873
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:11:37        lr: 	1.0000E-05 loss: 	0.04684 loss align 0.0000
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:10:36        lr: 	1.0000E-05 loss: 	0.01545 loss align 0.0000
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:9:35         lr: 	1.0000E-05 loss: 	0.02261 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	1.18988
starting val epoch 0
val [0000 / 0050] validation loss: 	0.36702
Acute and unspecified renal failure                                                        & 0.836(0.866, 0.803) & 0.492 (0.573, 0.420)
fused_ehr test  0   best mean auc :0.836 mean auprc 0.492
                    CI AUROC (0.803, 0.866) CI AUPRC (0.420, 0.573)
                     AUROC accute 0.836 mixed 0.836 chronic 0.836
                     AUROC accute CI (0.803, 0.866) mixed (0.803 , 0.866) chronic (0.803, 0.866)
                     AUPRC accute  0.492 mixed 0.492 chronic 0.492
                     AUPRC accute CI  (0.420, 0.573) mixed (0.420,  0.573) chronic (0.420, 0.573)