Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.92043
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 13:27:17       lr: 	1.0000E-03 loss: 	0.87702 loss align 0.0000
 epoch [0000 / 0050] [0109/267] eta: 0 Days 2:41:12        lr: 	1.0000E-03 loss: 	0.46218 loss align 0.0000
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:9:21         lr: 	1.0000E-03 loss: 	0.44272 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.45158
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:11:6         lr: 	1.0000E-03 loss: 	0.50232 loss align 0.0000
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:0:41         lr: 	1.0000E-03 loss: 	0.42937 loss align 0.0000
 epoch [0001 / 0050] [0209/267] eta: 0 Days 1:54:8         lr: 	1.0000E-03 loss: 	0.42495 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.47774
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 1:56:11        lr: 	1.0000E-03 loss: 	0.54356 loss align 0.0000
 epoch [0002 / 0050] [0109/267] eta: 0 Days 1:51:39        lr: 	1.0000E-03 loss: 	0.42276 loss align 0.0000
 epoch [0002 / 0050] [0209/267] eta: 0 Days 1:48:15        lr: 	1.0000E-03 loss: 	0.43077 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.43672
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 1:49:59        lr: 	1.0000E-03 loss: 	0.49461 loss align 0.0000
 epoch [0003 / 0050] [0109/267] eta: 0 Days 1:47:1         lr: 	1.0000E-03 loss: 	0.42623 loss align 0.0000
 epoch [0003 / 0050] [0209/267] eta: 0 Days 1:44:23        lr: 	1.0000E-03 loss: 	0.42676 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.43589
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 1:45:29        lr: 	1.0000E-03 loss: 	0.42063 loss align 0.0000
 epoch [0004 / 0050] [0109/267] eta: 0 Days 1:43:19        lr: 	1.0000E-03 loss: 	0.41941 loss align 0.0000
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:41:19        lr: 	1.0000E-03 loss: 	0.42626 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.43823
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:42:1         lr: 	1.0000E-03 loss: 	0.54043 loss align 0.0000
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:40:8         lr: 	1.0000E-03 loss: 	0.42423 loss align 0.0000
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:38:27        lr: 	1.0000E-03 loss: 	0.42443 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.43585
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:39:0         lr: 	1.0000E-03 loss: 	0.51737 loss align 0.0000
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:37:16        lr: 	1.0000E-03 loss: 	0.43334 loss align 0.0000
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:35:42        lr: 	1.0000E-03 loss: 	0.42344 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.43580
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:36:3         lr: 	1.0000E-03 loss: 	0.48366 loss align 0.0000
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:34:33        lr: 	1.0000E-03 loss: 	0.42744 loss align 0.0000
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:33:6         lr: 	1.0000E-03 loss: 	0.42341 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.43656
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:33:23        lr: 	1.0000E-03 loss: 	0.47193 loss align 0.0000
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:32:2         lr: 	1.0000E-03 loss: 	0.43899 loss align 0.0000
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:30:43        lr: 	1.0000E-03 loss: 	0.42391 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.43548
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:30:51        lr: 	1.0000E-03 loss: 	0.51954 loss align 0.0000
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:29:33        lr: 	1.0000E-03 loss: 	0.42322 loss align 0.0000
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:28:21        lr: 	1.0000E-03 loss: 	0.41819 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.43551
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:28:30        lr: 	1.0000E-03 loss: 	0.42395 loss align 0.0000
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:27:19        lr: 	1.0000E-03 loss: 	0.42756 loss align 0.0000
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:26:7         lr: 	1.0000E-03 loss: 	0.42513 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.44041
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:26:11        lr: 	1.0000E-03 loss: 	0.49451 loss align 0.0000
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:25:1         lr: 	1.0000E-03 loss: 	0.44826 loss align 0.0000
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:23:51        lr: 	1.0000E-03 loss: 	0.43027 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.43758
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:23:47        lr: 	1.0000E-03 loss: 	0.45455 loss align 0.0000
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:22:40        lr: 	1.0000E-03 loss: 	0.40787 loss align 0.0000
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:21:32        lr: 	1.0000E-03 loss: 	0.41596 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.43552
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:21:26        lr: 	1.0000E-03 loss: 	0.42668 loss align 0.0000
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:20:18        lr: 	1.0000E-03 loss: 	0.42106 loss align 0.0000
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:19:13        lr: 	1.0000E-03 loss: 	0.42141 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.43548
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:19:5         lr: 	1.0000E-03 loss: 	0.42979 loss align 0.0000
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:18:0         lr: 	1.0000E-03 loss: 	0.41634 loss align 0.0000
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:16:55        lr: 	1.0000E-03 loss: 	0.41789 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.43924
starting val epoch 0
val [0000 / 0050] validation loss: 	0.89882
Acute and unspecified renal failure                                                        & 0.629(0.673, 0.577) & 0.293 (0.362, 0.233)
fused_ehr test  0   best mean auc :0.629 mean auprc 0.293
                    CI AUROC (0.577, 0.673) CI AUPRC (0.233, 0.362)
                     AUROC accute 0.629 mixed 0.629 chronic 0.629
                     AUROC accute CI (0.577, 0.673) mixed (0.577 , 0.673) chronic (0.577, 0.673)
                     AUPRC accute  0.293 mixed 0.293 chronic 0.293
                     AUPRC accute CI  (0.233, 0.362) mixed (0.233,  0.362) chronic (0.233, 0.362)