Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type early
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.77787
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 13:45:17       lr: 	1.0000E-07 loss: 	0.83874
 epoch [0000 / 0050] [0109/280] eta: 0 Days 1:32:13        lr: 	1.0000E-07 loss: 	0.74528
 epoch [0000 / 0050] [0209/280] eta: 0 Days 0:56:48        lr: 	1.0000E-07 loss: 	0.72394
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.68038
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 0:58:6         lr: 	1.0000E-07 loss: 	0.73807
 epoch [0001 / 0050] [0109/280] eta: 0 Days 0:47:50        lr: 	1.0000E-07 loss: 	0.65482
 epoch [0001 / 0050] [0209/280] eta: 0 Days 0:41:40        lr: 	1.0000E-07 loss: 	0.63789
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.60207
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 0:43:57        lr: 	1.0000E-07 loss: 	0.66255
 epoch [0002 / 0050] [0109/280] eta: 0 Days 0:39:46        lr: 	1.0000E-07 loss: 	0.58866
 epoch [0002 / 0050] [0209/280] eta: 0 Days 0:36:37        lr: 	1.0000E-07 loss: 	0.56851
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.54227
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 0:38:31        lr: 	1.0000E-07 loss: 	0.58395
 epoch [0003 / 0050] [0109/280] eta: 0 Days 0:36:0         lr: 	1.0000E-07 loss: 	0.52868
 epoch [0003 / 0050] [0209/280] eta: 0 Days 0:33:49        lr: 	1.0000E-07 loss: 	0.51832
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.49845
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 0:35:17        lr: 	1.0000E-07 loss: 	0.54116
 epoch [0004 / 0050] [0109/280] eta: 0 Days 0:33:38        lr: 	1.0000E-07 loss: 	0.49494
 epoch [0004 / 0050] [0209/280] eta: 0 Days 0:32:6         lr: 	1.0000E-07 loss: 	0.48357
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.46824
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 0:33:12        lr: 	1.0000E-07 loss: 	0.52941
 epoch [0005 / 0050] [0109/280] eta: 0 Days 0:31:52        lr: 	1.0000E-07 loss: 	0.46854
 epoch [0005 / 0050] [0209/280] eta: 0 Days 0:30:43        lr: 	1.0000E-07 loss: 	0.45564
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.44975
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 0:31:39        lr: 	1.0000E-07 loss: 	0.54233
 epoch [0006 / 0050] [0109/280] eta: 0 Days 0:30:33        lr: 	1.0000E-07 loss: 	0.46097
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:29:31        lr: 	1.0000E-07 loss: 	0.44500
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.43826
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 0:30:17        lr: 	1.0000E-07 loss: 	0.39034
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:29:21        lr: 	1.0000E-07 loss: 	0.42322
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:28:26        lr: 	1.0000E-07 loss: 	0.42156
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.43167
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:29:4         lr: 	1.0000E-07 loss: 	0.47804
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:28:14        lr: 	1.0000E-07 loss: 	0.43550
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:27:27        lr: 	1.0000E-07 loss: 	0.42729
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.42751
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:27:59        lr: 	1.0000E-07 loss: 	0.47679
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:27:16        lr: 	1.0000E-07 loss: 	0.42640
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:26:35        lr: 	1.0000E-07 loss: 	0.42145
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.42477
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:27:5         lr: 	1.0000E-07 loss: 	0.41312
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:26:26        lr: 	1.0000E-07 loss: 	0.41014
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:25:47        lr: 	1.0000E-07 loss: 	0.41458
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.42297
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:26:12        lr: 	1.0000E-07 loss: 	0.40034
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:25:35        lr: 	1.0000E-07 loss: 	0.41389
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:25:0         lr: 	1.0000E-07 loss: 	0.41816
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.42155
checkpoint
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:25:19        lr: 	1.0000E-07 loss: 	0.42236
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:24:46        lr: 	1.0000E-07 loss: 	0.41047
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:24:13        lr: 	1.0000E-07 loss: 	0.41918
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.42039
checkpoint
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:24:30        lr: 	1.0000E-07 loss: 	0.54591
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:23:59        lr: 	1.0000E-07 loss: 	0.44752
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:23:28        lr: 	1.0000E-07 loss: 	0.42526
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.41932
checkpoint
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:23:44        lr: 	1.0000E-07 loss: 	0.52906
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:23:14        lr: 	1.0000E-07 loss: 	0.42466
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:22:46        lr: 	1.0000E-07 loss: 	0.41330
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.41836
checkpoint
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:22:59        lr: 	1.0000E-07 loss: 	0.44294
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:22:30        lr: 	1.0000E-07 loss: 	0.41621
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:22:3         lr: 	1.0000E-07 loss: 	0.41943
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.41743
checkpoint
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:22:15        lr: 	1.0000E-07 loss: 	0.43137
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:21:49        lr: 	1.0000E-07 loss: 	0.40684
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:21:24        lr: 	1.0000E-07 loss: 	0.42057
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.41652
checkpoint
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:21:32        lr: 	1.0000E-07 loss: 	0.44303
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:21:5         lr: 	1.0000E-07 loss: 	0.42635
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:20:41        lr: 	1.0000E-07 loss: 	0.41402
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.41565
checkpoint
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:20:48        lr: 	1.0000E-07 loss: 	0.42249
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:20:24        lr: 	1.0000E-07 loss: 	0.43197
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:20:0         lr: 	1.0000E-07 loss: 	0.41177
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.41478
checkpoint
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:20:7         lr: 	1.0000E-07 loss: 	0.36655
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:19:43        lr: 	1.0000E-07 loss: 	0.40602
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:19:20        lr: 	1.0000E-07 loss: 	0.41078
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.41394
checkpoint
starting train epoch 20
 epoch [0020 / 0050] [0009/280] eta: 0 Days 0:19:25        lr: 	1.0000E-07 loss: 	0.45950
 epoch [0020 / 0050] [0109/280] eta: 0 Days 0:19:2         lr: 	1.0000E-07 loss: 	0.40704
 epoch [0020 / 0050] [0209/280] eta: 0 Days 0:18:40        lr: 	1.0000E-07 loss: 	0.40676
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.41316
checkpoint
starting train epoch 21
 epoch [0021 / 0050] [0009/280] eta: 0 Days 0:18:44        lr: 	1.0000E-07 loss: 	0.50776
 epoch [0021 / 0050] [0109/280] eta: 0 Days 0:18:22        lr: 	1.0000E-07 loss: 	0.41658
 epoch [0021 / 0050] [0209/280] eta: 0 Days 0:18:1         lr: 	1.0000E-07 loss: 	0.41150
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.41231
checkpoint
starting train epoch 22
 epoch [0022 / 0050] [0009/280] eta: 0 Days 0:18:3         lr: 	1.0000E-07 loss: 	0.39269
 epoch [0022 / 0050] [0109/280] eta: 0 Days 0:17:42        lr: 	1.0000E-07 loss: 	0.38946
 epoch [0022 / 0050] [0209/280] eta: 0 Days 0:17:22        lr: 	1.0000E-07 loss: 	0.41590
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.41150
checkpoint
starting train epoch 23
 epoch [0023 / 0050] [0009/280] eta: 0 Days 0:17:23        lr: 	1.0000E-07 loss: 	0.45708
 epoch [0023 / 0050] [0109/280] eta: 0 Days 0:17:3         lr: 	1.0000E-07 loss: 	0.41066
 epoch [0023 / 0050] [0209/280] eta: 0 Days 0:16:42        lr: 	1.0000E-07 loss: 	0.40812
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.41066
checkpoint
starting train epoch 24
 epoch [0024 / 0050] [0009/280] eta: 0 Days 0:16:42        lr: 	1.0000E-07 loss: 	0.52967
 epoch [0024 / 0050] [0109/280] eta: 0 Days 0:16:22        lr: 	1.0000E-07 loss: 	0.39211
 epoch [0024 / 0050] [0209/280] eta: 0 Days 0:16:2         lr: 	1.0000E-07 loss: 	0.40656
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.40988
checkpoint
starting train epoch 25
 epoch [0025 / 0050] [0009/280] eta: 0 Days 0:16:1         lr: 	1.0000E-07 loss: 	0.42419
 epoch [0025 / 0050] [0109/280] eta: 0 Days 0:15:43        lr: 	1.0000E-07 loss: 	0.38794
 epoch [0025 / 0050] [0209/280] eta: 0 Days 0:15:24        lr: 	1.0000E-07 loss: 	0.39982
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.40911
checkpoint
starting train epoch 26
 epoch [0026 / 0050] [0009/280] eta: 0 Days 0:15:23        lr: 	1.0000E-07 loss: 	0.43196
 epoch [0026 / 0050] [0109/280] eta: 0 Days 0:15:4         lr: 	1.0000E-07 loss: 	0.38537
 epoch [0026 / 0050] [0209/280] eta: 0 Days 0:14:46        lr: 	1.0000E-07 loss: 	0.40471
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.40835
checkpoint
starting train epoch 27
 epoch [0027 / 0050] [0009/280] eta: 0 Days 0:14:44        lr: 	1.0000E-07 loss: 	0.42583
 epoch [0027 / 0050] [0109/280] eta: 0 Days 0:14:25        lr: 	1.0000E-07 loss: 	0.39603
 epoch [0027 / 0050] [0209/280] eta: 0 Days 0:14:7         lr: 	1.0000E-07 loss: 	0.40191
28
starting val epoch 28
val [0028 / 0050] validation loss: 	0.40755
checkpoint
starting train epoch 28
 epoch [0028 / 0050] [0009/280] eta: 0 Days 0:14:4         lr: 	1.0000E-07 loss: 	0.39090
 epoch [0028 / 0050] [0109/280] eta: 0 Days 0:13:46        lr: 	1.0000E-07 loss: 	0.39167
 epoch [0028 / 0050] [0209/280] eta: 0 Days 0:13:28        lr: 	1.0000E-07 loss: 	0.39583
29
starting val epoch 29
val [0029 / 0050] validation loss: 	0.40681
checkpoint
starting train epoch 29
 epoch [0029 / 0050] [0009/280] eta: 0 Days 0:13:25        lr: 	1.0000E-07 loss: 	0.38451
 epoch [0029 / 0050] [0109/280] eta: 0 Days 0:13:7         lr: 	1.0000E-07 loss: 	0.38270
 epoch [0029 / 0050] [0209/280] eta: 0 Days 0:12:50        lr: 	1.0000E-07 loss: 	0.39908
30
starting val epoch 30
val [0030 / 0050] validation loss: 	0.40606
checkpoint
starting train epoch 30
 epoch [0030 / 0050] [0009/280] eta: 0 Days 0:12:46        lr: 	1.0000E-07 loss: 	0.40977
 epoch [0030 / 0050] [0109/280] eta: 0 Days 0:12:29        lr: 	1.0000E-07 loss: 	0.40703
 epoch [0030 / 0050] [0209/280] eta: 0 Days 0:12:12        lr: 	1.0000E-07 loss: 	0.39804
31
starting val epoch 31
val [0031 / 0050] validation loss: 	0.40535
checkpoint
starting train epoch 31
 epoch [0031 / 0050] [0009/280] eta: 0 Days 0:12:7         lr: 	1.0000E-07 loss: 	0.51137
 epoch [0031 / 0050] [0109/280] eta: 0 Days 0:11:50        lr: 	1.0000E-07 loss: 	0.40611
 epoch [0031 / 0050] [0209/280] eta: 0 Days 0:11:33        lr: 	1.0000E-07 loss: 	0.39672
32
starting val epoch 32
val [0032 / 0050] validation loss: 	0.40464
checkpoint
starting train epoch 32
 epoch [0032 / 0050] [0009/280] eta: 0 Days 0:11:28        lr: 	1.0000E-07 loss: 	0.46509
 epoch [0032 / 0050] [0109/280] eta: 0 Days 0:11:11        lr: 	1.0000E-07 loss: 	0.41021
 epoch [0032 / 0050] [0209/280] eta: 0 Days 0:10:54        lr: 	1.0000E-07 loss: 	0.40098
33
starting val epoch 33
val [0033 / 0050] validation loss: 	0.40399
checkpoint
starting train epoch 33
 epoch [0033 / 0050] [0009/280] eta: 0 Days 0:10:49        lr: 	1.0000E-07 loss: 	0.38441
 epoch [0033 / 0050] [0109/280] eta: 0 Days 0:10:32        lr: 	1.0000E-07 loss: 	0.39841
 epoch [0033 / 0050] [0209/280] eta: 0 Days 0:10:16        lr: 	1.0000E-07 loss: 	0.38349
34
starting val epoch 34
val [0034 / 0050] validation loss: 	0.40330
checkpoint
starting train epoch 34
 epoch [0034 / 0050] [0009/280] eta: 0 Days 0:10:10        lr: 	1.0000E-07 loss: 	0.43807
 epoch [0034 / 0050] [0109/280] eta: 0 Days 0:9:54         lr: 	1.0000E-07 loss: 	0.36940
 epoch [0034 / 0050] [0209/280] eta: 0 Days 0:9:38         lr: 	1.0000E-07 loss: 	0.38389
35
starting val epoch 35
val [0035 / 0050] validation loss: 	0.40263
checkpoint
starting train epoch 35
 epoch [0035 / 0050] [0009/280] eta: 0 Days 0:9:31         lr: 	1.0000E-07 loss: 	0.46873
 epoch [0035 / 0050] [0109/280] eta: 0 Days 0:9:15         lr: 	1.0000E-07 loss: 	0.39935
 epoch [0035 / 0050] [0209/280] eta: 0 Days 0:8:59         lr: 	1.0000E-07 loss: 	0.39296
36
starting val epoch 36
val [0036 / 0050] validation loss: 	0.40202
checkpoint
starting train epoch 36
 epoch [0036 / 0050] [0009/280] eta: 0 Days 0:8:52         lr: 	1.0000E-07 loss: 	0.47515
 epoch [0036 / 0050] [0109/280] eta: 0 Days 0:8:37         lr: 	1.0000E-07 loss: 	0.39055
 epoch [0036 / 0050] [0209/280] eta: 0 Days 0:8:21         lr: 	1.0000E-07 loss: 	0.39816
37
starting val epoch 37
val [0037 / 0050] validation loss: 	0.40141
checkpoint
starting train epoch 37
 epoch [0037 / 0050] [0009/280] eta: 0 Days 0:8:14         lr: 	1.0000E-07 loss: 	0.42663
 epoch [0037 / 0050] [0109/280] eta: 0 Days 0:7:59         lr: 	1.0000E-07 loss: 	0.38443
 epoch [0037 / 0050] [0209/280] eta: 0 Days 0:7:43         lr: 	1.0000E-07 loss: 	0.39385
38
starting val epoch 38
val [0038 / 0050] validation loss: 	0.40083
checkpoint
starting train epoch 38
 epoch [0038 / 0050] [0009/280] eta: 0 Days 0:7:36         lr: 	1.0000E-07 loss: 	0.43414
 epoch [0038 / 0050] [0109/280] eta: 0 Days 0:7:20         lr: 	1.0000E-07 loss: 	0.39310
 epoch [0038 / 0050] [0209/280] eta: 0 Days 0:7:5          lr: 	1.0000E-07 loss: 	0.38980
39
starting val epoch 39
val [0039 / 0050] validation loss: 	0.40027
checkpoint
starting train epoch 39
 epoch [0039 / 0050] [0009/280] eta: 0 Days 0:6:58         lr: 	1.0000E-07 loss: 	0.40167
 epoch [0039 / 0050] [0109/280] eta: 0 Days 0:6:42         lr: 	1.0000E-07 loss: 	0.41500
 epoch [0039 / 0050] [0209/280] eta: 0 Days 0:6:27         lr: 	1.0000E-07 loss: 	0.39888
40
starting val epoch 40
val [0040 / 0050] validation loss: 	0.39968
checkpoint
starting train epoch 40
 epoch [0040 / 0050] [0009/280] eta: 0 Days 0:6:19         lr: 	1.0000E-07 loss: 	0.42439
 epoch [0040 / 0050] [0109/280] eta: 0 Days 0:6:4          lr: 	1.0000E-07 loss: 	0.38423
 epoch [0040 / 0050] [0209/280] eta: 0 Days 0:5:50         lr: 	1.0000E-07 loss: 	0.39280
41
starting val epoch 41
val [0041 / 0050] validation loss: 	0.39911
checkpoint
starting train epoch 41
 epoch [0041 / 0050] [0009/280] eta: 0 Days 0:5:41         lr: 	1.0000E-07 loss: 	0.46374
 epoch [0041 / 0050] [0109/280] eta: 0 Days 0:5:26         lr: 	1.0000E-07 loss: 	0.39353
 epoch [0041 / 0050] [0209/280] eta: 0 Days 0:5:12         lr: 	1.0000E-07 loss: 	0.39495
42
starting val epoch 42
val [0042 / 0050] validation loss: 	0.39859
checkpoint
starting train epoch 42
 epoch [0042 / 0050] [0009/280] eta: 0 Days 0:5:3          lr: 	1.0000E-07 loss: 	0.47183
 epoch [0042 / 0050] [0109/280] eta: 0 Days 0:4:48         lr: 	1.0000E-07 loss: 	0.38841
 epoch [0042 / 0050] [0209/280] eta: 0 Days 0:4:34         lr: 	1.0000E-07 loss: 	0.39119
43
starting val epoch 43
val [0043 / 0050] validation loss: 	0.39807
checkpoint
starting train epoch 43
 epoch [0043 / 0050] [0009/280] eta: 0 Days 0:4:24         lr: 	1.0000E-07 loss: 	0.40890
 epoch [0043 / 0050] [0109/280] eta: 0 Days 0:4:10         lr: 	1.0000E-07 loss: 	0.38306
 epoch [0043 / 0050] [0209/280] eta: 0 Days 0:3:56         lr: 	1.0000E-07 loss: 	0.38759
44
starting val epoch 44
val [0044 / 0050] validation loss: 	0.39753
checkpoint
starting train epoch 44
 epoch [0044 / 0050] [0009/280] eta: 0 Days 0:3:46         lr: 	1.0000E-07 loss: 	0.47177
 epoch [0044 / 0050] [0109/280] eta: 0 Days 0:3:32         lr: 	1.0000E-07 loss: 	0.36980
 epoch [0044 / 0050] [0209/280] eta: 0 Days 0:3:18         lr: 	1.0000E-07 loss: 	0.38326
45
starting val epoch 45
val [0045 / 0050] validation loss: 	0.39708
checkpoint
starting train epoch 45
 epoch [0045 / 0050] [0009/280] eta: 0 Days 0:3:8          lr: 	1.0000E-07 loss: 	0.48079
 epoch [0045 / 0050] [0109/280] eta: 0 Days 0:2:54         lr: 	1.0000E-07 loss: 	0.39489
 epoch [0045 / 0050] [0209/280] eta: 0 Days 0:2:40         lr: 	1.0000E-07 loss: 	0.38807
46
starting val epoch 46
val [0046 / 0050] validation loss: 	0.39659
checkpoint
starting train epoch 46
 epoch [0046 / 0050] [0009/280] eta: 0 Days 0:2:30         lr: 	1.0000E-07 loss: 	0.34164
 epoch [0046 / 0050] [0109/280] eta: 0 Days 0:2:16         lr: 	1.0000E-07 loss: 	0.36269
 epoch [0046 / 0050] [0209/280] eta: 0 Days 0:2:2          lr: 	1.0000E-07 loss: 	0.38656
47
starting val epoch 47
val [0047 / 0050] validation loss: 	0.39611
checkpoint
starting train epoch 47
 epoch [0047 / 0050] [0009/280] eta: 0 Days 0:1:52         lr: 	1.0000E-07 loss: 	0.49779
 epoch [0047 / 0050] [0109/280] eta: 0 Days 0:1:38         lr: 	1.0000E-07 loss: 	0.38568
 epoch [0047 / 0050] [0209/280] eta: 0 Days 0:1:25         lr: 	1.0000E-07 loss: 	0.37595
48
starting val epoch 48
val [0048 / 0050] validation loss: 	0.39569
checkpoint
starting train epoch 48
 epoch [0048 / 0050] [0009/280] eta: 0 Days 0:1:14         lr: 	1.0000E-07 loss: 	0.47624
 epoch [0048 / 0050] [0109/280] eta: 0 Days 0:1:0          lr: 	1.0000E-07 loss: 	0.38952
 epoch [0048 / 0050] [0209/280] eta: 0 Days 0:0:47         lr: 	1.0000E-07 loss: 	0.38301
49
starting val epoch 49
val [0049 / 0050] validation loss: 	0.39521
checkpoint
starting train epoch 49
 epoch [0049 / 0050] [0009/280] eta: 0 Days 0:0:36         lr: 	1.0000E-07 loss: 	0.36308
 epoch [0049 / 0050] [0109/280] eta: 0 Days 0:0:23         lr: 	1.0000E-07 loss: 	0.36704
 epoch [0049 / 0050] [0209/280] eta: 0 Days 0:0:9          lr: 	1.0000E-07 loss: 	0.38642
starting val epoch 0
val [0000 / 0050] validation loss: 	0.40106
Acute and unspecified renal failure                                                        & 0.699(0.735, 0.657) & 0.295 (0.360, 0.240)
fused_ehr test  0   best mean auc :0.699 mean auprc 0.295
                    CI AUROC (0.657, 0.735) CI AUPRC (0.240, 0.360)
                     AUROC accute 0.699 mixed 0.699 chronic 0.699
                     AUROC accute CI (0.657, 0.735) mixed (0.657 , 0.735) chronic (0.657, 0.735)
                     AUPRC accute  0.295 mixed 0.295 chronic 0.295
                     AUPRC accute CI  (0.240, 0.360) mixed (0.240,  0.360) chronic (0.240, 0.360)