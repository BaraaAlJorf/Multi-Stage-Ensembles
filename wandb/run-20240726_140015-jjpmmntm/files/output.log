Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type joint
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.76769
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 20:47:6        lr: 	1.0000E-07 loss: 	0.82328
 epoch [0000 / 0050] [0109/267] eta: 0 Days 3:28:15        lr: 	1.0000E-07 loss: 	0.69679
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:38:18        lr: 	1.0000E-07 loss: 	0.64948
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.56168
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:41:1         lr: 	1.0000E-07 loss: 	0.55181
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:25:1         lr: 	1.0000E-07 loss: 	0.50325
 epoch [0001 / 0050] [0209/267] eta: 0 Days 2:15:1         lr: 	1.0000E-07 loss: 	0.48868
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.47030
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:18:52        lr: 	1.0000E-07 loss: 	0.47917
 epoch [0002 / 0050] [0109/267] eta: 0 Days 2:12:18        lr: 	1.0000E-07 loss: 	0.43714
 epoch [0002 / 0050] [0209/267] eta: 0 Days 2:7:1          lr: 	1.0000E-07 loss: 	0.43680
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.44138
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 2:9:36         lr: 	1.0000E-07 loss: 	0.48060
 epoch [0003 / 0050] [0109/267] eta: 0 Days 2:5:21         lr: 	1.0000E-07 loss: 	0.43439
 epoch [0003 / 0050] [0209/267] eta: 0 Days 2:1:51         lr: 	1.0000E-07 loss: 	0.41816
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.43259
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 2:3:53         lr: 	1.0000E-07 loss: 	0.42774
 epoch [0004 / 0050] [0109/267] eta: 0 Days 2:0:40         lr: 	1.0000E-07 loss: 	0.39631
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:57:55        lr: 	1.0000E-07 loss: 	0.40518
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.42837
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:59:23        lr: 	1.0000E-07 loss: 	0.42684
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:56:48        lr: 	1.0000E-07 loss: 	0.40512
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:54:27        lr: 	1.0000E-07 loss: 	0.40942
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.42485
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:55:32        lr: 	1.0000E-07 loss: 	0.43129
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:53:13        lr: 	1.0000E-07 loss: 	0.41456
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:51:9         lr: 	1.0000E-07 loss: 	0.40822
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.42172
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:52:2         lr: 	1.0000E-07 loss: 	0.45430
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:50:4         lr: 	1.0000E-07 loss: 	0.39484
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:48:7         lr: 	1.0000E-07 loss: 	0.39482
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.41862
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:48:51        lr: 	1.0000E-07 loss: 	0.56142
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:47:1         lr: 	1.0000E-07 loss: 	0.40687
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:45:17        lr: 	1.0000E-07 loss: 	0.39613
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.41558
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:45:47        lr: 	1.0000E-07 loss: 	0.40995
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:44:3         lr: 	1.0000E-07 loss: 	0.40818
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:42:28        lr: 	1.0000E-07 loss: 	0.39810
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.41253
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:42:53        lr: 	1.0000E-07 loss: 	0.43894
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:41:16        lr: 	1.0000E-07 loss: 	0.41510
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:39:42        lr: 	1.0000E-07 loss: 	0.40385
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.41024
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:39:58        lr: 	1.0000E-07 loss: 	0.47346
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:38:26        lr: 	1.0000E-07 loss: 	0.39158
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:36:59        lr: 	1.0000E-07 loss: 	0.39378
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.40702
checkpoint
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:37:11        lr: 	1.0000E-07 loss: 	0.49240
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:35:44        lr: 	1.0000E-07 loss: 	0.40188
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:34:17        lr: 	1.0000E-07 loss: 	0.39163
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.40470
checkpoint
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:34:23        lr: 	1.0000E-07 loss: 	0.47373
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:33:0         lr: 	1.0000E-07 loss: 	0.38584
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:31:42        lr: 	1.0000E-07 loss: 	0.38817
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.40232
checkpoint
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:31:44        lr: 	1.0000E-07 loss: 	0.41774
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:30:23        lr: 	1.0000E-07 loss: 	0.39928
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:29:4         lr: 	1.0000E-07 loss: 	0.38505
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.40035
checkpoint
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:29:2         lr: 	1.0000E-07 loss: 	0.41710
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:27:42        lr: 	1.0000E-07 loss: 	0.37740
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:26:26        lr: 	1.0000E-07 loss: 	0.37464
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.39736
checkpoint
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:26:22        lr: 	1.0000E-07 loss: 	0.36817
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:25:5         lr: 	1.0000E-07 loss: 	0.37346
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:23:51        lr: 	1.0000E-07 loss: 	0.37868
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.39592
checkpoint
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:23:44        lr: 	1.0000E-07 loss: 	0.45143
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:22:30        lr: 	1.0000E-07 loss: 	0.36445
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:21:16        lr: 	1.0000E-07 loss: 	0.37594
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.39358
checkpoint
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:21:7         lr: 	1.0000E-07 loss: 	0.43888
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:19:53        lr: 	1.0000E-07 loss: 	0.35305
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:18:42        lr: 	1.0000E-07 loss: 	0.37071
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.39175
checkpoint
starting train epoch 19
 epoch [0019 / 0050] [0009/267] eta: 0 Days 1:18:30        lr: 	1.0000E-07 loss: 	0.34026
 epoch [0019 / 0050] [0109/267] eta: 0 Days 1:17:19        lr: 	1.0000E-07 loss: 	0.37310
 epoch [0019 / 0050] [0209/267] eta: 0 Days 1:16:8         lr: 	1.0000E-07 loss: 	0.37024
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.39117
checkpoint
starting train epoch 20
 epoch [0020 / 0050] [0009/267] eta: 0 Days 1:15:54        lr: 	1.0000E-07 loss: 	0.41637
 epoch [0020 / 0050] [0109/267] eta: 0 Days 1:14:45        lr: 	1.0000E-07 loss: 	0.36039
 epoch [0020 / 0050] [0209/267] eta: 0 Days 1:13:35        lr: 	1.0000E-07 loss: 	0.36307
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.38900
checkpoint
starting train epoch 21
 epoch [0021 / 0050] [0009/267] eta: 0 Days 1:13:20        lr: 	1.0000E-07 loss: 	0.42884
 epoch [0021 / 0050] [0109/267] eta: 0 Days 1:12:10        lr: 	1.0000E-07 loss: 	0.38276
 epoch [0021 / 0050] [0209/267] eta: 0 Days 1:11:2         lr: 	1.0000E-07 loss: 	0.36228
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.38889
checkpoint
starting train epoch 22
 epoch [0022 / 0050] [0009/267] eta: 0 Days 1:10:43        lr: 	1.0000E-07 loss: 	0.40797
 epoch [0022 / 0050] [0109/267] eta: 0 Days 1:9:36         lr: 	1.0000E-07 loss: 	0.37242
 epoch [0022 / 0050] [0209/267] eta: 0 Days 1:8:29         lr: 	1.0000E-07 loss: 	0.36671
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.38783
checkpoint
starting train epoch 23
 epoch [0023 / 0050] [0009/267] eta: 0 Days 1:8:10         lr: 	1.0000E-07 loss: 	0.38240
 epoch [0023 / 0050] [0109/267] eta: 0 Days 1:7:3          lr: 	1.0000E-07 loss: 	0.36605
 epoch [0023 / 0050] [0209/267] eta: 0 Days 1:5:56         lr: 	1.0000E-07 loss: 	0.36664
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.38830
checkpoint
starting train epoch 24
 epoch [0024 / 0050] [0009/267] eta: 0 Days 1:5:36         lr: 	1.0000E-07 loss: 	0.32598
 epoch [0024 / 0050] [0109/267] eta: 0 Days 1:4:30         lr: 	1.0000E-07 loss: 	0.35218
 epoch [0024 / 0050] [0209/267] eta: 0 Days 1:3:24         lr: 	1.0000E-07 loss: 	0.36357
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.38474
checkpoint
starting train epoch 25
 epoch [0025 / 0050] [0009/267] eta: 0 Days 1:3:3          lr: 	1.0000E-07 loss: 	0.39283
 epoch [0025 / 0050] [0109/267] eta: 0 Days 1:1:58         lr: 	1.0000E-07 loss: 	0.37515
 epoch [0025 / 0050] [0209/267] eta: 0 Days 1:0:53         lr: 	1.0000E-07 loss: 	0.36552
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.38537
checkpoint
starting train epoch 26
 epoch [0026 / 0050] [0009/267] eta: 0 Days 1:0:30         lr: 	1.0000E-07 loss: 	0.45739
 epoch [0026 / 0050] [0109/267] eta: 0 Days 0:59:25        lr: 	1.0000E-07 loss: 	0.35741
 epoch [0026 / 0050] [0209/267] eta: 0 Days 0:58:21        lr: 	1.0000E-07 loss: 	0.36308
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.38403
checkpoint
starting train epoch 27
 epoch [0027 / 0050] [0009/267] eta: 0 Days 0:57:58        lr: 	1.0000E-07 loss: 	0.28718
 epoch [0027 / 0050] [0109/267] eta: 0 Days 0:56:54        lr: 	1.0000E-07 loss: 	0.34962
 epoch [0027 / 0050] [0209/267] eta: 0 Days 0:55:50        lr: 	1.0000E-07 loss: 	0.35096
28
starting val epoch 28
val [0028 / 0050] validation loss: 	0.38147
checkpoint
starting train epoch 28
 epoch [0028 / 0050] [0009/267] eta: 0 Days 0:55:24        lr: 	1.0000E-07 loss: 	0.32608
 epoch [0028 / 0050] [0109/267] eta: 0 Days 0:54:21        lr: 	1.0000E-07 loss: 	0.35027
 epoch [0028 / 0050] [0209/267] eta: 0 Days 0:53:18        lr: 	1.0000E-07 loss: 	0.35824
29
starting val epoch 29
val [0029 / 0050] validation loss: 	0.38326
checkpoint
starting train epoch 29
 epoch [0029 / 0050] [0009/267] eta: 0 Days 0:52:52        lr: 	1.0000E-07 loss: 	0.36333
 epoch [0029 / 0050] [0109/267] eta: 0 Days 0:51:49        lr: 	1.0000E-07 loss: 	0.35717
 epoch [0029 / 0050] [0209/267] eta: 0 Days 0:50:46        lr: 	1.0000E-07 loss: 	0.35353
30
starting val epoch 30
val [0030 / 0050] validation loss: 	0.38344
checkpoint
starting train epoch 30
 epoch [0030 / 0050] [0009/267] eta: 0 Days 0:50:19        lr: 	1.0000E-07 loss: 	0.39988
 epoch [0030 / 0050] [0109/267] eta: 0 Days 0:49:17        lr: 	1.0000E-07 loss: 	0.35579
 epoch [0030 / 0050] [0209/267] eta: 0 Days 0:48:15        lr: 	1.0000E-07 loss: 	0.35066
31
starting val epoch 31
val [0031 / 0050] validation loss: 	0.37877
checkpoint
starting train epoch 31
 epoch [0031 / 0050] [0009/267] eta: 0 Days 0:47:47        lr: 	1.0000E-07 loss: 	0.45984
 epoch [0031 / 0050] [0109/267] eta: 0 Days 0:46:45        lr: 	1.0000E-07 loss: 	0.34329
 epoch [0031 / 0050] [0209/267] eta: 0 Days 0:45:43        lr: 	1.0000E-07 loss: 	0.35495
32
starting val epoch 32
val [0032 / 0050] validation loss: 	0.38030
checkpoint
starting train epoch 32
 epoch [0032 / 0050] [0009/267] eta: 0 Days 0:45:15        lr: 	1.0000E-07 loss: 	0.41291
 epoch [0032 / 0050] [0109/267] eta: 0 Days 0:44:13        lr: 	1.0000E-07 loss: 	0.36037
 epoch [0032 / 0050] [0209/267] eta: 0 Days 0:43:12        lr: 	1.0000E-07 loss: 	0.34971
33
starting val epoch 33
val [0033 / 0050] validation loss: 	0.38276
checkpoint
starting train epoch 33
 epoch [0033 / 0050] [0009/267] eta: 0 Days 0:42:42        lr: 	1.0000E-07 loss: 	0.34461
 epoch [0033 / 0050] [0109/267] eta: 0 Days 0:41:41        lr: 	1.0000E-07 loss: 	0.35115
 epoch [0033 / 0050] [0209/267] eta: 0 Days 0:40:40        lr: 	1.0000E-07 loss: 	0.34125
34
starting val epoch 34
val [0034 / 0050] validation loss: 	0.37721
checkpoint
starting train epoch 34
 epoch [0034 / 0050] [0009/267] eta: 0 Days 0:40:10        lr: 	1.0000E-07 loss: 	0.33666
 epoch [0034 / 0050] [0109/267] eta: 0 Days 0:39:10        lr: 	1.0000E-07 loss: 	0.35070
 epoch [0034 / 0050] [0209/267] eta: 0 Days 0:38:9         lr: 	1.0000E-07 loss: 	0.34635
35
starting val epoch 35
val [0035 / 0050] validation loss: 	0.37958
checkpoint
starting train epoch 35
 epoch [0035 / 0050] [0009/267] eta: 0 Days 0:37:38        lr: 	1.0000E-07 loss: 	0.38546
 epoch [0035 / 0050] [0109/267] eta: 0 Days 0:36:39        lr: 	1.0000E-07 loss: 	0.34438
 epoch [0035 / 0050] [0209/267] eta: 0 Days 0:35:39        lr: 	1.0000E-07 loss: 	0.34027
36
starting val epoch 36
val [0036 / 0050] validation loss: 	0.37762
checkpoint
starting train epoch 36
 epoch [0036 / 0050] [0009/267] eta: 0 Days 0:35:7         lr: 	1.0000E-07 loss: 	0.40453
 epoch [0036 / 0050] [0109/267] eta: 0 Days 0:34:8         lr: 	1.0000E-07 loss: 	0.34447
 epoch [0036 / 0050] [0209/267] eta: 0 Days 0:33:8         lr: 	1.0000E-07 loss: 	0.34184
37
starting val epoch 37
val [0037 / 0050] validation loss: 	0.37705
checkpoint
starting train epoch 37
 epoch [0037 / 0050] [0009/267] eta: 0 Days 0:32:36        lr: 	1.0000E-07 loss: 	0.43475
 epoch [0037 / 0050] [0109/267] eta: 0 Days 0:31:37        lr: 	1.0000E-07 loss: 	0.34192
 epoch [0037 / 0050] [0209/267] eta: 0 Days 0:30:37        lr: 	1.0000E-07 loss: 	0.34643
38
starting val epoch 38
val [0038 / 0050] validation loss: 	0.37948
checkpoint
starting train epoch 38
 epoch [0038 / 0050] [0009/267] eta: 0 Days 0:30:5         lr: 	1.0000E-07 loss: 	0.39369
 epoch [0038 / 0050] [0109/267] eta: 0 Days 0:29:5         lr: 	1.0000E-07 loss: 	0.34134
 epoch [0038 / 0050] [0209/267] eta: 0 Days 0:28:7         lr: 	1.0000E-07 loss: 	0.33985
39
starting val epoch 39
val [0039 / 0050] validation loss: 	0.37968
checkpoint
starting train epoch 39
 epoch [0039 / 0050] [0009/267] eta: 0 Days 0:27:34        lr: 	1.0000E-07 loss: 	0.35743
 epoch [0039 / 0050] [0109/267] eta: 0 Days 0:26:35        lr: 	1.0000E-07 loss: 	0.35201
 epoch [0039 / 0050] [0209/267] eta: 0 Days 0:25:36        lr: 	1.0000E-07 loss: 	0.34271
40
starting val epoch 40
val [0040 / 0050] validation loss: 	0.37655
starting train epoch 40
 epoch [0040 / 0050] [0009/267] eta: 0 Days 0:25:1         lr: 	1.0000E-07 loss: 	0.36614
 epoch [0040 / 0050] [0109/267] eta: 0 Days 0:24:3         lr: 	1.0000E-07 loss: 	0.34047
 epoch [0040 / 0050] [0209/267] eta: 0 Days 0:23:5         lr: 	1.0000E-07 loss: 	0.34361
41
starting val epoch 41
val [0041 / 0050] validation loss: 	0.37959
checkpoint
starting train epoch 41
 epoch [0041 / 0050] [0009/267] eta: 0 Days 0:22:30        lr: 	1.0000E-07 loss: 	0.41113
 epoch [0041 / 0050] [0109/267] eta: 0 Days 0:21:32        lr: 	1.0000E-07 loss: 	0.33718
 epoch [0041 / 0050] [0209/267] eta: 0 Days 0:20:34        lr: 	1.0000E-07 loss: 	0.33347
42
starting val epoch 42
val [0042 / 0050] validation loss: 	0.37573
starting train epoch 42
 epoch [0042 / 0050] [0009/267] eta: 0 Days 0:19:59        lr: 	1.0000E-07 loss: 	0.33699
 epoch [0042 / 0050] [0109/267] eta: 0 Days 0:19:1         lr: 	1.0000E-07 loss: 	0.32445
 epoch [0042 / 0050] [0209/267] eta: 0 Days 0:18:3         lr: 	1.0000E-07 loss: 	0.32632
43
starting val epoch 43
val [0043 / 0050] validation loss: 	0.37416
starting train epoch 43
 epoch [0043 / 0050] [0009/267] eta: 0 Days 0:17:27        lr: 	1.0000E-07 loss: 	0.27195
 epoch [0043 / 0050] [0109/267] eta: 0 Days 0:16:30        lr: 	1.0000E-07 loss: 	0.32410
 epoch [0043 / 0050] [0209/267] eta: 0 Days 0:15:32        lr: 	1.0000E-07 loss: 	0.33151
44
starting val epoch 44
val [0044 / 0050] validation loss: 	0.37597
checkpoint
starting train epoch 44
 epoch [0044 / 0050] [0009/267] eta: 0 Days 0:14:57        lr: 	1.0000E-07 loss: 	0.30734
 epoch [0044 / 0050] [0109/267] eta: 0 Days 0:13:59        lr: 	1.0000E-07 loss: 	0.34108
 epoch [0044 / 0050] [0209/267] eta: 0 Days 0:13:2         lr: 	1.0000E-07 loss: 	0.33288
45
starting val epoch 45
val [0045 / 0050] validation loss: 	0.37530
checkpoint
starting train epoch 45
 epoch [0045 / 0050] [0009/267] eta: 0 Days 0:12:26        lr: 	1.0000E-07 loss: 	0.40679
 epoch [0045 / 0050] [0109/267] eta: 0 Days 0:11:29        lr: 	1.0000E-07 loss: 	0.34096
 epoch [0045 / 0050] [0209/267] eta: 0 Days 0:10:32        lr: 	1.0000E-07 loss: 	0.32884
46
starting val epoch 46
val [0046 / 0050] validation loss: 	0.37592
checkpoint
starting train epoch 46
 epoch [0046 / 0050] [0009/267] eta: 0 Days 0:9:56         lr: 	1.0000E-07 loss: 	0.29546
 epoch [0046 / 0050] [0109/267] eta: 0 Days 0:8:59         lr: 	1.0000E-07 loss: 	0.32393
 epoch [0046 / 0050] [0209/267] eta: 0 Days 0:8:2          lr: 	1.0000E-07 loss: 	0.32694
47
starting val epoch 47
val [0047 / 0050] validation loss: 	0.37618
checkpoint
starting train epoch 47
 epoch [0047 / 0050] [0009/267] eta: 0 Days 0:7:25         lr: 	1.0000E-07 loss: 	0.36294
 epoch [0047 / 0050] [0109/267] eta: 0 Days 0:6:28         lr: 	1.0000E-07 loss: 	0.32836
 epoch [0047 / 0050] [0209/267] eta: 0 Days 0:5:32         lr: 	1.0000E-07 loss: 	0.32746
48
starting val epoch 48
val [0048 / 0050] validation loss: 	0.37440
checkpoint
starting train epoch 48
 epoch [0048 / 0050] [0009/267] eta: 0 Days 0:4:55         lr: 	1.0000E-07 loss: 	0.43889
 epoch [0048 / 0050] [0109/267] eta: 0 Days 0:3:58         lr: 	1.0000E-07 loss: 	0.34126
 epoch [0048 / 0050] [0209/267] eta: 0 Days 0:3:2          lr: 	1.0000E-07 loss: 	0.32613
49
starting val epoch 49
val [0049 / 0050] validation loss: 	0.37601
checkpoint
starting train epoch 49
 epoch [0049 / 0050] [0009/267] eta: 0 Days 0:2:24         lr: 	1.0000E-07 loss: 	0.26739
 epoch [0049 / 0050] [0109/267] eta: 0 Days 0:1:28         lr: 	1.0000E-07 loss: 	0.31389
 epoch [0049 / 0050] [0209/267] eta: 0 Days 0:0:32         lr: 	1.0000E-07 loss: 	0.32230
starting val epoch 0
val [0000 / 0050] validation loss: 	0.37030
Acute and unspecified renal failure                                                        & 0.771(0.807, 0.733) & 0.382 (0.458, 0.315)
fused_ehr test  0   best mean auc :0.771 mean auprc 0.382
                    CI AUROC (0.733, 0.807) CI AUPRC (0.315, 0.458)
                     AUROC accute 0.771 mixed 0.771 chronic 0.771
                     AUROC accute CI (0.733, 0.807) mixed (0.733 , 0.807) chronic (0.733, 0.807)
                     AUPRC accute  0.382 mixed 0.382 chronic 0.382
                     AUPRC accute CI  (0.315, 0.458) mixed (0.315,  0.458) chronic (0.315, 0.458)