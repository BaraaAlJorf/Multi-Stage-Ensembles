Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.78205
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 15:16:35       lr: 	1.0000E-05 loss: 	0.59217 loss align 0.0000
 epoch [0000 / 0050] [0109/280] eta: 0 Days 2:11:12        lr: 	1.0000E-05 loss: 	0.45392 loss align 0.0000
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:34:28        lr: 	1.0000E-05 loss: 	0.42600 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.37914
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:35:16        lr: 	1.0000E-05 loss: 	0.40811 loss align 0.0000
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:24:4         lr: 	1.0000E-05 loss: 	0.36859 loss align 0.0000
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:17:13        lr: 	1.0000E-05 loss: 	0.36587 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.37161
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:19:44        lr: 	1.0000E-05 loss: 	0.44547 loss align 0.0000
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:15:3         lr: 	1.0000E-05 loss: 	0.33148 loss align 0.0000
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:11:35        lr: 	1.0000E-05 loss: 	0.34407 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.35090
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:13:38        lr: 	1.0000E-05 loss: 	0.34512 loss align 0.0000
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:10:57        lr: 	1.0000E-05 loss: 	0.33406 loss align 0.0000
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:8:40         lr: 	1.0000E-05 loss: 	0.32824 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.37145
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:10:19        lr: 	1.0000E-05 loss: 	0.40071 loss align 0.0000
 epoch [0004 / 0050] [0109/280] eta: 0 Days 1:8:10         lr: 	1.0000E-05 loss: 	0.31909 loss align 0.0000
 epoch [0004 / 0050] [0209/280] eta: 0 Days 1:6:31         lr: 	1.0000E-05 loss: 	0.31563 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.33750
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 1:7:57         lr: 	1.0000E-05 loss: 	0.34916 loss align 0.0000
 epoch [0005 / 0050] [0109/280] eta: 0 Days 1:6:22         lr: 	1.0000E-05 loss: 	0.30754 loss align 0.0000
 epoch [0005 / 0050] [0209/280] eta: 0 Days 1:5:0          lr: 	1.0000E-05 loss: 	0.30430 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.36159
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 1:6:3          lr: 	1.0000E-05 loss: 	0.28082 loss align 0.0000
 epoch [0006 / 0050] [0109/280] eta: 0 Days 1:4:37         lr: 	1.0000E-05 loss: 	0.29766 loss align 0.0000
 epoch [0006 / 0050] [0209/280] eta: 0 Days 1:3:20         lr: 	1.0000E-05 loss: 	0.30006 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.33574
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 1:3:58         lr: 	1.0000E-05 loss: 	0.39283 loss align 0.0000
 epoch [0007 / 0050] [0109/280] eta: 0 Days 1:2:59         lr: 	1.0000E-05 loss: 	0.28367 loss align 0.0000
 epoch [0007 / 0050] [0209/280] eta: 0 Days 1:1:51         lr: 	1.0000E-05 loss: 	0.27362 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.34492
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 1:2:2          lr: 	1.0000E-05 loss: 	0.20718 loss align 0.0000
 epoch [0008 / 0050] [0109/280] eta: 0 Days 1:0:57         lr: 	1.0000E-05 loss: 	0.28279 loss align 0.0000
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:59:54        lr: 	1.0000E-05 loss: 	0.26836 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.36404
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 1:0:5          lr: 	1.0000E-05 loss: 	0.22069 loss align 0.0000
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:59:3         lr: 	1.0000E-05 loss: 	0.24368 loss align 0.0000
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:58:2         lr: 	1.0000E-05 loss: 	0.25057 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.37958
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:58:5         lr: 	1.0000E-05 loss: 	0.28005 loss align 0.0000
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:57:7         lr: 	1.0000E-05 loss: 	0.23690 loss align 0.0000
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:56:15        lr: 	1.0000E-05 loss: 	0.23614 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.36031
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:56:17        lr: 	1.0000E-05 loss: 	0.27206 loss align 0.0000
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:55:25        lr: 	1.0000E-05 loss: 	0.23280 loss align 0.0000
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:54:33        lr: 	1.0000E-05 loss: 	0.22666 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.42305
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:54:36        lr: 	1.0000E-05 loss: 	0.27492 loss align 0.0000
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:53:44        lr: 	1.0000E-05 loss: 	0.20737 loss align 0.0000
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:52:53        lr: 	1.0000E-05 loss: 	0.20672 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.45181
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:52:50        lr: 	1.0000E-05 loss: 	0.29858 loss align 0.0000
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:52:3         lr: 	1.0000E-05 loss: 	0.21608 loss align 0.0000
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:51:16        lr: 	1.0000E-05 loss: 	0.21887 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.44623
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:51:14        lr: 	1.0000E-05 loss: 	0.17914 loss align 0.0000
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:50:29        lr: 	1.0000E-05 loss: 	0.17862 loss align 0.0000
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:49:42        lr: 	1.0000E-05 loss: 	0.18956 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.45870
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:49:35        lr: 	1.0000E-05 loss: 	0.10063 loss align 0.0000
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:48:51        lr: 	1.0000E-05 loss: 	0.18147 loss align 0.0000
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:48:7         lr: 	1.0000E-05 loss: 	0.18535 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.42897
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:47:58        lr: 	1.0000E-05 loss: 	0.19103 loss align 0.0000
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:47:13        lr: 	1.0000E-05 loss: 	0.17000 loss align 0.0000
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:46:32        lr: 	1.0000E-05 loss: 	0.16618 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.42061
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:46:26        lr: 	1.0000E-05 loss: 	0.13174 loss align 0.0000
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:45:45        lr: 	1.0000E-05 loss: 	0.13996 loss align 0.0000
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:45:4         lr: 	1.0000E-05 loss: 	0.14654 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.48993
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:44:56        lr: 	1.0000E-05 loss: 	0.16770 loss align 0.0000
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:44:15        lr: 	1.0000E-05 loss: 	0.15807 loss align 0.0000
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:43:35        lr: 	1.0000E-05 loss: 	0.15653 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.50744
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:43:24        lr: 	1.0000E-05 loss: 	0.13993 loss align 0.0000
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:42:44        lr: 	1.0000E-05 loss: 	0.13336 loss align 0.0000
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:42:6         lr: 	1.0000E-05 loss: 	0.13222 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.53336
starting train epoch 20
 epoch [0020 / 0050] [0009/280] eta: 0 Days 0:41:57        lr: 	1.0000E-05 loss: 	0.14629 loss align 0.0000
 epoch [0020 / 0050] [0109/280] eta: 0 Days 0:41:20        lr: 	1.0000E-05 loss: 	0.10874 loss align 0.0000
 epoch [0020 / 0050] [0209/280] eta: 0 Days 0:40:42        lr: 	1.0000E-05 loss: 	0.11265 loss align 0.0000
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.54349
starting train epoch 21
 epoch [0021 / 0050] [0009/280] eta: 0 Days 0:40:30        lr: 	1.0000E-05 loss: 	0.12968 loss align 0.0000
 epoch [0021 / 0050] [0109/280] eta: 0 Days 0:39:53        lr: 	1.0000E-05 loss: 	0.11468 loss align 0.0000
 epoch [0021 / 0050] [0209/280] eta: 0 Days 0:39:15        lr: 	1.0000E-05 loss: 	0.10187 loss align 0.0000
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.57906
starting val epoch 0
val [0000 / 0050] validation loss: 	0.35549
Acute and unspecified renal failure                                                        & 0.805(0.839, 0.770) & 0.472 (0.545, 0.401)
fused_ehr test  0   best mean auc :0.805 mean auprc 0.472
                    CI AUROC (0.770, 0.839) CI AUPRC (0.401, 0.545)
                     AUROC accute 0.805 mixed 0.805 chronic 0.805
                     AUROC accute CI (0.770, 0.839) mixed (0.770 , 0.839) chronic (0.770, 0.839)
                     AUPRC accute  0.472 mixed 0.472 chronic 0.472
                     AUPRC accute CI  (0.401, 0.545) mixed (0.401,  0.545) chronic (0.401, 0.545)