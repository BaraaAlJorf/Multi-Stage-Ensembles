Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
running for fusion_type late
0
starting val epoch 0
val [0000 / 0020] validation loss: 	1.09854
checkpoint
starting train epoch 0
 epoch [0000 / 0020] [0009/267] eta: 0 Days 7:24:16        lr: 	1.0000E-05 loss: 	0.68812
 epoch [0000 / 0020] [0109/267] eta: 0 Days 1:39:16        lr: 	1.0000E-05 loss: 	0.43034
 epoch [0000 / 0020] [0209/267] eta: 0 Days 1:21:6         lr: 	1.0000E-05 loss: 	0.43290
1
starting val epoch 1
val [0001 / 0020] validation loss: 	0.41986
checkpoint
starting train epoch 1
 epoch [0001 / 0020] [0009/267] eta: 0 Days 1:23:21        lr: 	1.0000E-05 loss: 	0.44218
 epoch [0001 / 0020] [0109/267] eta: 0 Days 1:16:31        lr: 	1.0000E-05 loss: 	0.39376
 epoch [0001 / 0020] [0209/267] eta: 0 Days 1:11:56        lr: 	1.0000E-05 loss: 	0.37542
2
starting val epoch 2
val [0002 / 0020] validation loss: 	0.39112
checkpoint
starting train epoch 2
 epoch [0002 / 0020] [0009/267] eta: 0 Days 1:13:13        lr: 	1.0000E-05 loss: 	0.42542
 epoch [0002 / 0020] [0109/267] eta: 0 Days 1:9:46         lr: 	1.0000E-05 loss: 	0.35462
 epoch [0002 / 0020] [0209/267] eta: 0 Days 1:6:47         lr: 	1.0000E-05 loss: 	0.34579
3
starting val epoch 3
val [0003 / 0020] validation loss: 	0.38332
checkpoint
starting train epoch 3
 epoch [0003 / 0020] [0009/267] eta: 0 Days 1:7:18         lr: 	1.0000E-05 loss: 	0.40658
 epoch [0003 / 0020] [0109/267] eta: 0 Days 1:4:40         lr: 	1.0000E-05 loss: 	0.31917
 epoch [0003 / 0020] [0209/267] eta: 0 Days 1:2:21         lr: 	1.0000E-05 loss: 	0.31223
4
starting val epoch 4
val [0004 / 0020] validation loss: 	0.38297
starting train epoch 4
 epoch [0004 / 0020] [0009/267] eta: 0 Days 1:2:6          lr: 	1.0000E-05 loss: 	0.32096
 epoch [0004 / 0020] [0109/267] eta: 0 Days 0:59:59        lr: 	1.0000E-05 loss: 	0.29709
 epoch [0004 / 0020] [0209/267] eta: 0 Days 0:57:55        lr: 	1.0000E-05 loss: 	0.27773
5
starting val epoch 5
val [0005 / 0020] validation loss: 	0.42435
starting train epoch 5
 epoch [0005 / 0020] [0009/267] eta: 0 Days 0:57:37        lr: 	1.0000E-05 loss: 	0.22321
 epoch [0005 / 0020] [0109/267] eta: 0 Days 0:55:43        lr: 	1.0000E-05 loss: 	0.21936
 epoch [0005 / 0020] [0209/267] eta: 0 Days 0:53:49        lr: 	1.0000E-05 loss: 	0.23893
6
starting val epoch 6
val [0006 / 0020] validation loss: 	0.47748
starting train epoch 6
 epoch [0006 / 0020] [0009/267] eta: 0 Days 0:53:23        lr: 	1.0000E-05 loss: 	0.20981
 epoch [0006 / 0020] [0109/267] eta: 0 Days 0:51:32        lr: 	1.0000E-05 loss: 	0.17476
 epoch [0006 / 0020] [0209/267] eta: 0 Days 0:49:48        lr: 	1.0000E-05 loss: 	0.18475
7
starting val epoch 7
val [0007 / 0020] validation loss: 	0.46575
starting train epoch 7
 epoch [0007 / 0020] [0009/267] eta: 0 Days 0:49:15        lr: 	1.0000E-05 loss: 	0.13680
 epoch [0007 / 0020] [0109/267] eta: 0 Days 0:47:34        lr: 	1.0000E-05 loss: 	0.11562
 epoch [0007 / 0020] [0209/267] eta: 0 Days 0:45:53        lr: 	1.0000E-05 loss: 	0.10951
8
starting val epoch 8
val [0008 / 0020] validation loss: 	0.67770
starting train epoch 8
 epoch [0008 / 0020] [0009/267] eta: 0 Days 0:45:17        lr: 	1.0000E-05 loss: 	0.06317
 epoch [0008 / 0020] [0109/267] eta: 0 Days 0:43:38        lr: 	1.0000E-05 loss: 	0.07721
 epoch [0008 / 0020] [0209/267] eta: 0 Days 0:42:0         lr: 	1.0000E-05 loss: 	0.08794
9
starting val epoch 9
val [0009 / 0020] validation loss: 	0.77349
starting train epoch 9
 epoch [0009 / 0020] [0009/267] eta: 0 Days 0:41:21        lr: 	1.0000E-05 loss: 	0.05145
 epoch [0009 / 0020] [0109/267] eta: 0 Days 0:39:45        lr: 	1.0000E-05 loss: 	0.05533
 epoch [0009 / 0020] [0209/267] eta: 0 Days 0:38:11        lr: 	1.0000E-05 loss: 	0.06693
10
starting val epoch 10
val [0010 / 0020] validation loss: 	0.72636
checkpoint
starting train epoch 10
 epoch [0010 / 0020] [0009/267] eta: 0 Days 0:37:34        lr: 	1.0000E-05 loss: 	0.04554
 epoch [0010 / 0020] [0109/267] eta: 0 Days 0:36:1         lr: 	1.0000E-05 loss: 	0.05029
 epoch [0010 / 0020] [0209/267] eta: 0 Days 0:34:29        lr: 	1.0000E-05 loss: 	0.04616
11
starting val epoch 11
val [0011 / 0020] validation loss: 	0.76305
starting train epoch 11
 epoch [0011 / 0020] [0009/267] eta: 0 Days 0:33:45        lr: 	1.0000E-05 loss: 	0.04159
 epoch [0011 / 0020] [0109/267] eta: 0 Days 0:32:14        lr: 	1.0000E-05 loss: 	0.03676
 epoch [0011 / 0020] [0209/267] eta: 0 Days 0:30:43        lr: 	1.0000E-05 loss: 	0.03956
12
starting val epoch 12
val [0012 / 0020] validation loss: 	0.92830
starting train epoch 12
 epoch [0012 / 0020] [0009/267] eta: 0 Days 0:29:55        lr: 	1.0000E-05 loss: 	0.03630
 epoch [0012 / 0020] [0109/267] eta: 0 Days 0:28:24        lr: 	1.0000E-05 loss: 	0.04550
 epoch [0012 / 0020] [0209/267] eta: 0 Days 0:26:55        lr: 	1.0000E-05 loss: 	0.04009
13
starting val epoch 13
val [0013 / 0020] validation loss: 	0.89541
starting train epoch 13
 epoch [0013 / 0020] [0009/267] eta: 0 Days 0:26:6         lr: 	1.0000E-05 loss: 	0.03135
 epoch [0013 / 0020] [0109/267] eta: 0 Days 0:24:38        lr: 	1.0000E-05 loss: 	0.02644
 epoch [0013 / 0020] [0209/267] eta: 0 Days 0:23:11        lr: 	1.0000E-05 loss: 	0.02670
14
starting val epoch 14
val [0014 / 0020] validation loss: 	0.99068
starting train epoch 14
 epoch [0014 / 0020] [0009/267] eta: 0 Days 0:22:20        lr: 	1.0000E-05 loss: 	0.01791
 epoch [0014 / 0020] [0109/267] eta: 0 Days 0:20:52        lr: 	1.0000E-05 loss: 	0.02524
 epoch [0014 / 0020] [0209/267] eta: 0 Days 0:19:24        lr: 	1.0000E-05 loss: 	0.02517
15
starting val epoch 15
val [0015 / 0020] validation loss: 	1.05593
starting train epoch 15
 epoch [0015 / 0020] [0009/267] eta: 0 Days 0:18:33        lr: 	1.0000E-05 loss: 	0.02665
 epoch [0015 / 0020] [0109/267] eta: 0 Days 0:17:6         lr: 	1.0000E-05 loss: 	0.02406
 epoch [0015 / 0020] [0209/267] eta: 0 Days 0:15:40        lr: 	1.0000E-05 loss: 	0.02591
16
starting val epoch 16
val [0016 / 0020] validation loss: 	1.03246
starting train epoch 16
 epoch [0016 / 0020] [0009/267] eta: 0 Days 0:14:48        lr: 	1.0000E-05 loss: 	0.01816
 epoch [0016 / 0020] [0109/267] eta: 0 Days 0:13:22        lr: 	1.0000E-05 loss: 	0.01247
 epoch [0016 / 0020] [0209/267] eta: 0 Days 0:11:57        lr: 	1.0000E-05 loss: 	0.02188
17
starting val epoch 17
val [0017 / 0020] validation loss: 	1.02357
starting train epoch 17
 epoch [0017 / 0020] [0009/267] eta: 0 Days 0:11:3         lr: 	1.0000E-05 loss: 	0.00979
 epoch [0017 / 0020] [0109/267] eta: 0 Days 0:9:38         lr: 	1.0000E-05 loss: 	0.00848
 epoch [0017 / 0020] [0209/267] eta: 0 Days 0:8:13         lr: 	1.0000E-05 loss: 	0.01549
18
starting val epoch 18
val [0018 / 0020] validation loss: 	1.26205
starting train epoch 18
 epoch [0018 / 0020] [0009/267] eta: 0 Days 0:7:19         lr: 	1.0000E-05 loss: 	0.00166
 epoch [0018 / 0020] [0109/267] eta: 0 Days 0:5:54         lr: 	1.0000E-05 loss: 	0.02239
 epoch [0018 / 0020] [0209/267] eta: 0 Days 0:4:30         lr: 	1.0000E-05 loss: 	0.02034
19
starting val epoch 19
val [0019 / 0020] validation loss: 	1.18425
starting train epoch 19
 epoch [0019 / 0020] [0009/267] eta: 0 Days 0:3:35         lr: 	1.0000E-05 loss: 	0.00273
 epoch [0019 / 0020] [0109/267] eta: 0 Days 0:2:11         lr: 	1.0000E-05 loss: 	0.01504
