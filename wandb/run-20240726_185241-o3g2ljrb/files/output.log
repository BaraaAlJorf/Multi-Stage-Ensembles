Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.98829
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 16:40:30       lr: 	1.0000E-06 loss: 	1.02000 loss align 0.0000
 epoch [0000 / 0050] [0109/267] eta: 0 Days 3:16:6         lr: 	1.0000E-06 loss: 	0.66099 loss align 0.0000
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:36:51        lr: 	1.0000E-06 loss: 	0.54690 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.42697
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:43:13        lr: 	1.0000E-06 loss: 	0.47776 loss align 0.0000
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:29:28        lr: 	1.0000E-06 loss: 	0.41616 loss align 0.0000
 epoch [0001 / 0050] [0209/267] eta: 0 Days 2:21:4         lr: 	1.0000E-06 loss: 	0.40758 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.41262
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:25:42        lr: 	1.0000E-06 loss: 	0.49125 loss align 0.0000
 epoch [0002 / 0050] [0109/267] eta: 0 Days 2:19:42        lr: 	1.0000E-06 loss: 	0.39209 loss align 0.0000
 epoch [0002 / 0050] [0209/267] eta: 0 Days 2:14:54        lr: 	1.0000E-06 loss: 	0.39505 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.40413
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 2:17:55        lr: 	1.0000E-06 loss: 	0.43526 loss align 0.0000
 epoch [0003 / 0050] [0109/267] eta: 0 Days 2:13:52        lr: 	1.0000E-06 loss: 	0.37760 loss align 0.0000
 epoch [0003 / 0050] [0209/267] eta: 0 Days 2:10:21        lr: 	1.0000E-06 loss: 	0.37828 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.39048
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 2:12:32        lr: 	1.0000E-06 loss: 	0.39302 loss align 0.0000
 epoch [0004 / 0050] [0109/267] eta: 0 Days 2:9:35         lr: 	1.0000E-06 loss: 	0.37575 loss align 0.0000
 epoch [0004 / 0050] [0209/267] eta: 0 Days 2:6:51         lr: 	1.0000E-06 loss: 	0.37312 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.38972
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 2:8:25         lr: 	1.0000E-06 loss: 	0.44423 loss align 0.0000
 epoch [0005 / 0050] [0109/267] eta: 0 Days 2:5:50         lr: 	1.0000E-06 loss: 	0.35741 loss align 0.0000
 epoch [0005 / 0050] [0209/267] eta: 0 Days 2:3:24         lr: 	1.0000E-06 loss: 	0.35976 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.38820
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 2:4:40         lr: 	1.0000E-06 loss: 	0.41842 loss align 0.0000
 epoch [0006 / 0050] [0109/267] eta: 0 Days 2:2:18         lr: 	1.0000E-06 loss: 	0.36172 loss align 0.0000
 epoch [0006 / 0050] [0209/267] eta: 0 Days 2:0:12         lr: 	1.0000E-06 loss: 	0.35356 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.38131
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 2:1:5          lr: 	1.0000E-06 loss: 	0.36470 loss align 0.0000
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:59:4         lr: 	1.0000E-06 loss: 	0.32782 loss align 0.0000
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:57:5         lr: 	1.0000E-06 loss: 	0.32129 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.36672
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:57:47        lr: 	1.0000E-06 loss: 	0.34848 loss align 0.0000
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:55:53        lr: 	1.0000E-06 loss: 	0.30611 loss align 0.0000
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:54:3         lr: 	1.0000E-06 loss: 	0.30414 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.36980
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:54:32        lr: 	1.0000E-06 loss: 	0.37883 loss align 0.0000
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:52:43        lr: 	1.0000E-06 loss: 	0.28982 loss align 0.0000
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:51:2         lr: 	1.0000E-06 loss: 	0.28189 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.37758
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:51:23        lr: 	1.0000E-06 loss: 	0.29047 loss align 0.0000
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:49:44        lr: 	1.0000E-06 loss: 	0.28600 loss align 0.0000
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:48:7         lr: 	1.0000E-06 loss: 	0.28140 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.35795
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:48:23        lr: 	1.0000E-06 loss: 	0.29278 loss align 0.0000
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:46:48        lr: 	1.0000E-06 loss: 	0.27683 loss align 0.0000
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:45:17        lr: 	1.0000E-06 loss: 	0.26755 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.36373
checkpoint
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:45:26        lr: 	1.0000E-06 loss: 	0.25294 loss align 0.0000
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:43:56        lr: 	1.0000E-06 loss: 	0.22732 loss align 0.0000
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:42:26        lr: 	1.0000E-06 loss: 	0.24538 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.38473
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:42:16        lr: 	1.0000E-06 loss: 	0.20138 loss align 0.0000
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:40:49        lr: 	1.0000E-06 loss: 	0.24598 loss align 0.0000
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:39:22        lr: 	1.0000E-06 loss: 	0.23609 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.35178
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:39:11        lr: 	1.0000E-06 loss: 	0.30033 loss align 0.0000
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:37:47        lr: 	1.0000E-06 loss: 	0.23671 loss align 0.0000
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:36:23        lr: 	1.0000E-06 loss: 	0.23821 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.36271
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:36:9         lr: 	1.0000E-06 loss: 	0.30411 loss align 0.0000
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:34:47        lr: 	1.0000E-06 loss: 	0.23657 loss align 0.0000
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:33:28        lr: 	1.0000E-06 loss: 	0.23117 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.40846
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:33:13        lr: 	1.0000E-06 loss: 	0.19106 loss align 0.0000
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:31:54        lr: 	1.0000E-06 loss: 	0.21924 loss align 0.0000
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:30:35        lr: 	1.0000E-06 loss: 	0.21444 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.42674
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:30:17        lr: 	1.0000E-06 loss: 	0.20898 loss align 0.0000
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:28:59        lr: 	1.0000E-06 loss: 	0.19162 loss align 0.0000
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:27:42        lr: 	1.0000E-06 loss: 	0.20454 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.43816
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:27:21        lr: 	1.0000E-06 loss: 	0.16921 loss align 0.0000
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:26:6         lr: 	1.0000E-06 loss: 	0.18868 loss align 0.0000
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:24:51        lr: 	1.0000E-06 loss: 	0.19782 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.43822
starting train epoch 19
 epoch [0019 / 0050] [0009/267] eta: 0 Days 1:24:28        lr: 	1.0000E-06 loss: 	0.21827 loss align 0.0000
 epoch [0019 / 0050] [0109/267] eta: 0 Days 1:23:14        lr: 	1.0000E-06 loss: 	0.17036 loss align 0.0000
 epoch [0019 / 0050] [0209/267] eta: 0 Days 1:21:59        lr: 	1.0000E-06 loss: 	0.17960 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.47074
starting train epoch 20
 epoch [0020 / 0050] [0009/267] eta: 0 Days 1:21:36        lr: 	1.0000E-06 loss: 	0.10720 loss align 0.0000
 epoch [0020 / 0050] [0109/267] eta: 0 Days 1:20:23        lr: 	1.0000E-06 loss: 	0.15137 loss align 0.0000
 epoch [0020 / 0050] [0209/267] eta: 0 Days 1:19:11        lr: 	1.0000E-06 loss: 	0.17637 loss align 0.0000
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.42024
starting train epoch 21
 epoch [0021 / 0050] [0009/267] eta: 0 Days 1:18:46        lr: 	1.0000E-06 loss: 	0.17267 loss align 0.0000
 epoch [0021 / 0050] [0109/267] eta: 0 Days 1:17:33        lr: 	1.0000E-06 loss: 	0.17193 loss align 0.0000
 epoch [0021 / 0050] [0209/267] eta: 0 Days 1:16:22        lr: 	1.0000E-06 loss: 	0.17340 loss align 0.0000
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.47385
starting train epoch 22
 epoch [0022 / 0050] [0009/267] eta: 0 Days 1:15:56        lr: 	1.0000E-06 loss: 	0.20725 loss align 0.0000
 epoch [0022 / 0050] [0109/267] eta: 0 Days 1:14:45        lr: 	1.0000E-06 loss: 	0.16032 loss align 0.0000
 epoch [0022 / 0050] [0209/267] eta: 0 Days 1:13:35        lr: 	1.0000E-06 loss: 	0.15938 loss align 0.0000
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.47866
starting train epoch 23
 epoch [0023 / 0050] [0009/267] eta: 0 Days 1:13:8         lr: 	1.0000E-06 loss: 	0.10850 loss align 0.0000
 epoch [0023 / 0050] [0109/267] eta: 0 Days 1:11:58        lr: 	1.0000E-06 loss: 	0.14235 loss align 0.0000
 epoch [0023 / 0050] [0209/267] eta: 0 Days 1:10:49        lr: 	1.0000E-06 loss: 	0.14572 loss align 0.0000
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.50102
starting train epoch 24
 epoch [0024 / 0050] [0009/267] eta: 0 Days 1:10:22        lr: 	1.0000E-06 loss: 	0.19574 loss align 0.0000
 epoch [0024 / 0050] [0109/267] eta: 0 Days 1:9:12         lr: 	1.0000E-06 loss: 	0.13609 loss align 0.0000
 epoch [0024 / 0050] [0209/267] eta: 0 Days 1:8:3          lr: 	1.0000E-06 loss: 	0.14370 loss align 0.0000
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.50549
starting train epoch 25
 epoch [0025 / 0050] [0009/267] eta: 0 Days 1:7:35         lr: 	1.0000E-06 loss: 	0.20556 loss align 0.0000
 epoch [0025 / 0050] [0109/267] eta: 0 Days 1:6:27         lr: 	1.0000E-06 loss: 	0.14044 loss align 0.0000
 epoch [0025 / 0050] [0209/267] eta: 0 Days 1:5:19         lr: 	1.0000E-06 loss: 	0.13469 loss align 0.0000
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.54008
starting train epoch 26
 epoch [0026 / 0050] [0009/267] eta: 0 Days 1:4:49         lr: 	1.0000E-06 loss: 	0.16171 loss align 0.0000
 epoch [0026 / 0050] [0109/267] eta: 0 Days 1:3:42         lr: 	1.0000E-06 loss: 	0.12228 loss align 0.0000
 epoch [0026 / 0050] [0209/267] eta: 0 Days 1:2:35         lr: 	1.0000E-06 loss: 	0.13015 loss align 0.0000
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.54434
starting val epoch 0
val [0000 / 0050] validation loss: 	0.34550
Acute and unspecified renal failure                                                        & 0.835(0.867, 0.805) & 0.497 (0.577, 0.424)
fused_ehr test  0   best mean auc :0.835 mean auprc 0.497
                    CI AUROC (0.805, 0.867) CI AUPRC (0.424, 0.577)
                     AUROC accute 0.835 mixed 0.835 chronic 0.835
                     AUROC accute CI (0.805, 0.867) mixed (0.805 , 0.867) chronic (0.805, 0.867)
                     AUPRC accute  0.497 mixed 0.497 chronic 0.497
                     AUPRC accute CI  (0.424, 0.577) mixed (0.424,  0.577) chronic (0.424, 0.577)