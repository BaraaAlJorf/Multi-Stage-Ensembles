Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.84791
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 11:13:49       lr: 	1.0000E-08 loss: 	0.88579 loss align 0.0000
 epoch [0000 / 0050] [0109/280] eta: 0 Days 1:50:10        lr: 	1.0000E-08 loss: 	0.78883 loss align 0.0000
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:20:47        lr: 	1.0000E-08 loss: 	0.78166 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.81460
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:21:6         lr: 	1.0000E-08 loss: 	0.84227 loss align 0.0000
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:11:39        lr: 	1.0000E-08 loss: 	0.75795 loss align 0.0000
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:6:32         lr: 	1.0000E-08 loss: 	0.74763 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.78295
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:8:54         lr: 	1.0000E-08 loss: 	0.79714 loss align 0.0000
 epoch [0002 / 0050] [0109/280] eta: 0 Days 1:5:18         lr: 	1.0000E-08 loss: 	0.72680 loss align 0.0000
 epoch [0002 / 0050] [0209/280] eta: 0 Days 1:2:51         lr: 	1.0000E-08 loss: 	0.71639 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.75296
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 1:4:21         lr: 	1.0000E-08 loss: 	0.76782 loss align 0.0000
 epoch [0003 / 0050] [0109/280] eta: 0 Days 1:2:17         lr: 	1.0000E-08 loss: 	0.69892 loss align 0.0000
 epoch [0003 / 0050] [0209/280] eta: 0 Days 1:0:23         lr: 	1.0000E-08 loss: 	0.69076 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.72443
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 1:1:21         lr: 	1.0000E-08 loss: 	0.75190 loss align 0.0000
 epoch [0004 / 0050] [0109/280] eta: 0 Days 0:59:41        lr: 	1.0000E-08 loss: 	0.66933 loss align 0.0000
 epoch [0004 / 0050] [0209/280] eta: 0 Days 0:58:15        lr: 	1.0000E-08 loss: 	0.66197 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.69764
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 0:59:2         lr: 	1.0000E-08 loss: 	0.71131 loss align 0.0000
 epoch [0005 / 0050] [0109/280] eta: 0 Days 0:57:40        lr: 	1.0000E-08 loss: 	0.64361 loss align 0.0000
 epoch [0005 / 0050] [0209/280] eta: 0 Days 0:56:21        lr: 	1.0000E-08 loss: 	0.63758 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.67253
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 0:56:38        lr: 	1.0000E-08 loss: 	0.68736 loss align 0.0000
 epoch [0006 / 0050] [0109/280] eta: 0 Days 0:55:32        lr: 	1.0000E-08 loss: 	0.62116 loss align 0.0000
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:54:31        lr: 	1.0000E-08 loss: 	0.61428 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.64899
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 0:54:42        lr: 	1.0000E-08 loss: 	0.67854 loss align 0.0000
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:53:46        lr: 	1.0000E-08 loss: 	0.59987 loss align 0.0000
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:52:54        lr: 	1.0000E-08 loss: 	0.59087 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.62713
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:53:11        lr: 	1.0000E-08 loss: 	0.61576 loss align 0.0000
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:52:19        lr: 	1.0000E-08 loss: 	0.58097 loss align 0.0000
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:51:26        lr: 	1.0000E-08 loss: 	0.57267 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.60659
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:51:33        lr: 	1.0000E-08 loss: 	0.59130 loss align 0.0000
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:50:46        lr: 	1.0000E-08 loss: 	0.55932 loss align 0.0000
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:49:59        lr: 	1.0000E-08 loss: 	0.55400 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.58780
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:50:5         lr: 	1.0000E-08 loss: 	0.61306 loss align 0.0000
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:49:18        lr: 	1.0000E-08 loss: 	0.53960 loss align 0.0000
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:48:33        lr: 	1.0000E-08 loss: 	0.53656 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.57036
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:48:36        lr: 	1.0000E-08 loss: 	0.61912 loss align 0.0000
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:47:52        lr: 	1.0000E-08 loss: 	0.52818 loss align 0.0000
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:47:8         lr: 	1.0000E-08 loss: 	0.52024 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.55427
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:47:8         lr: 	1.0000E-08 loss: 	0.53612 loss align 0.0000
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:46:24        lr: 	1.0000E-08 loss: 	0.51115 loss align 0.0000
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:45:41        lr: 	1.0000E-08 loss: 	0.50415 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.53986
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:45:38        lr: 	1.0000E-08 loss: 	0.55375 loss align 0.0000
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:44:54        lr: 	1.0000E-08 loss: 	0.49258 loss align 0.0000
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:44:14        lr: 	1.0000E-08 loss: 	0.49571 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.52640
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:44:10        lr: 	1.0000E-08 loss: 	0.52133 loss align 0.0000
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:43:32        lr: 	1.0000E-08 loss: 	0.49067 loss align 0.0000
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:42:55        lr: 	1.0000E-08 loss: 	0.48359 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.51434
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:42:48        lr: 	1.0000E-08 loss: 	0.50175 loss align 0.0000
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:42:9         lr: 	1.0000E-08 loss: 	0.47963 loss align 0.0000
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:41:32        lr: 	1.0000E-08 loss: 	0.47395 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.50356
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:41:27        lr: 	1.0000E-08 loss: 	0.54325 loss align 0.0000
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:40:53        lr: 	1.0000E-08 loss: 	0.47157 loss align 0.0000
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:40:16        lr: 	1.0000E-08 loss: 	0.46948 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.49374
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:40:9         lr: 	1.0000E-08 loss: 	0.53615 loss align 0.0000
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:39:33        lr: 	1.0000E-08 loss: 	0.45601 loss align 0.0000
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:38:59        lr: 	1.0000E-08 loss: 	0.45562 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.48485
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:38:52        lr: 	1.0000E-08 loss: 	0.51084 loss align 0.0000
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:38:18        lr: 	1.0000E-08 loss: 	0.46379 loss align 0.0000
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:37:45        lr: 	1.0000E-08 loss: 	0.46046 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.47710
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:37:35        lr: 	1.0000E-08 loss: 	0.48504 loss align 0.0000
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:37:3         lr: 	1.0000E-08 loss: 	0.43712 loss align 0.0000
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:36:30        lr: 	1.0000E-08 loss: 	0.44007 loss align 0.0000
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.47021
starting val epoch 0
val [0000 / 0050] validation loss: 	0.68667
Acute and unspecified renal failure                                                        & 0.600(0.647, 0.560) & 0.221 (0.279, 0.186)
fused_ehr test  0   best mean auc :0.600 mean auprc 0.221
                    CI AUROC (0.560, 0.647) CI AUPRC (0.186, 0.279)
                     AUROC accute 0.600 mixed 0.600 chronic 0.600
                     AUROC accute CI (0.560, 0.647) mixed (0.560 , 0.647) chronic (0.560, 0.647)
                     AUPRC accute  0.221 mixed 0.221 chronic 0.221
                     AUPRC accute CI  (0.186, 0.279) mixed (0.186,  0.279) chronic (0.186, 0.279)