Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type joint
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.76769
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 16:48:29       lr: 	1.0000E-05 loss: 	0.54714
 epoch [0000 / 0050] [0109/267] eta: 0 Days 3:9:49         lr: 	1.0000E-05 loss: 	0.42632
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:30:16        lr: 	1.0000E-05 loss: 	0.40813
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.37599
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:36:5         lr: 	1.0000E-05 loss: 	0.31956
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:22:31        lr: 	1.0000E-05 loss: 	0.32959
 epoch [0001 / 0050] [0209/267] eta: 0 Days 2:13:48        lr: 	1.0000E-05 loss: 	0.34380
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.38194
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:18:3         lr: 	1.0000E-05 loss: 	0.31485
 epoch [0002 / 0050] [0109/267] eta: 0 Days 2:11:57        lr: 	1.0000E-05 loss: 	0.31822
 epoch [0002 / 0050] [0209/267] eta: 0 Days 2:7:14         lr: 	1.0000E-05 loss: 	0.31239
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.40782
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 2:10:47        lr: 	1.0000E-05 loss: 	0.28562
 epoch [0003 / 0050] [0109/267] eta: 0 Days 2:6:45         lr: 	1.0000E-05 loss: 	0.24052
 epoch [0003 / 0050] [0209/267] eta: 0 Days 2:3:20         lr: 	1.0000E-05 loss: 	0.24285
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.44644
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 2:4:31         lr: 	1.0000E-05 loss: 	0.22471
 epoch [0004 / 0050] [0109/267] eta: 0 Days 2:1:36         lr: 	1.0000E-05 loss: 	0.18946
 epoch [0004 / 0050] [0209/267] eta: 0 Days 1:58:58        lr: 	1.0000E-05 loss: 	0.19079
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.47120
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 1:59:48        lr: 	1.0000E-05 loss: 	0.13667
 epoch [0005 / 0050] [0109/267] eta: 0 Days 1:57:20        lr: 	1.0000E-05 loss: 	0.14767
 epoch [0005 / 0050] [0209/267] eta: 0 Days 1:55:12        lr: 	1.0000E-05 loss: 	0.14506
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.60613
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 1:55:57        lr: 	1.0000E-05 loss: 	0.07792
 epoch [0006 / 0050] [0109/267] eta: 0 Days 1:53:47        lr: 	1.0000E-05 loss: 	0.11709
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:51:52        lr: 	1.0000E-05 loss: 	0.12030
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.72046
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:52:19        lr: 	1.0000E-05 loss: 	0.07152
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:50:30        lr: 	1.0000E-05 loss: 	0.07823
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:48:36        lr: 	1.0000E-05 loss: 	0.08128
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.69722
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:48:57        lr: 	1.0000E-05 loss: 	0.13991
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:47:13        lr: 	1.0000E-05 loss: 	0.07073
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:45:36        lr: 	1.0000E-05 loss: 	0.06720
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.84489
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:45:48        lr: 	1.0000E-05 loss: 	0.13684
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:44:8         lr: 	1.0000E-05 loss: 	0.06642
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:42:33        lr: 	1.0000E-05 loss: 	0.06173
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.79965
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:42:42        lr: 	1.0000E-05 loss: 	0.04220
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:41:16        lr: 	1.0000E-05 loss: 	0.03964
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:39:47        lr: 	1.0000E-05 loss: 	0.04256
11
starting val epoch 11
val [0011 / 0050] validation loss: 	1.04163
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:39:48        lr: 	1.0000E-05 loss: 	0.17967
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:38:22        lr: 	1.0000E-05 loss: 	0.05710
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:36:58        lr: 	1.0000E-05 loss: 	0.05293
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.88473
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:36:56        lr: 	1.0000E-05 loss: 	0.03910
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:35:35        lr: 	1.0000E-05 loss: 	0.03453
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:34:14        lr: 	1.0000E-05 loss: 	0.03780
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.88385
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:34:9         lr: 	1.0000E-05 loss: 	0.02451
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:32:50        lr: 	1.0000E-05 loss: 	0.01796
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:31:33        lr: 	1.0000E-05 loss: 	0.03538
14
starting val epoch 14
val [0014 / 0050] validation loss: 	1.07720
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:31:25        lr: 	1.0000E-05 loss: 	0.04353
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:30:8         lr: 	1.0000E-05 loss: 	0.02327
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:28:54        lr: 	1.0000E-05 loss: 	0.02936
15
starting val epoch 15
val [0015 / 0050] validation loss: 	1.23298
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:28:43        lr: 	1.0000E-05 loss: 	0.05462
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:27:28        lr: 	1.0000E-05 loss: 	0.03237
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:26:15        lr: 	1.0000E-05 loss: 	0.03711
16
starting val epoch 16
val [0016 / 0050] validation loss: 	1.08072
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:26:4         lr: 	1.0000E-05 loss: 	0.00879
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:24:50        lr: 	1.0000E-05 loss: 	0.03056
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:23:39        lr: 	1.0000E-05 loss: 	0.02575
17
starting val epoch 17
val [0017 / 0050] validation loss: 	1.09531
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:23:25        lr: 	1.0000E-05 loss: 	0.00190
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:22:13        lr: 	1.0000E-05 loss: 	0.01352
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:21:2         lr: 	1.0000E-05 loss: 	0.01671
18
starting val epoch 18
val [0018 / 0050] validation loss: 	1.08498
starting val epoch 0
val [0000 / 0050] validation loss: 	0.37039
Acute and unspecified renal failure                                                        & 0.815(0.849, 0.780) & 0.484 (0.567, 0.406)
fused_ehr test  0   best mean auc :0.815 mean auprc 0.484
                    CI AUROC (0.780, 0.849) CI AUPRC (0.406, 0.567)
                     AUROC accute 0.815 mixed 0.815 chronic 0.815
                     AUROC accute CI (0.780, 0.849) mixed (0.780 , 0.849) chronic (0.780, 0.849)
                     AUPRC accute  0.484 mixed 0.484 chronic 0.484
                     AUPRC accute CI  (0.406, 0.567) mixed (0.406,  0.567) chronic (0.406, 0.567)