Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type late
0
starting val epoch 0
val [0000 / 0050] validation loss: 	1.07356
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 12:1:8         lr: 	1.0000E-08 loss: 	1.12948
 epoch [0000 / 0050] [0109/280] eta: 0 Days 1:43:6         lr: 	1.0000E-08 loss: 	1.01408
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:12:54        lr: 	1.0000E-08 loss: 	0.99894
1
starting val epoch 1
val [0001 / 0050] validation loss: 	1.02923
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:13:44        lr: 	1.0000E-08 loss: 	1.05169
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:5:12         lr: 	1.0000E-08 loss: 	0.95833
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:0:9          lr: 	1.0000E-08 loss: 	0.95399
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.98664
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:2:6          lr: 	1.0000E-08 loss: 	1.04094
 epoch [0002 / 0050] [0109/280] eta: 0 Days 0:58:29        lr: 	1.0000E-08 loss: 	0.92767
 epoch [0002 / 0050] [0209/280] eta: 0 Days 0:55:47        lr: 	1.0000E-08 loss: 	0.91440
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.94606
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 0:57:24        lr: 	1.0000E-08 loss: 	0.98752
 epoch [0003 / 0050] [0109/280] eta: 0 Days 0:55:6         lr: 	1.0000E-08 loss: 	0.88556
 epoch [0003 / 0050] [0209/280] eta: 0 Days 0:53:27        lr: 	1.0000E-08 loss: 	0.87497
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.90745
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 0:54:32        lr: 	1.0000E-08 loss: 	0.93977
 epoch [0004 / 0050] [0109/280] eta: 0 Days 0:52:44        lr: 	1.0000E-08 loss: 	0.85014
 epoch [0004 / 0050] [0209/280] eta: 0 Days 0:51:14        lr: 	1.0000E-08 loss: 	0.83814
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.87048
checkpoint
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 0:52:5         lr: 	1.0000E-08 loss: 	0.90328
 epoch [0005 / 0050] [0109/280] eta: 0 Days 0:50:38        lr: 	1.0000E-08 loss: 	0.81231
 epoch [0005 / 0050] [0209/280] eta: 0 Days 0:49:25        lr: 	1.0000E-08 loss: 	0.80334
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.83546
checkpoint
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 0:50:4         lr: 	1.0000E-08 loss: 	0.87043
 epoch [0006 / 0050] [0109/280] eta: 0 Days 0:49:3         lr: 	1.0000E-08 loss: 	0.77920
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:48:7         lr: 	1.0000E-08 loss: 	0.77150
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.80228
checkpoint
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 0:48:43        lr: 	1.0000E-08 loss: 	0.82961
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:47:54        lr: 	1.0000E-08 loss: 	0.74835
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:47:6         lr: 	1.0000E-08 loss: 	0.73874
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.77096
checkpoint
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:47:31        lr: 	1.0000E-08 loss: 	0.79417
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:46:37        lr: 	1.0000E-08 loss: 	0.71691
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:45:50        lr: 	1.0000E-08 loss: 	0.71020
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.74136
checkpoint
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:46:16        lr: 	1.0000E-08 loss: 	0.77650
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:45:30        lr: 	1.0000E-08 loss: 	0.69213
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:44:42        lr: 	1.0000E-08 loss: 	0.68369
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.71361
checkpoint
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:44:57        lr: 	1.0000E-08 loss: 	0.75656
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:44:11        lr: 	1.0000E-08 loss: 	0.66709
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:43:26        lr: 	1.0000E-08 loss: 	0.66040
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.68749
checkpoint
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:43:38        lr: 	1.0000E-08 loss: 	0.71706
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:42:55        lr: 	1.0000E-08 loss: 	0.64304
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:42:11        lr: 	1.0000E-08 loss: 	0.63512
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.66290
checkpoint
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:42:21        lr: 	1.0000E-08 loss: 	0.67112
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:41:43        lr: 	1.0000E-08 loss: 	0.61468
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:41:3         lr: 	1.0000E-08 loss: 	0.61168
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.64013
checkpoint
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:41:10        lr: 	1.0000E-08 loss: 	0.65562
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:40:29        lr: 	1.0000E-08 loss: 	0.59698
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:39:50        lr: 	1.0000E-08 loss: 	0.59445
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.61899
checkpoint
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:39:53        lr: 	1.0000E-08 loss: 	0.65091
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:39:14        lr: 	1.0000E-08 loss: 	0.57312
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:38:37        lr: 	1.0000E-08 loss: 	0.57281
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.59919
checkpoint
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:38:38        lr: 	1.0000E-08 loss: 	0.63359
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:38:3         lr: 	1.0000E-08 loss: 	0.55747
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:37:30        lr: 	1.0000E-08 loss: 	0.55398
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.58077
checkpoint
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:37:31        lr: 	1.0000E-08 loss: 	0.63556
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:36:59        lr: 	1.0000E-08 loss: 	0.55091
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:36:25        lr: 	1.0000E-08 loss: 	0.54074
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.56411
checkpoint
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:36:23        lr: 	1.0000E-08 loss: 	0.60863
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:35:51        lr: 	1.0000E-08 loss: 	0.53923
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:35:20        lr: 	1.0000E-08 loss: 	0.52795
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.54893
checkpoint
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:35:16        lr: 	1.0000E-08 loss: 	0.60368
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:34:43        lr: 	1.0000E-08 loss: 	0.52120
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:34:10        lr: 	1.0000E-08 loss: 	0.51684
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.53528
checkpoint
starting train epoch 19
 epoch [0019 / 0050] [0009/280] eta: 0 Days 0:34:7         lr: 	1.0000E-08 loss: 	0.58388
 epoch [0019 / 0050] [0109/280] eta: 0 Days 0:33:34        lr: 	1.0000E-08 loss: 	0.51374
 epoch [0019 / 0050] [0209/280] eta: 0 Days 0:33:2         lr: 	1.0000E-08 loss: 	0.50390
20
starting val epoch 20
val [0020 / 0050] validation loss: 	0.52245
checkpoint
starting train epoch 20
 epoch [0020 / 0050] [0009/280] eta: 0 Days 0:32:56        lr: 	1.0000E-08 loss: 	0.50765
 epoch [0020 / 0050] [0109/280] eta: 0 Days 0:32:26        lr: 	1.0000E-08 loss: 	0.49193
 epoch [0020 / 0050] [0209/280] eta: 0 Days 0:31:55        lr: 	1.0000E-08 loss: 	0.49305
21
starting val epoch 21
val [0021 / 0050] validation loss: 	0.51094
checkpoint
starting train epoch 21
 epoch [0021 / 0050] [0009/280] eta: 0 Days 0:31:48        lr: 	1.0000E-08 loss: 	0.54709
 epoch [0021 / 0050] [0109/280] eta: 0 Days 0:31:19        lr: 	1.0000E-08 loss: 	0.48854
 epoch [0021 / 0050] [0209/280] eta: 0 Days 0:30:49        lr: 	1.0000E-08 loss: 	0.48393
22
starting val epoch 22
val [0022 / 0050] validation loss: 	0.50067
checkpoint
starting train epoch 22
 epoch [0022 / 0050] [0009/280] eta: 0 Days 0:30:41        lr: 	1.0000E-08 loss: 	0.48462
 epoch [0022 / 0050] [0109/280] eta: 0 Days 0:30:11        lr: 	1.0000E-08 loss: 	0.48116
 epoch [0022 / 0050] [0209/280] eta: 0 Days 0:29:40        lr: 	1.0000E-08 loss: 	0.47523
23
starting val epoch 23
val [0023 / 0050] validation loss: 	0.49133
checkpoint
starting train epoch 23
 epoch [0023 / 0050] [0009/280] eta: 0 Days 0:29:32        lr: 	1.0000E-08 loss: 	0.48409
 epoch [0023 / 0050] [0109/280] eta: 0 Days 0:29:2         lr: 	1.0000E-08 loss: 	0.46633
 epoch [0023 / 0050] [0209/280] eta: 0 Days 0:28:33        lr: 	1.0000E-08 loss: 	0.46779
24
starting val epoch 24
val [0024 / 0050] validation loss: 	0.48288
checkpoint
starting train epoch 24
 epoch [0024 / 0050] [0009/280] eta: 0 Days 0:28:26        lr: 	1.0000E-08 loss: 	0.51358
 epoch [0024 / 0050] [0109/280] eta: 0 Days 0:27:58        lr: 	1.0000E-08 loss: 	0.47173
 epoch [0024 / 0050] [0209/280] eta: 0 Days 0:27:29        lr: 	1.0000E-08 loss: 	0.46271
25
starting val epoch 25
val [0025 / 0050] validation loss: 	0.47550
checkpoint
starting train epoch 25
 epoch [0025 / 0050] [0009/280] eta: 0 Days 0:27:20        lr: 	1.0000E-08 loss: 	0.54711
 epoch [0025 / 0050] [0109/280] eta: 0 Days 0:26:53        lr: 	1.0000E-08 loss: 	0.47275
 epoch [0025 / 0050] [0209/280] eta: 0 Days 0:26:24        lr: 	1.0000E-08 loss: 	0.46407
26
starting val epoch 26
val [0026 / 0050] validation loss: 	0.46901
checkpoint
starting train epoch 26
 epoch [0026 / 0050] [0009/280] eta: 0 Days 0:26:15        lr: 	1.0000E-08 loss: 	0.46350
 epoch [0026 / 0050] [0109/280] eta: 0 Days 0:25:48        lr: 	1.0000E-08 loss: 	0.46085
 epoch [0026 / 0050] [0209/280] eta: 0 Days 0:25:21        lr: 	1.0000E-08 loss: 	0.45763
27
starting val epoch 27
val [0027 / 0050] validation loss: 	0.46318
checkpoint
starting train epoch 27
 epoch [0027 / 0050] [0009/280] eta: 0 Days 0:25:10        lr: 	1.0000E-08 loss: 	0.51913
 epoch [0027 / 0050] [0109/280] eta: 0 Days 0:24:42        lr: 	1.0000E-08 loss: 	0.45622
 epoch [0027 / 0050] [0209/280] eta: 0 Days 0:24:15        lr: 	1.0000E-08 loss: 	0.44889
28
starting val epoch 28
val [0028 / 0050] validation loss: 	0.45806
checkpoint
starting train epoch 28
 epoch [0028 / 0050] [0009/280] eta: 0 Days 0:24:3         lr: 	1.0000E-08 loss: 	0.45555
 epoch [0028 / 0050] [0109/280] eta: 0 Days 0:23:36        lr: 	1.0000E-08 loss: 	0.44386
 epoch [0028 / 0050] [0209/280] eta: 0 Days 0:23:9         lr: 	1.0000E-08 loss: 	0.44033
29
starting val epoch 29
val [0029 / 0050] validation loss: 	0.45362
checkpoint
starting train epoch 29
 epoch [0029 / 0050] [0009/280] eta: 0 Days 0:22:57        lr: 	1.0000E-08 loss: 	0.55808
 epoch [0029 / 0050] [0109/280] eta: 0 Days 0:22:31        lr: 	1.0000E-08 loss: 	0.44957
 epoch [0029 / 0050] [0209/280] eta: 0 Days 0:22:4         lr: 	1.0000E-08 loss: 	0.44457
30
starting val epoch 30
val [0030 / 0050] validation loss: 	0.44963
checkpoint
starting train epoch 30
 epoch [0030 / 0050] [0009/280] eta: 0 Days 0:21:52        lr: 	1.0000E-08 loss: 	0.51442
 epoch [0030 / 0050] [0109/280] eta: 0 Days 0:21:24        lr: 	1.0000E-08 loss: 	0.43511
 epoch [0030 / 0050] [0209/280] eta: 0 Days 0:20:57        lr: 	1.0000E-08 loss: 	0.43523
31
starting val epoch 31
val [0031 / 0050] validation loss: 	0.44633
checkpoint
starting train epoch 31
 epoch [0031 / 0050] [0009/280] eta: 0 Days 0:20:44        lr: 	1.0000E-08 loss: 	0.52427
 epoch [0031 / 0050] [0109/280] eta: 0 Days 0:20:19        lr: 	1.0000E-08 loss: 	0.45381
 epoch [0031 / 0050] [0209/280] eta: 0 Days 0:19:52        lr: 	1.0000E-08 loss: 	0.43959
32
starting val epoch 32
val [0032 / 0050] validation loss: 	0.44343
checkpoint
starting train epoch 32
 epoch [0032 / 0050] [0009/280] eta: 0 Days 0:19:38        lr: 	1.0000E-08 loss: 	0.43838
 epoch [0032 / 0050] [0109/280] eta: 0 Days 0:19:12        lr: 	1.0000E-08 loss: 	0.43661
 epoch [0032 / 0050] [0209/280] eta: 0 Days 0:18:47        lr: 	1.0000E-08 loss: 	0.43049
33
starting val epoch 33
val [0033 / 0050] validation loss: 	0.44066
checkpoint
starting train epoch 33
 epoch [0033 / 0050] [0009/280] eta: 0 Days 0:18:33        lr: 	1.0000E-08 loss: 	0.42494
 epoch [0033 / 0050] [0109/280] eta: 0 Days 0:18:7         lr: 	1.0000E-08 loss: 	0.42547
 epoch [0033 / 0050] [0209/280] eta: 0 Days 0:17:42        lr: 	1.0000E-08 loss: 	0.42729
34
starting val epoch 34
val [0034 / 0050] validation loss: 	0.43826
checkpoint
starting train epoch 34
 epoch [0034 / 0050] [0009/280] eta: 0 Days 0:17:28        lr: 	1.0000E-08 loss: 	0.44021
 epoch [0034 / 0050] [0109/280] eta: 0 Days 0:17:2         lr: 	1.0000E-08 loss: 	0.43279
 epoch [0034 / 0050] [0209/280] eta: 0 Days 0:16:36        lr: 	1.0000E-08 loss: 	0.42864
35
starting val epoch 35
val [0035 / 0050] validation loss: 	0.43618
checkpoint
starting train epoch 35
 epoch [0035 / 0050] [0009/280] eta: 0 Days 0:16:21        lr: 	1.0000E-08 loss: 	0.51032
 epoch [0035 / 0050] [0109/280] eta: 0 Days 0:15:55        lr: 	1.0000E-08 loss: 	0.42545
 epoch [0035 / 0050] [0209/280] eta: 0 Days 0:15:29        lr: 	1.0000E-08 loss: 	0.42937
36
starting val epoch 36
val [0036 / 0050] validation loss: 	0.43428
checkpoint
starting train epoch 36
 epoch [0036 / 0050] [0009/280] eta: 0 Days 0:15:14        lr: 	1.0000E-08 loss: 	0.47621
 epoch [0036 / 0050] [0109/280] eta: 0 Days 0:14:49        lr: 	1.0000E-08 loss: 	0.42295
 epoch [0036 / 0050] [0209/280] eta: 0 Days 0:14:24        lr: 	1.0000E-08 loss: 	0.41472
37
starting val epoch 37
val [0037 / 0050] validation loss: 	0.43258
checkpoint
starting train epoch 37
 epoch [0037 / 0050] [0009/280] eta: 0 Days 0:14:9         lr: 	1.0000E-08 loss: 	0.47449
 epoch [0037 / 0050] [0109/280] eta: 0 Days 0:13:44        lr: 	1.0000E-08 loss: 	0.43530
 epoch [0037 / 0050] [0209/280] eta: 0 Days 0:13:19        lr: 	1.0000E-08 loss: 	0.42132
38
starting val epoch 38
val [0038 / 0050] validation loss: 	0.43111
checkpoint
starting train epoch 38
 epoch [0038 / 0050] [0009/280] eta: 0 Days 0:13:3         lr: 	1.0000E-08 loss: 	0.44384
 epoch [0038 / 0050] [0109/280] eta: 0 Days 0:12:39        lr: 	1.0000E-08 loss: 	0.42682
 epoch [0038 / 0050] [0209/280] eta: 0 Days 0:12:14        lr: 	1.0000E-08 loss: 	0.42072
39
starting val epoch 39
val [0039 / 0050] validation loss: 	0.42977
checkpoint
starting train epoch 39
 epoch [0039 / 0050] [0009/280] eta: 0 Days 0:11:58        lr: 	1.0000E-08 loss: 	0.45336
 epoch [0039 / 0050] [0109/280] eta: 0 Days 0:11:33        lr: 	1.0000E-08 loss: 	0.43477
 epoch [0039 / 0050] [0209/280] eta: 0 Days 0:11:9         lr: 	1.0000E-08 loss: 	0.42426
40
starting val epoch 40
val [0040 / 0050] validation loss: 	0.42856
checkpoint
starting train epoch 40
 epoch [0040 / 0050] [0009/280] eta: 0 Days 0:10:52        lr: 	1.0000E-08 loss: 	0.51368
 epoch [0040 / 0050] [0109/280] eta: 0 Days 0:10:28        lr: 	1.0000E-08 loss: 	0.42306
 epoch [0040 / 0050] [0209/280] eta: 0 Days 0:10:3         lr: 	1.0000E-08 loss: 	0.42519
41
starting val epoch 41
val [0041 / 0050] validation loss: 	0.42739
checkpoint
starting train epoch 41
 epoch [0041 / 0050] [0009/280] eta: 0 Days 0:9:47         lr: 	1.0000E-08 loss: 	0.49066
 epoch [0041 / 0050] [0109/280] eta: 0 Days 0:9:22         lr: 	1.0000E-08 loss: 	0.42396
 epoch [0041 / 0050] [0209/280] eta: 0 Days 0:8:58         lr: 	1.0000E-08 loss: 	0.42106
42
starting val epoch 42
val [0042 / 0050] validation loss: 	0.42633
checkpoint
starting train epoch 42
 epoch [0042 / 0050] [0009/280] eta: 0 Days 0:8:41         lr: 	1.0000E-08 loss: 	0.51828
 epoch [0042 / 0050] [0109/280] eta: 0 Days 0:8:17         lr: 	1.0000E-08 loss: 	0.43896
 epoch [0042 / 0050] [0209/280] eta: 0 Days 0:7:52         lr: 	1.0000E-08 loss: 	0.42367
43
starting val epoch 43
val [0043 / 0050] validation loss: 	0.42534
checkpoint
starting train epoch 43
 epoch [0043 / 0050] [0009/280] eta: 0 Days 0:7:35         lr: 	1.0000E-08 loss: 	0.53004
 epoch [0043 / 0050] [0109/280] eta: 0 Days 0:7:11         lr: 	1.0000E-08 loss: 	0.42713
 epoch [0043 / 0050] [0209/280] eta: 0 Days 0:6:47         lr: 	1.0000E-08 loss: 	0.41307
44
starting val epoch 44
val [0044 / 0050] validation loss: 	0.42441
checkpoint
starting train epoch 44
 epoch [0044 / 0050] [0009/280] eta: 0 Days 0:6:29         lr: 	1.0000E-08 loss: 	0.46358
 epoch [0044 / 0050] [0109/280] eta: 0 Days 0:6:5          lr: 	1.0000E-08 loss: 	0.41321
 epoch [0044 / 0050] [0209/280] eta: 0 Days 0:5:42         lr: 	1.0000E-08 loss: 	0.41854
45
starting val epoch 45
val [0045 / 0050] validation loss: 	0.42350
checkpoint
starting train epoch 45
 epoch [0045 / 0050] [0009/280] eta: 0 Days 0:5:24         lr: 	1.0000E-08 loss: 	0.43396
 epoch [0045 / 0050] [0109/280] eta: 0 Days 0:5:0          lr: 	1.0000E-08 loss: 	0.40559
 epoch [0045 / 0050] [0209/280] eta: 0 Days 0:4:36         lr: 	1.0000E-08 loss: 	0.41537
46
starting val epoch 46
val [0046 / 0050] validation loss: 	0.42268
checkpoint
starting train epoch 46
 epoch [0046 / 0050] [0009/280] eta: 0 Days 0:4:18         lr: 	1.0000E-08 loss: 	0.49139
 epoch [0046 / 0050] [0109/280] eta: 0 Days 0:3:55         lr: 	1.0000E-08 loss: 	0.43921
 epoch [0046 / 0050] [0209/280] eta: 0 Days 0:3:31         lr: 	1.0000E-08 loss: 	0.41428
47
starting val epoch 47
val [0047 / 0050] validation loss: 	0.42189
checkpoint
starting train epoch 47
 epoch [0047 / 0050] [0009/280] eta: 0 Days 0:3:13         lr: 	1.0000E-08 loss: 	0.53698
 epoch [0047 / 0050] [0109/280] eta: 0 Days 0:2:49         lr: 	1.0000E-08 loss: 	0.43550
 epoch [0047 / 0050] [0209/280] eta: 0 Days 0:2:26         lr: 	1.0000E-08 loss: 	0.42595
48
starting val epoch 48
val [0048 / 0050] validation loss: 	0.42114
checkpoint
starting train epoch 48
 epoch [0048 / 0050] [0009/280] eta: 0 Days 0:2:8          lr: 	1.0000E-08 loss: 	0.40481
 epoch [0048 / 0050] [0109/280] eta: 0 Days 0:1:44         lr: 	1.0000E-08 loss: 	0.41524
 epoch [0048 / 0050] [0209/280] eta: 0 Days 0:1:21         lr: 	1.0000E-08 loss: 	0.41252
49
starting val epoch 49
val [0049 / 0050] validation loss: 	0.42041
checkpoint
starting train epoch 49
 epoch [0049 / 0050] [0009/280] eta: 0 Days 0:1:2          lr: 	1.0000E-08 loss: 	0.43863
 epoch [0049 / 0050] [0109/280] eta: 0 Days 0:0:39         lr: 	1.0000E-08 loss: 	0.41602
 epoch [0049 / 0050] [0209/280] eta: 0 Days 0:0:16         lr: 	1.0000E-08 loss: 	0.42048
starting val epoch 0
val [0000 / 0050] validation loss: 	0.42090
Acute and unspecified renal failure                                                        & 0.662(0.703, 0.621) & 0.246 (0.301, 0.203)
fused_ehr test  0   best mean auc :0.662 mean auprc 0.246
                    CI AUROC (0.621, 0.703) CI AUPRC (0.203, 0.301)
                     AUROC accute 0.662 mixed 0.662 chronic 0.662
                     AUROC accute CI (0.621, 0.703) mixed (0.621 , 0.703) chronic (0.621, 0.703)
                     AUPRC accute  0.246 mixed 0.246 chronic 0.246
                     AUPRC accute CI  (0.203, 0.301) mixed (0.203,  0.301) chronic (0.203, 0.301)