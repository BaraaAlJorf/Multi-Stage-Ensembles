Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
==> training
Running unimodal pretraining for modality RR
0
Starting val epoch 0
val [0000 / 0050] validation loss: 	0.66053
checkpoint
Starting train epoch 0
 epoch [0000 / 0050] [0099/1017] eta: 0 Days 9:59:58        lr: 	1.0000E-05 loss: 	0.41958
 epoch [0000 / 0050] [0199/1017] eta: 0 Days 7:2:20         lr: 	1.0000E-05 loss: 	0.40739
 epoch [0000 / 0050] [0299/1017] eta: 0 Days 6:4:15         lr: 	1.0000E-05 loss: 	0.40378
 epoch [0000 / 0050] [0399/1017] eta: 0 Days 5:35:14        lr: 	1.0000E-05 loss: 	0.39882
 epoch [0000 / 0050] [0499/1017] eta: 0 Days 5:17:35        lr: 	1.0000E-05 loss: 	0.39479
 epoch [0000 / 0050] [0599/1017] eta: 0 Days 5:5:46         lr: 	1.0000E-05 loss: 	0.39102
 epoch [0000 / 0050] [0699/1017] eta: 0 Days 4:56:47        lr: 	1.0000E-05 loss: 	0.38611
 epoch [0000 / 0050] [0799/1017] eta: 0 Days 4:50:21        lr: 	1.0000E-05 loss: 	0.38599
 epoch [0000 / 0050] [0899/1017] eta: 0 Days 4:45:7         lr: 	1.0000E-05 loss: 	0.38270
 epoch [0000 / 0050] [0999/1017] eta: 0 Days 4:40:20        lr: 	1.0000E-05 loss: 	0.37892
1
Starting val epoch 1
val [0001 / 0050] validation loss: 	0.33994
checkpoint
Starting train epoch 1
 epoch [0001 / 0050] [0099/1017] eta: 0 Days 5:4:18         lr: 	1.0000E-05 loss: 	0.33936
 epoch [0001 / 0050] [0199/1017] eta: 0 Days 4:58:33        lr: 	1.0000E-05 loss: 	0.34291
 epoch [0001 / 0050] [0299/1017] eta: 0 Days 4:54:7         lr: 	1.0000E-05 loss: 	0.34421
 epoch [0001 / 0050] [0399/1017] eta: 0 Days 4:49:51        lr: 	1.0000E-05 loss: 	0.34403
 epoch [0001 / 0050] [0499/1017] eta: 0 Days 4:46:38        lr: 	1.0000E-05 loss: 	0.33934
 epoch [0001 / 0050] [0599/1017] eta: 0 Days 4:43:27        lr: 	1.0000E-05 loss: 	0.34170
 epoch [0001 / 0050] [0699/1017] eta: 0 Days 4:40:45        lr: 	1.0000E-05 loss: 	0.34331
 epoch [0001 / 0050] [0799/1017] eta: 0 Days 4:38:3         lr: 	1.0000E-05 loss: 	0.34164
 epoch [0001 / 0050] [0899/1017] eta: 0 Days 4:35:35        lr: 	1.0000E-05 loss: 	0.34212
 epoch [0001 / 0050] [0999/1017] eta: 0 Days 4:33:15        lr: 	1.0000E-05 loss: 	0.34386
2
Starting val epoch 2
val [0002 / 0050] validation loss: 	0.33798
checkpoint
Starting train epoch 2
 epoch [0002 / 0050] [0099/1017] eta: 0 Days 4:45:31        lr: 	1.0000E-05 loss: 	0.32277
 epoch [0002 / 0050] [0199/1017] eta: 0 Days 4:42:55        lr: 	1.0000E-05 loss: 	0.31123
 epoch [0002 / 0050] [0299/1017] eta: 0 Days 4:40:15        lr: 	1.0000E-05 loss: 	0.31767
 epoch [0002 / 0050] [0399/1017] eta: 0 Days 4:38:3         lr: 	1.0000E-05 loss: 	0.31667
 epoch [0002 / 0050] [0499/1017] eta: 0 Days 4:36:10        lr: 	1.0000E-05 loss: 	0.31343
 epoch [0002 / 0050] [0599/1017] eta: 0 Days 4:34:14        lr: 	1.0000E-05 loss: 	0.31296
 epoch [0002 / 0050] [0699/1017] eta: 0 Days 4:32:17        lr: 	1.0000E-05 loss: 	0.31482
 epoch [0002 / 0050] [0799/1017] eta: 0 Days 4:30:36        lr: 	1.0000E-05 loss: 	0.31229
 epoch [0002 / 0050] [0899/1017] eta: 0 Days 4:28:51        lr: 	1.0000E-05 loss: 	0.31378
 epoch [0002 / 0050] [0999/1017] eta: 0 Days 4:27:10        lr: 	1.0000E-05 loss: 	0.31359
3
Starting val epoch 3
val [0003 / 0050] validation loss: 	0.34710
Starting train epoch 3
 epoch [0003 / 0050] [0099/1017] eta: 0 Days 4:34:32        lr: 	1.0000E-05 loss: 	0.27788
 epoch [0003 / 0050] [0199/1017] eta: 0 Days 4:32:42        lr: 	1.0000E-05 loss: 	0.27621
 epoch [0003 / 0050] [0299/1017] eta: 0 Days 4:31:4         lr: 	1.0000E-05 loss: 	0.27463
 epoch [0003 / 0050] [0399/1017] eta: 0 Days 4:29:23        lr: 	1.0000E-05 loss: 	0.27889
 epoch [0003 / 0050] [0499/1017] eta: 0 Days 4:27:52        lr: 	1.0000E-05 loss: 	0.27641
 epoch [0003 / 0050] [0599/1017] eta: 0 Days 4:26:20        lr: 	1.0000E-05 loss: 	0.27751
 epoch [0003 / 0050] [0699/1017] eta: 0 Days 4:24:53        lr: 	1.0000E-05 loss: 	0.27697
 epoch [0003 / 0050] [0799/1017] eta: 0 Days 4:23:28        lr: 	1.0000E-05 loss: 	0.27635
 epoch [0003 / 0050] [0899/1017] eta: 0 Days 4:22:14        lr: 	1.0000E-05 loss: 	0.27162
 epoch [0003 / 0050] [0999/1017] eta: 0 Days 4:20:55        lr: 	1.0000E-05 loss: 	0.27090
4
Starting val epoch 4
val [0004 / 0050] validation loss: 	0.36688
checkpoint
Starting train epoch 4
 epoch [0004 / 0050] [0099/1017] eta: 0 Days 4:26:36        lr: 	1.0000E-05 loss: 	0.21448
 epoch [0004 / 0050] [0199/1017] eta: 0 Days 4:25:9         lr: 	1.0000E-05 loss: 	0.22776
 epoch [0004 / 0050] [0299/1017] eta: 0 Days 4:23:45        lr: 	1.0000E-05 loss: 	0.22947
 epoch [0004 / 0050] [0399/1017] eta: 0 Days 4:22:21        lr: 	1.0000E-05 loss: 	0.22930
 epoch [0004 / 0050] [0499/1017] eta: 0 Days 4:20:57        lr: 	1.0000E-05 loss: 	0.22557
 epoch [0004 / 0050] [0599/1017] eta: 0 Days 4:19:48        lr: 	1.0000E-05 loss: 	0.22497
 epoch [0004 / 0050] [0699/1017] eta: 0 Days 4:18:38        lr: 	1.0000E-05 loss: 	0.22398
 epoch [0004 / 0050] [0799/1017] eta: 0 Days 4:17:31        lr: 	1.0000E-05 loss: 	0.22612
 epoch [0004 / 0050] [0899/1017] eta: 0 Days 4:16:26        lr: 	1.0000E-05 loss: 	0.22554
 epoch [0004 / 0050] [0999/1017] eta: 0 Days 4:15:21        lr: 	1.0000E-05 loss: 	0.22478
5
Starting val epoch 5
val [0005 / 0050] validation loss: 	0.45998
Starting train epoch 5
 epoch [0005 / 0050] [0099/1017] eta: 0 Days 4:19:15        lr: 	1.0000E-05 loss: 	0.17675
 epoch [0005 / 0050] [0199/1017] eta: 0 Days 4:18:12        lr: 	1.0000E-05 loss: 	0.16447
 epoch [0005 / 0050] [0299/1017] eta: 0 Days 4:17:1         lr: 	1.0000E-05 loss: 	0.17259
 epoch [0005 / 0050] [0399/1017] eta: 0 Days 4:15:51        lr: 	1.0000E-05 loss: 	0.17619
 epoch [0005 / 0050] [0499/1017] eta: 0 Days 4:14:45        lr: 	1.0000E-05 loss: 	0.17613
 epoch [0005 / 0050] [0599/1017] eta: 0 Days 4:13:37        lr: 	1.0000E-05 loss: 	0.17605
 epoch [0005 / 0050] [0699/1017] eta: 0 Days 4:12:29        lr: 	1.0000E-05 loss: 	0.17473
 epoch [0005 / 0050] [0799/1017] eta: 0 Days 4:11:22        lr: 	1.0000E-05 loss: 	0.17454
 epoch [0005 / 0050] [0899/1017] eta: 0 Days 4:10:24        lr: 	1.0000E-05 loss: 	0.17528
 epoch [0005 / 0050] [0999/1017] eta: 0 Days 4:9:27         lr: 	1.0000E-05 loss: 	0.17567
6
Starting val epoch 6
val [0006 / 0050] validation loss: 	0.47392
Starting train epoch 6
 epoch [0006 / 0050] [0099/1017] eta: 0 Days 4:12:44        lr: 	1.0000E-05 loss: 	0.12904
 epoch [0006 / 0050] [0199/1017] eta: 0 Days 4:11:37        lr: 	1.0000E-05 loss: 	0.12369
 epoch [0006 / 0050] [0299/1017] eta: 0 Days 4:10:36        lr: 	1.0000E-05 loss: 	0.12182
 epoch [0006 / 0050] [0399/1017] eta: 0 Days 4:9:36         lr: 	1.0000E-05 loss: 	0.12316
 epoch [0006 / 0050] [0499/1017] eta: 0 Days 4:8:36         lr: 	1.0000E-05 loss: 	0.12470
 epoch [0006 / 0050] [0599/1017] eta: 0 Days 4:7:37         lr: 	1.0000E-05 loss: 	0.12497
 epoch [0006 / 0050] [0699/1017] eta: 0 Days 4:6:39         lr: 	1.0000E-05 loss: 	0.12631
 epoch [0006 / 0050] [0799/1017] eta: 0 Days 4:5:41         lr: 	1.0000E-05 loss: 	0.12791
 epoch [0006 / 0050] [0899/1017] eta: 0 Days 4:4:44         lr: 	1.0000E-05 loss: 	0.12869
 epoch [0006 / 0050] [0999/1017] eta: 0 Days 4:3:47         lr: 	1.0000E-05 loss: 	0.13030
7
Starting val epoch 7
val [0007 / 0050] validation loss: 	0.65358
Starting train epoch 7
 epoch [0007 / 0050] [0099/1017] eta: 0 Days 4:6:27         lr: 	1.0000E-05 loss: 	0.10238
 epoch [0007 / 0050] [0199/1017] eta: 0 Days 4:5:32         lr: 	1.0000E-05 loss: 	0.09689
 epoch [0007 / 0050] [0299/1017] eta: 0 Days 4:4:38         lr: 	1.0000E-05 loss: 	0.09725
 epoch [0007 / 0050] [0399/1017] eta: 0 Days 4:3:40         lr: 	1.0000E-05 loss: 	0.08912
 epoch [0007 / 0050] [0499/1017] eta: 0 Days 4:2:45         lr: 	1.0000E-05 loss: 	0.09051
 epoch [0007 / 0050] [0599/1017] eta: 0 Days 4:1:51         lr: 	1.0000E-05 loss: 	0.09017
 epoch [0007 / 0050] [0699/1017] eta: 0 Days 4:0:54         lr: 	1.0000E-05 loss: 	0.09332
 epoch [0007 / 0050] [0799/1017] eta: 0 Days 4:0:0          lr: 	1.0000E-05 loss: 	0.09611
 epoch [0007 / 0050] [0899/1017] eta: 0 Days 3:59:7         lr: 	1.0000E-05 loss: 	0.09687
 epoch [0007 / 0050] [0999/1017] eta: 0 Days 3:58:12        lr: 	1.0000E-05 loss: 	0.09811
8
Starting val epoch 8
val [0008 / 0050] validation loss: 	0.64397
Starting train epoch 8
 epoch [0008 / 0050] [0099/1017] eta: 0 Days 4:0:17         lr: 	1.0000E-05 loss: 	0.06641
 epoch [0008 / 0050] [0199/1017] eta: 0 Days 3:59:23        lr: 	1.0000E-05 loss: 	0.06942
 epoch [0008 / 0050] [0299/1017] eta: 0 Days 3:58:29        lr: 	1.0000E-05 loss: 	0.07174
 epoch [0008 / 0050] [0399/1017] eta: 0 Days 3:57:34        lr: 	1.0000E-05 loss: 	0.07246
 epoch [0008 / 0050] [0499/1017] eta: 0 Days 3:56:40        lr: 	1.0000E-05 loss: 	0.07315
 epoch [0008 / 0050] [0599/1017] eta: 0 Days 3:55:46        lr: 	1.0000E-05 loss: 	0.07249
 epoch [0008 / 0050] [0699/1017] eta: 0 Days 3:54:51        lr: 	1.0000E-05 loss: 	0.07247
 epoch [0008 / 0050] [0799/1017] eta: 0 Days 3:54:1         lr: 	1.0000E-05 loss: 	0.07315
 epoch [0008 / 0050] [0899/1017] eta: 0 Days 3:53:8         lr: 	1.0000E-05 loss: 	0.07443
 epoch [0008 / 0050] [0999/1017] eta: 0 Days 3:52:18        lr: 	1.0000E-05 loss: 	0.07570
9
Starting val epoch 9
val [0009 / 0050] validation loss: 	0.77605
Starting train epoch 9
 epoch [0009 / 0050] [0099/1017] eta: 0 Days 3:54:4         lr: 	1.0000E-05 loss: 	0.06202
 epoch [0009 / 0050] [0199/1017] eta: 0 Days 3:53:15        lr: 	1.0000E-05 loss: 	0.05355
 epoch [0009 / 0050] [0299/1017] eta: 0 Days 3:52:25        lr: 	1.0000E-05 loss: 	0.05714
 epoch [0009 / 0050] [0399/1017] eta: 0 Days 3:51:34        lr: 	1.0000E-05 loss: 	0.06139
 epoch [0009 / 0050] [0499/1017] eta: 0 Days 3:50:44        lr: 	1.0000E-05 loss: 	0.06093
 epoch [0009 / 0050] [0599/1017] eta: 0 Days 3:49:56        lr: 	1.0000E-05 loss: 	0.05925
 epoch [0009 / 0050] [0699/1017] eta: 0 Days 3:49:5         lr: 	1.0000E-05 loss: 	0.06046
 epoch [0009 / 0050] [0799/1017] eta: 0 Days 3:48:17        lr: 	1.0000E-05 loss: 	0.06046
 epoch [0009 / 0050] [0899/1017] eta: 0 Days 3:47:28        lr: 	1.0000E-05 loss: 	0.05945
 epoch [0009 / 0050] [0999/1017] eta: 0 Days 3:46:39        lr: 	1.0000E-05 loss: 	0.05846
10
Starting val epoch 10
val [0010 / 0050] validation loss: 	0.86557
Starting train epoch 10
 epoch [0010 / 0050] [0099/1017] eta: 0 Days 3:48:6         lr: 	1.0000E-05 loss: 	0.05696
 epoch [0010 / 0050] [0199/1017] eta: 0 Days 3:47:19        lr: 	1.0000E-05 loss: 	0.05334
 epoch [0010 / 0050] [0299/1017] eta: 0 Days 3:46:31        lr: 	1.0000E-05 loss: 	0.05438
 epoch [0010 / 0050] [0399/1017] eta: 0 Days 3:45:40        lr: 	1.0000E-05 loss: 	0.05398
 epoch [0010 / 0050] [0499/1017] eta: 0 Days 3:44:54        lr: 	1.0000E-05 loss: 	0.05369
 epoch [0010 / 0050] [0599/1017] eta: 0 Days 3:44:6         lr: 	1.0000E-05 loss: 	0.05190
 epoch [0010 / 0050] [0699/1017] eta: 0 Days 3:43:20        lr: 	1.0000E-05 loss: 	0.05239
 epoch [0010 / 0050] [0799/1017] eta: 0 Days 3:42:33        lr: 	1.0000E-05 loss: 	0.05343
 epoch [0010 / 0050] [0899/1017] eta: 0 Days 3:41:48        lr: 	1.0000E-05 loss: 	0.05376
 epoch [0010 / 0050] [0999/1017] eta: 0 Days 3:41:1         lr: 	1.0000E-05 loss: 	0.05276
11
Starting val epoch 11
val [0011 / 0050] validation loss: 	0.91633
Starting train epoch 11
 epoch [0011 / 0050] [0099/1017] eta: 0 Days 3:42:15        lr: 	1.0000E-05 loss: 	0.03455
 epoch [0011 / 0050] [0199/1017] eta: 0 Days 3:41:29        lr: 	1.0000E-05 loss: 	0.03328
 epoch [0011 / 0050] [0299/1017] eta: 0 Days 3:40:46        lr: 	1.0000E-05 loss: 	0.03865
 epoch [0011 / 0050] [0399/1017] eta: 0 Days 3:40:0         lr: 	1.0000E-05 loss: 	0.04063
 epoch [0011 / 0050] [0499/1017] eta: 0 Days 3:39:12        lr: 	1.0000E-05 loss: 	0.04170
 epoch [0011 / 0050] [0599/1017] eta: 0 Days 3:38:26        lr: 	1.0000E-05 loss: 	0.04218
 epoch [0011 / 0050] [0699/1017] eta: 0 Days 3:37:39        lr: 	1.0000E-05 loss: 	0.04438
 epoch [0011 / 0050] [0799/1017] eta: 0 Days 3:36:56        lr: 	1.0000E-05 loss: 	0.04288
 epoch [0011 / 0050] [0899/1017] eta: 0 Days 3:36:10        lr: 	1.0000E-05 loss: 	0.04416
 epoch [0011 / 0050] [0999/1017] eta: 0 Days 3:35:25        lr: 	1.0000E-05 loss: 	0.04314
12
Starting val epoch 12
val [0012 / 0050] validation loss: 	0.95046
Starting train epoch 12
 epoch [0012 / 0050] [0099/1017] eta: 0 Days 3:36:25        lr: 	1.0000E-05 loss: 	0.03432
 epoch [0012 / 0050] [0199/1017] eta: 0 Days 3:35:38        lr: 	1.0000E-05 loss: 	0.03001
 epoch [0012 / 0050] [0299/1017] eta: 0 Days 3:34:50        lr: 	1.0000E-05 loss: 	0.02940
 epoch [0012 / 0050] [0399/1017] eta: 0 Days 3:34:4         lr: 	1.0000E-05 loss: 	0.03164
 epoch [0012 / 0050] [0499/1017] eta: 0 Days 3:33:19        lr: 	1.0000E-05 loss: 	0.03446
 epoch [0012 / 0050] [0599/1017] eta: 0 Days 3:32:33        lr: 	1.0000E-05 loss: 	0.03512
 epoch [0012 / 0050] [0699/1017] eta: 0 Days 3:31:48        lr: 	1.0000E-05 loss: 	0.03354
 epoch [0012 / 0050] [0799/1017] eta: 0 Days 3:31:3         lr: 	1.0000E-05 loss: 	0.03484
 epoch [0012 / 0050] [0899/1017] eta: 0 Days 3:30:20        lr: 	1.0000E-05 loss: 	0.03551
 epoch [0012 / 0050] [0999/1017] eta: 0 Days 3:29:34        lr: 	1.0000E-05 loss: 	0.03541
13
Starting val epoch 13
val [0013 / 0050] validation loss: 	0.91940
Starting train epoch 13
 epoch [0013 / 0050] [0099/1017] eta: 0 Days 3:30:26        lr: 	1.0000E-05 loss: 	0.02737
 epoch [0013 / 0050] [0199/1017] eta: 0 Days 3:29:39        lr: 	1.0000E-05 loss: 	0.02801
 epoch [0013 / 0050] [0299/1017] eta: 0 Days 3:28:55        lr: 	1.0000E-05 loss: 	0.02891
 epoch [0013 / 0050] [0399/1017] eta: 0 Days 3:28:11        lr: 	1.0000E-05 loss: 	0.02973
 epoch [0013 / 0050] [0499/1017] eta: 0 Days 3:27:27        lr: 	1.0000E-05 loss: 	0.02897
 epoch [0013 / 0050] [0599/1017] eta: 0 Days 3:26:43        lr: 	1.0000E-05 loss: 	0.03025
 epoch [0013 / 0050] [0699/1017] eta: 0 Days 3:25:59        lr: 	1.0000E-05 loss: 	0.03211
 epoch [0013 / 0050] [0799/1017] eta: 0 Days 3:25:15        lr: 	1.0000E-05 loss: 	0.03183
 epoch [0013 / 0050] [0899/1017] eta: 0 Days 3:24:32        lr: 	1.0000E-05 loss: 	0.03349
 epoch [0013 / 0050] [0999/1017] eta: 0 Days 3:23:50        lr: 	1.0000E-05 loss: 	0.03401
14
Starting val epoch 14
val [0014 / 0050] validation loss: 	1.01623
Starting train epoch 14
 epoch [0014 / 0050] [0099/1017] eta: 0 Days 3:24:33        lr: 	1.0000E-05 loss: 	0.03686
 epoch [0014 / 0050] [0199/1017] eta: 0 Days 3:23:49        lr: 	1.0000E-05 loss: 	0.04195
 epoch [0014 / 0050] [0299/1017] eta: 0 Days 3:23:7         lr: 	1.0000E-05 loss: 	0.04036
 epoch [0014 / 0050] [0399/1017] eta: 0 Days 3:22:24        lr: 	1.0000E-05 loss: 	0.03430
 epoch [0014 / 0050] [0499/1017] eta: 0 Days 3:21:40        lr: 	1.0000E-05 loss: 	0.03182
 epoch [0014 / 0050] [0599/1017] eta: 0 Days 3:20:56        lr: 	1.0000E-05 loss: 	0.03168
 epoch [0014 / 0050] [0699/1017] eta: 0 Days 3:20:13        lr: 	1.0000E-05 loss: 	0.03143
 epoch [0014 / 0050] [0799/1017] eta: 0 Days 3:19:30        lr: 	1.0000E-05 loss: 	0.03348
 epoch [0014 / 0050] [0899/1017] eta: 0 Days 3:18:47        lr: 	1.0000E-05 loss: 	0.03230
 epoch [0014 / 0050] [0999/1017] eta: 0 Days 3:18:5         lr: 	1.0000E-05 loss: 	0.03268
15
Starting val epoch 15
val [0015 / 0050] validation loss: 	0.97577
Starting train epoch 15
 epoch [0015 / 0050] [0099/1017] eta: 0 Days 3:18:42        lr: 	1.0000E-05 loss: 	0.02670
 epoch [0015 / 0050] [0199/1017] eta: 0 Days 3:18:0         lr: 	1.0000E-05 loss: 	0.03320
 epoch [0015 / 0050] [0299/1017] eta: 0 Days 3:17:18        lr: 	1.0000E-05 loss: 	0.03209
 epoch [0015 / 0050] [0399/1017] eta: 0 Days 3:16:35        lr: 	1.0000E-05 loss: 	0.03284
 epoch [0015 / 0050] [0499/1017] eta: 0 Days 3:15:54        lr: 	1.0000E-05 loss: 	0.03407
 epoch [0015 / 0050] [0599/1017] eta: 0 Days 3:15:14        lr: 	1.0000E-05 loss: 	0.03453
 epoch [0015 / 0050] [0699/1017] eta: 0 Days 3:14:32        lr: 	1.0000E-05 loss: 	0.03319
 epoch [0015 / 0050] [0799/1017] eta: 0 Days 3:13:49        lr: 	1.0000E-05 loss: 	0.03270
 epoch [0015 / 0050] [0899/1017] eta: 0 Days 3:13:6         lr: 	1.0000E-05 loss: 	0.03202
 epoch [0015 / 0050] [0999/1017] eta: 0 Days 3:12:26        lr: 	1.0000E-05 loss: 	0.03173
16
Starting val epoch 16
val [0016 / 0050] validation loss: 	0.95329
Starting train epoch 16
 epoch [0016 / 0050] [0099/1017] eta: 0 Days 3:12:54        lr: 	1.0000E-05 loss: 	0.02487
 epoch [0016 / 0050] [0199/1017] eta: 0 Days 3:12:13        lr: 	1.0000E-05 loss: 	0.02001
 epoch [0016 / 0050] [0299/1017] eta: 0 Days 3:11:30        lr: 	1.0000E-05 loss: 	0.01974
 epoch [0016 / 0050] [0399/1017] eta: 0 Days 3:10:50        lr: 	1.0000E-05 loss: 	0.02129
 epoch [0016 / 0050] [0499/1017] eta: 0 Days 3:10:9         lr: 	1.0000E-05 loss: 	0.02114
 epoch [0016 / 0050] [0599/1017] eta: 0 Days 3:9:27         lr: 	1.0000E-05 loss: 	0.02424
 epoch [0016 / 0050] [0699/1017] eta: 0 Days 3:8:45         lr: 	1.0000E-05 loss: 	0.02324
 epoch [0016 / 0050] [0799/1017] eta: 0 Days 3:8:3          lr: 	1.0000E-05 loss: 	0.02348
 epoch [0016 / 0050] [0899/1017] eta: 0 Days 3:7:22         lr: 	1.0000E-05 loss: 	0.02452
 epoch [0016 / 0050] [0999/1017] eta: 0 Days 3:6:42         lr: 	1.0000E-05 loss: 	0.02544
17
Starting val epoch 17
val [0017 / 0050] validation loss: 	0.91924
Starting train epoch 17
 epoch [0017 / 0050] [0099/1017] eta: 0 Days 3:7:3          lr: 	1.0000E-05 loss: 	0.02009
 epoch [0017 / 0050] [0199/1017] eta: 0 Days 3:6:22         lr: 	1.0000E-05 loss: 	0.01785
 epoch [0017 / 0050] [0299/1017] eta: 0 Days 3:5:41         lr: 	1.0000E-05 loss: 	0.02289
 epoch [0017 / 0050] [0399/1017] eta: 0 Days 3:5:0          lr: 	1.0000E-05 loss: 	0.02371
 epoch [0017 / 0050] [0499/1017] eta: 0 Days 3:4:20         lr: 	1.0000E-05 loss: 	0.02362
 epoch [0017 / 0050] [0599/1017] eta: 0 Days 3:3:39         lr: 	1.0000E-05 loss: 	0.02217
 epoch [0017 / 0050] [0699/1017] eta: 0 Days 3:2:58         lr: 	1.0000E-05 loss: 	0.02400
 epoch [0017 / 0050] [0799/1017] eta: 0 Days 3:2:17         lr: 	1.0000E-05 loss: 	0.02384
 epoch [0017 / 0050] [0899/1017] eta: 0 Days 3:1:37         lr: 	1.0000E-05 loss: 	0.02412
 epoch [0017 / 0050] [0999/1017] eta: 0 Days 3:0:57         lr: 	1.0000E-05 loss: 	0.02395
18
Starting val epoch 18
val [0018 / 0050] validation loss: 	1.02339
Starting train epoch 18
 epoch [0018 / 0050] [0099/1017] eta: 0 Days 3:1:13         lr: 	1.0000E-05 loss: 	0.01182
 epoch [0018 / 0050] [0199/1017] eta: 0 Days 3:0:34         lr: 	1.0000E-05 loss: 	0.01073
 epoch [0018 / 0050] [0299/1017] eta: 0 Days 2:59:53        lr: 	1.0000E-05 loss: 	0.01716
 epoch [0018 / 0050] [0399/1017] eta: 0 Days 2:59:14        lr: 	1.0000E-05 loss: 	0.01808
 epoch [0018 / 0050] [0499/1017] eta: 0 Days 2:58:33        lr: 	1.0000E-05 loss: 	0.02040
 epoch [0018 / 0050] [0599/1017] eta: 0 Days 2:57:55        lr: 	1.0000E-05 loss: 	0.02439
 epoch [0018 / 0050] [0699/1017] eta: 0 Days 2:57:15        lr: 	1.0000E-05 loss: 	0.02559
 epoch [0018 / 0050] [0799/1017] eta: 0 Days 2:56:35        lr: 	1.0000E-05 loss: 	0.02546
 epoch [0018 / 0050] [0899/1017] eta: 0 Days 2:55:56        lr: 	1.0000E-05 loss: 	0.02537
 epoch [0018 / 0050] [0999/1017] eta: 0 Days 2:55:18        lr: 	1.0000E-05 loss: 	0.02632
19
Starting val epoch 19
val [0019 / 0050] validation loss: 	1.00868
Starting val epoch 0
val [0000 / 0050] validation loss: 	0.37376
Acute and unspecified renal failure                                                        & 0.751(0.771, 0.731) & 0.308 (0.345, 0.277)
fused_ehr test  0   best mean auc :0.751 mean auprc 0.308
                    CI AUROC (0.731, 0.771) CI AUPRC (0.277, 0.345)
                     AUROC accute 0.751 mixed 0.751 chronic 0.751
                     AUROC accute CI (0.731, 0.771) mixed (0.731 , 0.771) chronic (0.731, 0.771)
                     AUPRC accute  0.308 mixed 0.308 chronic 0.308
                     AUPRC accute CI  (0.277, 0.345) mixed (0.277,  0.345) chronic (0.277, 0.345)