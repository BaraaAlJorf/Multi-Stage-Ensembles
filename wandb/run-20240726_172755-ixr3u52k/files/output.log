Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
rr loaded
==> training
running for fusion_type fused_ehr
0
starting val epoch 0
val [0000 / 0050] validation loss: 	0.98829
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/267] eta: 0 Days 16:50:9        lr: 	1.0000E-05 loss: 	0.76550 loss align 0.0000
 epoch [0000 / 0050] [0109/267] eta: 0 Days 3:17:44        lr: 	1.0000E-05 loss: 	0.43249 loss align 0.0000
 epoch [0000 / 0050] [0209/267] eta: 0 Days 2:38:42        lr: 	1.0000E-05 loss: 	0.41937 loss align 0.0000
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.37631
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/267] eta: 0 Days 2:44:42        lr: 	1.0000E-05 loss: 	0.38766 loss align 0.0000
 epoch [0001 / 0050] [0109/267] eta: 0 Days 2:30:52        lr: 	1.0000E-05 loss: 	0.33725 loss align 0.0000
 epoch [0001 / 0050] [0209/267] eta: 0 Days 2:22:16        lr: 	1.0000E-05 loss: 	0.32478 loss align 0.0000
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.34999
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/267] eta: 0 Days 2:26:36        lr: 	1.0000E-05 loss: 	0.35317 loss align 0.0000
 epoch [0002 / 0050] [0109/267] eta: 0 Days 2:20:39        lr: 	1.0000E-05 loss: 	0.29073 loss align 0.0000
 epoch [0002 / 0050] [0209/267] eta: 0 Days 2:15:55        lr: 	1.0000E-05 loss: 	0.28514 loss align 0.0000
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.33549
checkpoint
starting train epoch 3
 epoch [0003 / 0050] [0009/267] eta: 0 Days 2:18:48        lr: 	1.0000E-05 loss: 	0.24898 loss align 0.0000
 epoch [0003 / 0050] [0109/267] eta: 0 Days 2:14:45        lr: 	1.0000E-05 loss: 	0.25582 loss align 0.0000
 epoch [0003 / 0050] [0209/267] eta: 0 Days 2:11:12        lr: 	1.0000E-05 loss: 	0.26795 loss align 0.0000
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.33337
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/267] eta: 0 Days 2:13:18        lr: 	1.0000E-05 loss: 	0.27048 loss align 0.0000
 epoch [0004 / 0050] [0109/267] eta: 0 Days 2:10:6         lr: 	1.0000E-05 loss: 	0.24192 loss align 0.0000
 epoch [0004 / 0050] [0209/267] eta: 0 Days 2:7:15         lr: 	1.0000E-05 loss: 	0.24231 loss align 0.0000
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.39644
starting train epoch 5
 epoch [0005 / 0050] [0009/267] eta: 0 Days 2:8:0          lr: 	1.0000E-05 loss: 	0.21074 loss align 0.0000
 epoch [0005 / 0050] [0109/267] eta: 0 Days 2:5:28         lr: 	1.0000E-05 loss: 	0.18599 loss align 0.0000
 epoch [0005 / 0050] [0209/267] eta: 0 Days 2:3:7          lr: 	1.0000E-05 loss: 	0.18491 loss align 0.0000
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.46250
starting train epoch 6
 epoch [0006 / 0050] [0009/267] eta: 0 Days 2:3:46         lr: 	1.0000E-05 loss: 	0.18846 loss align 0.0000
 epoch [0006 / 0050] [0109/267] eta: 0 Days 2:1:29         lr: 	1.0000E-05 loss: 	0.13277 loss align 0.0000
 epoch [0006 / 0050] [0209/267] eta: 0 Days 1:59:26        lr: 	1.0000E-05 loss: 	0.13943 loss align 0.0000
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.52324
starting train epoch 7
 epoch [0007 / 0050] [0009/267] eta: 0 Days 1:59:51        lr: 	1.0000E-05 loss: 	0.07982 loss align 0.0000
 epoch [0007 / 0050] [0109/267] eta: 0 Days 1:57:56        lr: 	1.0000E-05 loss: 	0.08240 loss align 0.0000
 epoch [0007 / 0050] [0209/267] eta: 0 Days 1:56:3         lr: 	1.0000E-05 loss: 	0.09650 loss align 0.0000
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.61339
starting train epoch 8
 epoch [0008 / 0050] [0009/267] eta: 0 Days 1:56:22        lr: 	1.0000E-05 loss: 	0.11084 loss align 0.0000
 epoch [0008 / 0050] [0109/267] eta: 0 Days 1:54:37        lr: 	1.0000E-05 loss: 	0.05502 loss align 0.0000
 epoch [0008 / 0050] [0209/267] eta: 0 Days 1:52:54        lr: 	1.0000E-05 loss: 	0.06034 loss align 0.0000
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.75239
starting train epoch 9
 epoch [0009 / 0050] [0009/267] eta: 0 Days 1:53:4         lr: 	1.0000E-05 loss: 	0.06911 loss align 0.0000
 epoch [0009 / 0050] [0109/267] eta: 0 Days 1:51:21        lr: 	1.0000E-05 loss: 	0.05533 loss align 0.0000
 epoch [0009 / 0050] [0209/267] eta: 0 Days 1:49:44        lr: 	1.0000E-05 loss: 	0.05017 loss align 0.0000
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.88002
starting train epoch 10
 epoch [0010 / 0050] [0009/267] eta: 0 Days 1:49:49        lr: 	1.0000E-05 loss: 	0.12106 loss align 0.0000
 epoch [0010 / 0050] [0109/267] eta: 0 Days 1:48:15        lr: 	1.0000E-05 loss: 	0.06645 loss align 0.0000
 epoch [0010 / 0050] [0209/267] eta: 0 Days 1:46:43        lr: 	1.0000E-05 loss: 	0.05481 loss align 0.0000
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.86163
starting train epoch 11
 epoch [0011 / 0050] [0009/267] eta: 0 Days 1:46:42        lr: 	1.0000E-05 loss: 	0.02287 loss align 0.0000
 epoch [0011 / 0050] [0109/267] eta: 0 Days 1:45:14        lr: 	1.0000E-05 loss: 	0.03271 loss align 0.0000
 epoch [0011 / 0050] [0209/267] eta: 0 Days 1:43:48        lr: 	1.0000E-05 loss: 	0.03696 loss align 0.0000
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.86244
starting train epoch 12
 epoch [0012 / 0050] [0009/267] eta: 0 Days 1:43:45        lr: 	1.0000E-05 loss: 	0.01245 loss align 0.0000
 epoch [0012 / 0050] [0109/267] eta: 0 Days 1:42:19        lr: 	1.0000E-05 loss: 	0.02458 loss align 0.0000
 epoch [0012 / 0050] [0209/267] eta: 0 Days 1:40:54        lr: 	1.0000E-05 loss: 	0.02865 loss align 0.0000
13
starting val epoch 13
val [0013 / 0050] validation loss: 	1.05455
starting train epoch 13
 epoch [0013 / 0050] [0009/267] eta: 0 Days 1:40:46        lr: 	1.0000E-05 loss: 	0.03268 loss align 0.0000
 epoch [0013 / 0050] [0109/267] eta: 0 Days 1:39:23        lr: 	1.0000E-05 loss: 	0.02341 loss align 0.0000
 epoch [0013 / 0050] [0209/267] eta: 0 Days 1:38:0         lr: 	1.0000E-05 loss: 	0.03048 loss align 0.0000
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.96893
starting train epoch 14
 epoch [0014 / 0050] [0009/267] eta: 0 Days 1:37:51        lr: 	1.0000E-05 loss: 	0.01036 loss align 0.0000
 epoch [0014 / 0050] [0109/267] eta: 0 Days 1:36:30        lr: 	1.0000E-05 loss: 	0.03782 loss align 0.0000
 epoch [0014 / 0050] [0209/267] eta: 0 Days 1:35:9         lr: 	1.0000E-05 loss: 	0.03267 loss align 0.0000
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.98370
starting train epoch 15
 epoch [0015 / 0050] [0009/267] eta: 0 Days 1:34:57        lr: 	1.0000E-05 loss: 	0.00621 loss align 0.0000
 epoch [0015 / 0050] [0109/267] eta: 0 Days 1:33:38        lr: 	1.0000E-05 loss: 	0.02843 loss align 0.0000
 epoch [0015 / 0050] [0209/267] eta: 0 Days 1:32:19        lr: 	1.0000E-05 loss: 	0.03244 loss align 0.0000
16
starting val epoch 16
val [0016 / 0050] validation loss: 	1.06067
starting train epoch 16
 epoch [0016 / 0050] [0009/267] eta: 0 Days 1:32:5         lr: 	1.0000E-05 loss: 	0.02507 loss align 0.0000
 epoch [0016 / 0050] [0109/267] eta: 0 Days 1:30:49        lr: 	1.0000E-05 loss: 	0.01191 loss align 0.0000
 epoch [0016 / 0050] [0209/267] eta: 0 Days 1:29:32        lr: 	1.0000E-05 loss: 	0.02496 loss align 0.0000
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.87604
starting train epoch 17
 epoch [0017 / 0050] [0009/267] eta: 0 Days 1:29:15        lr: 	1.0000E-05 loss: 	0.04367 loss align 0.0000
 epoch [0017 / 0050] [0109/267] eta: 0 Days 1:28:0         lr: 	1.0000E-05 loss: 	0.02296 loss align 0.0000
 epoch [0017 / 0050] [0209/267] eta: 0 Days 1:26:46        lr: 	1.0000E-05 loss: 	0.01868 loss align 0.0000
18
starting val epoch 18
val [0018 / 0050] validation loss: 	1.19439
starting train epoch 18
 epoch [0018 / 0050] [0009/267] eta: 0 Days 1:26:27        lr: 	1.0000E-05 loss: 	0.00374 loss align 0.0000
 epoch [0018 / 0050] [0109/267] eta: 0 Days 1:25:14        lr: 	1.0000E-05 loss: 	0.01025 loss align 0.0000
 epoch [0018 / 0050] [0209/267] eta: 0 Days 1:24:2         lr: 	1.0000E-05 loss: 	0.01216 loss align 0.0000
19
starting val epoch 19
val [0019 / 0050] validation loss: 	1.11692
starting val epoch 0
val [0000 / 0050] validation loss: 	0.33703
Acute and unspecified renal failure                                                        & 0.843(0.872, 0.812) & 0.504 (0.585, 0.437)
fused_ehr test  0   best mean auc :0.843 mean auprc 0.504
                    CI AUROC (0.812, 0.872) CI AUPRC (0.437, 0.585)
                     AUROC accute 0.843 mixed 0.843 chronic 0.843
                     AUROC accute CI (0.812, 0.872) mixed (0.812 , 0.872) chronic (0.812, 0.872)
                     AUPRC accute  0.504 mixed 0.504 chronic 0.504
                     AUPRC accute CI  (0.437, 0.585) mixed (0.437,  0.585) chronic (0.437, 0.585)