Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
ehr loaded
cxr loaded
==> training
running for fusion_type late
0
starting val epoch 0
val [0000 / 0050] validation loss: 	1.07356
checkpoint
starting train epoch 0
 epoch [0000 / 0050] [0009/280] eta: 0 Days 11:48:3        lr: 	1.0000E-03 loss: 	1.73586
 epoch [0000 / 0050] [0109/280] eta: 0 Days 1:42:56        lr: 	1.0000E-03 loss: 	0.62098
 epoch [0000 / 0050] [0209/280] eta: 0 Days 1:13:56        lr: 	1.0000E-03 loss: 	0.52946
1
starting val epoch 1
val [0001 / 0050] validation loss: 	0.38981
checkpoint
starting train epoch 1
 epoch [0001 / 0050] [0009/280] eta: 0 Days 1:14:18        lr: 	1.0000E-03 loss: 	0.47012
 epoch [0001 / 0050] [0109/280] eta: 0 Days 1:5:47         lr: 	1.0000E-03 loss: 	0.42047
 epoch [0001 / 0050] [0209/280] eta: 0 Days 1:0:18         lr: 	1.0000E-03 loss: 	0.40179
2
starting val epoch 2
val [0002 / 0050] validation loss: 	0.39386
checkpoint
starting train epoch 2
 epoch [0002 / 0050] [0009/280] eta: 0 Days 1:1:56         lr: 	1.0000E-03 loss: 	0.37574
 epoch [0002 / 0050] [0109/280] eta: 0 Days 0:58:10        lr: 	1.0000E-03 loss: 	0.37040
 epoch [0002 / 0050] [0209/280] eta: 0 Days 0:55:36        lr: 	1.0000E-03 loss: 	0.38557
3
starting val epoch 3
val [0003 / 0050] validation loss: 	0.40359
starting train epoch 3
 epoch [0003 / 0050] [0009/280] eta: 0 Days 0:56:18        lr: 	1.0000E-03 loss: 	0.34440
 epoch [0003 / 0050] [0109/280] eta: 0 Days 0:54:12        lr: 	1.0000E-03 loss: 	0.38281
 epoch [0003 / 0050] [0209/280] eta: 0 Days 0:52:51        lr: 	1.0000E-03 loss: 	0.38903
4
starting val epoch 4
val [0004 / 0050] validation loss: 	0.42532
checkpoint
starting train epoch 4
 epoch [0004 / 0050] [0009/280] eta: 0 Days 0:54:1         lr: 	1.0000E-03 loss: 	0.43005
 epoch [0004 / 0050] [0109/280] eta: 0 Days 0:52:29        lr: 	1.0000E-03 loss: 	0.38549
 epoch [0004 / 0050] [0209/280] eta: 0 Days 0:51:9         lr: 	1.0000E-03 loss: 	0.39492
5
starting val epoch 5
val [0005 / 0050] validation loss: 	0.43269
starting train epoch 5
 epoch [0005 / 0050] [0009/280] eta: 0 Days 0:51:38        lr: 	1.0000E-03 loss: 	0.52088
 epoch [0005 / 0050] [0109/280] eta: 0 Days 0:50:17        lr: 	1.0000E-03 loss: 	0.37779
 epoch [0005 / 0050] [0209/280] eta: 0 Days 0:49:4         lr: 	1.0000E-03 loss: 	0.37408
6
starting val epoch 6
val [0006 / 0050] validation loss: 	0.43512
starting train epoch 6
 epoch [0006 / 0050] [0009/280] eta: 0 Days 0:49:20        lr: 	1.0000E-03 loss: 	0.42238
 epoch [0006 / 0050] [0109/280] eta: 0 Days 0:48:20        lr: 	1.0000E-03 loss: 	0.39592
 epoch [0006 / 0050] [0209/280] eta: 0 Days 0:47:20        lr: 	1.0000E-03 loss: 	0.39073
7
starting val epoch 7
val [0007 / 0050] validation loss: 	0.38381
starting train epoch 7
 epoch [0007 / 0050] [0009/280] eta: 0 Days 0:47:42        lr: 	1.0000E-03 loss: 	0.49694
 epoch [0007 / 0050] [0109/280] eta: 0 Days 0:46:48        lr: 	1.0000E-03 loss: 	0.39175
 epoch [0007 / 0050] [0209/280] eta: 0 Days 0:45:58        lr: 	1.0000E-03 loss: 	0.38300
8
starting val epoch 8
val [0008 / 0050] validation loss: 	0.47163
starting train epoch 8
 epoch [0008 / 0050] [0009/280] eta: 0 Days 0:46:11        lr: 	1.0000E-03 loss: 	0.49042
 epoch [0008 / 0050] [0109/280] eta: 0 Days 0:45:29        lr: 	1.0000E-03 loss: 	0.38019
 epoch [0008 / 0050] [0209/280] eta: 0 Days 0:44:44        lr: 	1.0000E-03 loss: 	0.38791
9
starting val epoch 9
val [0009 / 0050] validation loss: 	0.42487
starting train epoch 9
 epoch [0009 / 0050] [0009/280] eta: 0 Days 0:44:53        lr: 	1.0000E-03 loss: 	0.48307
 epoch [0009 / 0050] [0109/280] eta: 0 Days 0:44:10        lr: 	1.0000E-03 loss: 	0.38685
 epoch [0009 / 0050] [0209/280] eta: 0 Days 0:43:27        lr: 	1.0000E-03 loss: 	0.37807
10
starting val epoch 10
val [0010 / 0050] validation loss: 	0.45177
starting train epoch 10
 epoch [0010 / 0050] [0009/280] eta: 0 Days 0:43:30        lr: 	1.0000E-03 loss: 	0.52232
 epoch [0010 / 0050] [0109/280] eta: 0 Days 0:42:47        lr: 	1.0000E-03 loss: 	0.37140
 epoch [0010 / 0050] [0209/280] eta: 0 Days 0:42:7         lr: 	1.0000E-03 loss: 	0.38023
11
starting val epoch 11
val [0011 / 0050] validation loss: 	0.40904
starting train epoch 11
 epoch [0011 / 0050] [0009/280] eta: 0 Days 0:42:9         lr: 	1.0000E-03 loss: 	0.42497
 epoch [0011 / 0050] [0109/280] eta: 0 Days 0:41:29        lr: 	1.0000E-03 loss: 	0.38128
 epoch [0011 / 0050] [0209/280] eta: 0 Days 0:40:55        lr: 	1.0000E-03 loss: 	0.37474
12
starting val epoch 12
val [0012 / 0050] validation loss: 	0.41485
starting train epoch 12
 epoch [0012 / 0050] [0009/280] eta: 0 Days 0:40:57        lr: 	1.0000E-03 loss: 	0.35495
 epoch [0012 / 0050] [0109/280] eta: 0 Days 0:40:24        lr: 	1.0000E-03 loss: 	0.35975
 epoch [0012 / 0050] [0209/280] eta: 0 Days 0:39:48        lr: 	1.0000E-03 loss: 	0.37484
13
starting val epoch 13
val [0013 / 0050] validation loss: 	0.40045
starting train epoch 13
 epoch [0013 / 0050] [0009/280] eta: 0 Days 0:39:48        lr: 	1.0000E-03 loss: 	0.30907
 epoch [0013 / 0050] [0109/280] eta: 0 Days 0:39:14        lr: 	1.0000E-03 loss: 	0.36875
 epoch [0013 / 0050] [0209/280] eta: 0 Days 0:38:39        lr: 	1.0000E-03 loss: 	0.37722
14
starting val epoch 14
val [0014 / 0050] validation loss: 	0.45840
starting train epoch 14
 epoch [0014 / 0050] [0009/280] eta: 0 Days 0:38:36        lr: 	1.0000E-03 loss: 	0.47351
 epoch [0014 / 0050] [0109/280] eta: 0 Days 0:38:1         lr: 	1.0000E-03 loss: 	0.36817
 epoch [0014 / 0050] [0209/280] eta: 0 Days 0:37:27        lr: 	1.0000E-03 loss: 	0.38458
15
starting val epoch 15
val [0015 / 0050] validation loss: 	0.48077
starting train epoch 15
 epoch [0015 / 0050] [0009/280] eta: 0 Days 0:37:22        lr: 	1.0000E-03 loss: 	0.45327
 epoch [0015 / 0050] [0109/280] eta: 0 Days 0:36:48        lr: 	1.0000E-03 loss: 	0.38173
 epoch [0015 / 0050] [0209/280] eta: 0 Days 0:36:14        lr: 	1.0000E-03 loss: 	0.37455
16
starting val epoch 16
val [0016 / 0050] validation loss: 	0.39704
starting train epoch 16
 epoch [0016 / 0050] [0009/280] eta: 0 Days 0:36:9         lr: 	1.0000E-03 loss: 	0.42537
 epoch [0016 / 0050] [0109/280] eta: 0 Days 0:35:36        lr: 	1.0000E-03 loss: 	0.36409
 epoch [0016 / 0050] [0209/280] eta: 0 Days 0:35:5         lr: 	1.0000E-03 loss: 	0.36651
17
starting val epoch 17
val [0017 / 0050] validation loss: 	0.40893
starting train epoch 17
 epoch [0017 / 0050] [0009/280] eta: 0 Days 0:34:58        lr: 	1.0000E-03 loss: 	0.45041
 epoch [0017 / 0050] [0109/280] eta: 0 Days 0:34:30        lr: 	1.0000E-03 loss: 	0.37994
 epoch [0017 / 0050] [0209/280] eta: 0 Days 0:33:59        lr: 	1.0000E-03 loss: 	0.37809
18
starting val epoch 18
val [0018 / 0050] validation loss: 	0.43595
starting train epoch 18
 epoch [0018 / 0050] [0009/280] eta: 0 Days 0:33:52        lr: 	1.0000E-03 loss: 	0.43950
 epoch [0018 / 0050] [0109/280] eta: 0 Days 0:33:22        lr: 	1.0000E-03 loss: 	0.39379
 epoch [0018 / 0050] [0209/280] eta: 0 Days 0:32:51        lr: 	1.0000E-03 loss: 	0.38822
19
starting val epoch 19
val [0019 / 0050] validation loss: 	0.40612
starting val epoch 0
val [0000 / 0050] validation loss: 	0.41965
Acute and unspecified renal failure                                                        & 0.726(0.766, 0.684) & 0.325 (0.393, 0.267)
fused_ehr test  0   best mean auc :0.726 mean auprc 0.325
                    CI AUROC (0.684, 0.766) CI AUPRC (0.267, 0.393)
                     AUROC accute 0.726 mixed 0.726 chronic 0.726
                     AUROC accute CI (0.684, 0.766) mixed (0.684 , 0.766) chronic (0.684, 0.766)
                     AUPRC accute  0.325 mixed 0.325 chronic 0.325
                     AUPRC accute CI  (0.267, 0.393) mixed (0.267,  0.393) chronic (0.267, 0.393)